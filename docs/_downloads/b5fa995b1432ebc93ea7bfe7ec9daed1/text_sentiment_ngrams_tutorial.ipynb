{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ntorchtext \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c \ud14d\uc2a4\ud2b8 \ubd84\ub958\ud558\uae30\n===============================================\n\n**\ubc88\uc5ed**: `\uae40\uac15\ubbfc <https://github.com/gangsss>`_ , `\uae40\uc9c4\ud604 <https://github.com/lewha0>`_\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 torchtext \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc5b4\ub5bb\uac8c \ud14d\uc2a4\ud2b8 \ubd84\ub958 \ubd84\uc11d\uc744 \uc704\ud55c \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4dc\ub294\uc9c0\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\ub2e4\uc74c\uacfc \uac19\uc740 \ub0b4\uc6a9\ub4e4\uc744 \uc54c\uac8c \ub429\ub2c8\ub2e4:\n\n   - \ubc18\ubcf5\uc790(iterator)\ub85c \uac00\uacf5\ub418\uc9c0 \uc54a\uc740 \ub370\uc774\ud130(raw data)\uc5d0 \uc811\uadfc\ud558\uae30\n   - \uac00\uacf5\ub418\uc9c0 \uc54a\uc740 \ud14d\uc2a4\ud2b8 \ubb38\uc7a5\ub4e4\uc744 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 ``torch.Tensor`` \ub85c \ubcc0\ud658\ud558\ub294 \ub370\uc774\ud130 \ucc98\ub9ac \ud30c\uc774\ud504\ub77c\uc778 \ub9cc\ub4e4\uae30\n   - `torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__ \ub97c \uc0ac\uc6a9\ud558\uc5ec \ub370\uc774\ud130\ub97c \uc11e\uace0 \ubc18\ubcf5\ud558\uae30(shuffle and iterate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uae30\ucd08 \ub370\uc774\ud130\uc14b \ubc18\ubcf5\uc790(raw data iterator)\uc5d0 \uc811\uadfc\ud558\uae30\n-------------------------------------------------------------\n\ntorchtext \ub77c\uc774\ube0c\ub7ec\ub9ac\ub294 \uac00\uacf5\ub418\uc9c0 \uc54a\uc740 \ud14d\uc2a4\ud2b8 \ubb38\uc7a5\ub4e4\uc744 \ub9cc\ub4dc\ub294(yield) \uba87 \uac00\uc9c0 \uae30\ucd08 \ub370\uc774\ud130\uc14b \ubc18\ubcf5\uc790(raw dataset iterator)\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\uc608\ub97c \ub4e4\uc5b4, ``AG_NEWS`` \ub370\uc774\ud130\uc14b \ubc18\ubcf5\uc790\ub294 \ub808\uc774\ube14(label)\uacfc \ubb38\uc7a5\uc758 \ud29c\ud50c(tuple) \ud615\ud0dc\ub85c \uac00\uacf5\ub418\uc9c0 \uc54a\uc740 \ub370\uc774\ud130\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n\ntorchtext \ub370\uc774\ud130\uc14b\uc5d0 \uc811\uadfc\ud558\uae30 \uc804\uc5d0, https://github.com/pytorch/data \uc744 \ucc38\uace0\ud558\uc5ec torchdata\ub97c\n\uc124\uce58\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torchtext.datasets import AG_NEWS\ntrain_iter = iter(AG_NEWS(split='train'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::\n\n    next(train_iter)\n    >>> (3, \"Fears for T N pension after talks Unions representing workers at Turner\n    Newall say they are 'disappointed' after talks with stricken parent firm Federal\n    Mogul.\")\n\n    next(train_iter)\n    >>> (4, \"The Race is On: Second Private Team Sets Launch Date for Human\n    Spaceflight (SPACE.com) SPACE.com - TORONTO, Canada -- A second\\\\team of\n    rocketeers competing for the  #36;10 million Ansari X Prize, a contest\n    for\\\\privately funded suborbital space flight, has officially announced\n    the first\\\\launch date for its manned rocket.\")\n\n    next(train_iter)\n    >>> (4, 'Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded\n    by a chemistry researcher at the University of Louisville won a grant to develop\n    a method of producing better peptides, which are short chains of amino acids, the\n    building blocks of proteins.')\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \ucc98\ub9ac \ud30c\uc774\ud504\ub77c\uc778 \uc900\ube44\ud558\uae30\n---------------------------------\n\n\uc5b4\ud718\uc9d1(vocab), \ub2e8\uc5b4 \ubca1\ud130(word vector), \ud1a0\ud06c\ub098\uc774\uc800(tokenizer)\ub97c \ud3ec\ud568\ud558\uc5ec torchtext \ub77c\uc774\ube0c\ub7ec\ub9ac\uc758 \uac00\uc7a5 \uae30\ubcf8\uc801\uc778 \uad6c\uc131\uc694\uc18c\ub97c \uc7ac\uac80\ud1a0\ud588\uc2b5\ub2c8\ub2e4.\n\uc774\ub4e4\uc740 \uac00\uacf5\ub418\uc9c0 \uc54a\uc740 \ud14d\uc2a4\ud2b8 \ubb38\uc790\uc5f4\uc5d0 \ub300\ud55c \uae30\ubcf8\uc801\uc778 \ub370\uc774\ud130 \ucc98\ub9ac \ube4c\ub529 \ube14\ub85d(data processing building block)\uc785\ub2c8\ub2e4.\n\n\ub2e4\uc74c\uc740 \ud1a0\ud06c\ub098\uc774\uc800 \ubc0f \uc5b4\ud718\uc9d1\uc744 \uc0ac\uc6a9\ud55c \uc77c\ubc18\uc801\uc778 NLP \ub370\uc774\ud130 \ucc98\ub9ac\uc758 \uc608\uc785\ub2c8\ub2e4.\n\uccab\ubc88\uc9f8 \ub2e8\uacc4\ub294 \uac00\uacf5\ub418\uc9c0 \uc54a\uc740 \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc73c\ub85c \uc5b4\ud718\uc9d1\uc744 \ub9cc\ub4dc\ub294 \uac83\uc785\ub2c8\ub2e4.\n\uc5ec\uae30\uc5d0\uc11c\ub294 \ud1a0\ud070\uc758 \ubaa9\ub85d \ub610\ub294 \ubc18\ubcf5\uc790\ub97c \ubc1b\ub294 \ub0b4\uc7a5(built-in) \ud329\ud1a0\ub9ac \ud568\uc218(factory function) `build_vocab_from_iterator` \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\uc0ac\uc6a9\uc790\ub294 \uc5b4\ud718\uc9d1\uc5d0 \ucd94\uac00\ud560 \ud2b9\uc218 \uae30\ud638(special symbol) \uac19\uc740 \uac83\ub4e4\uc744 \uc804\ub2ec\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\n\ntokenizer = get_tokenizer('basic_english')\ntrain_iter = AG_NEWS(split='train')\n\ndef yield_tokens(data_iter):\n    for _, text in data_iter:\n        yield tokenizer(text)\n\nvocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\nvocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc5b4\ud718\uc9d1 \ube14\ub85d(vocabulary block)\uc740 \ud1a0\ud070 \ubaa9\ub85d\uc744 \uc815\uc218\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n\n::\n\n    vocab(['here', 'is', 'an', 'example'])\n    >>> [475, 21, 30, 5297]\n\n\ud1a0\ud06c\ub098\uc774\uc800\uc640 \uc5b4\ud718\uc9d1\uc744 \uac16\ucd98 \ud14d\uc2a4\ud2b8 \ucc98\ub9ac \ud30c\uc774\ud504\ub77c\uc778\uc744 \uc900\ube44\ud569\ub2c8\ub2e4.\n\ud14d\uc2a4\ud2b8 \ud30c\uc774\ud504\ub77c\uc778\uacfc \ub808\uc774\ube14(label) \ud30c\uc774\ud504\ub77c\uc778\uc740 \ub370\uc774\ud130\uc14b \ubc18\ubcf5\uc790\ub85c\ubd80\ud130 \uc5bb\uc5b4\uc628 \uac00\uacf5\ub418\uc9c0 \uc54a\uc740 \ubb38\uc7a5 \ub370\uc774\ud130\ub97c \ucc98\ub9ac\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\nlabel_pipeline = lambda x: int(x) - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud14d\uc2a4\ud2b8 \ud30c\uc774\ud504\ub77c\uc778\uc740 \uc5b4\ud718\uc9d1\uc5d0 \uc815\uc758\ub41c \ub8e9\uc5c5 \ud14c\uc774\ube14(\uc21c\ub78c\ud45c; lookup table)\uc5d0 \uae30\ubc18\ud558\uc5ec \ud14d\uc2a4\ud2b8 \ubb38\uc7a5\uc744 \uc815\uc218 \ubaa9\ub85d\uc73c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n\ub808\uc774\ube14(label) \ud30c\uc774\ud504\ub77c\uc778\uc740 \ub808\uc774\ube14\uc744 \uc815\uc218\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4,\n\n::\n\n    text_pipeline('here is the an example')\n    >>> [475, 21, 2, 30, 5297]\n    label_pipeline('10')\n    >>> 9\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \ubc30\uce58(batch)\uc640 \ubc18\ubcf5\uc790 \uc0dd\uc131\ud558\uae30\n----------------------------------------\n\n`torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__ \ub97c\n\uad8c\uc7a5\ud569\ub2c8\ub2e4. (\ud29c\ud1a0\ub9ac\uc5bc\uc740 `\uc5ec\uae30 <https://tutorials.pytorch.kr/beginner/data_loading_tutorial.html>`__ \uc788\uc2b5\ub2c8\ub2e4.)\n\uc774\ub294 ``getitem()`` \uacfc ``len()`` \ud504\ub85c\ud1a0\ucf5c\uc744 \uad6c\ud604\ud55c \ub9f5 \ud615\ud0dc(map-style)\uc758 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ub3d9\uc791\ud558\uba70, \ub9f5(map)\ucc98\ub7fc \uc778\ub371\uc2a4/\ud0a4\ub85c \ub370\uc774\ud130 \uc0d8\ud50c\uc744 \uc5bb\uc5b4\uc635\ub2c8\ub2e4.\n\ub610\ud55c, \uc154\ud50c(shuffle) \uc778\uc790\ub97c ``False`` \ub85c \uc124\uc815\ud558\uba74 \uc21c\ud68c \uac00\ub2a5\ud55c(iterable) \ub370\uc774\ud130\uc14b\ucc98\ub7fc \ub3d9\uc791\ud569\ub2c8\ub2e4.\n\n\ubaa8\ub378\ub85c \ubcf4\ub0b4\uae30 \uc804, ``collate_fn`` \ud568\uc218\ub294 ``DataLoader`` \ub85c\ubd80\ud130 \uc0dd\uc131\ub41c \uc0d8\ud50c \ubc30\uce58\ub85c \ub3d9\uc791\ud569\ub2c8\ub2e4.\n``collate_fn`` \uc758 \uc785\ub825\uc740 ``DataLoader`` \uc5d0 \ubc30\uce58 \ud06c\uae30(batch size)\uac00 \uc788\ub294 \ubc30\uce58(batch) \ub370\uc774\ud130\uc774\uba70,\n``collate_fn`` \uc740 \uc774\ub97c \ubbf8\ub9ac \uc120\uc5b8\ub41c \ub370\uc774\ud130 \ucc98\ub9ac \ud30c\uc774\ud504\ub77c\uc778\uc5d0 \ub530\ub77c \ucc98\ub9ac\ud569\ub2c8\ub2e4.\n``collate_fn`` \uc774 \ucd5c\uc0c1\uc704 \uc218\uc900\uc73c\ub85c \uc815\uc758(top level def)\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4. \uc774\ub807\uac8c \ud558\uba74 \ubaa8\ub4e0 \uc6cc\ucee4\uc5d0\uc11c \uc774 \ud568\uc218\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc544\ub798 \uc608\uc81c\uc5d0\uc11c, \uc8fc\uc5b4\uc9c4(original) \ub370\uc774\ud130 \ubc30\uce58\uc758 \ud14d\uc2a4\ud2b8 \ud56d\ubaa9\ub4e4\uc740 \ub9ac\uc2a4\ud2b8(list)\uc5d0 \ub2f4\uae34(pack) \ub4a4 ``nn.EmbeddingBag`` \uc758 \uc785\ub825\uc744 \uc704\ud55c \ud558\ub098\uc758 tensor\ub85c \ud569\uccd0(concatenate)\uc9d1\ub2c8\ub2e4.\n\uc624\ud504\uc14b(offset)\uc740 \ud14d\uc2a4\ud2b8 tensor\uc5d0\uc11c \uac1c\ubcc4 \uc2dc\ud000\uc2a4 \uc2dc\uc791 \uc778\ub371\uc2a4\ub97c \ud45c\ud604\ud558\uae30 \uc704\ud55c \uad6c\ubd84\uc790(delimiter) tensor\uc785\ub2c8\ub2e4.\n\ub808\uc774\ube14(label)\uc740 \uac1c\ubcc4 \ud14d\uc2a4\ud2b8 \ud56d\ubaa9\uc758 \ub808\uc774\ube14\uc744 \uc800\uc7a5\ud558\ub294 tensor\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef collate_batch(batch):\n    label_list, text_list, offsets = [], [], [0]\n    for (_label, _text) in batch:\n         label_list.append(label_pipeline(_label))\n         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n         text_list.append(processed_text)\n         offsets.append(processed_text.size(0))\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    text_list = torch.cat(text_list)\n    return label_list.to(device), text_list.to(device), offsets.to(device)\n\ntrain_iter = AG_NEWS(split='train')\ndataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc815\uc758\ud558\uae30\n---------------\n\n\ubaa8\ub378\uc740\n`nn.EmbeddingBag <https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag>`__\n\ub808\uc774\uc5b4\uc640 \ubd84\ub958(classification) \ubaa9\uc801\uc744 \uc704\ud55c \uc120\ud615 \ub808\uc774\uc5b4\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.\n\uae30\ubcf8 \ubaa8\ub4dc\uac00 \"\ud3c9\uade0(mean)\"\uc778 ``nn.EmbeddingBag`` \uc740 \uc784\ubca0\ub529\ub4e4\uc758 \"\uac00\ubc29(bag)\"\uc758 \ud3c9\uade0 \uac12\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\uc774\ub54c \ud14d\uc2a4\ud2b8(text) \ud56d\ubaa9\ub4e4\uc740 \uac01\uae30 \uadf8 \uae38\uc774\uac00 \ub2e4\ub97c \uc218 \uc788\uc9c0\ub9cc, ``nn.EmbeddingBag`` \ubaa8\ub4c8\uc740 \ud14d\uc2a4\ud2b8\uc758 \uae38\uc774\ub97c\n\uc624\ud504\uc14b(offset)\uc73c\ub85c \uc800\uc7a5\ud558\uace0 \uc788\uc73c\ubbc0\ub85c \ud328\ub529(padding)\uc774 \ud544\uc694\ud558\uc9c0\ub294 \uc54a\uc2b5\ub2c8\ub2e4.\n\n\ub367\ubd99\uc5ec\uc11c, ``nn.EmbeddingBag`` \uc740 \uc784\ubca0\ub529\uc758 \ud3c9\uade0\uc744 \uc989\uc2dc \uacc4\uc0b0\ud558\uae30 \ub54c\ubb38\uc5d0,\ntensor\ub4e4\uc758 \uc2dc\ud000\uc2a4\ub97c \ucc98\ub9ac\ud560 \ub54c \uc131\ub2a5 \ubc0f \uba54\ubaa8\ub9ac \ud6a8\uc728\uc131 \uce21\uba74\uc5d0\uc11c\uc758 \uc7a5\uc810\ub3c4\n\uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n![](../_static/img/text_sentiment_ngrams_model.png)\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import nn\n\nclass TextClassificationModel(nn.Module):\n\n    def __init__(self, vocab_size, embed_dim, num_class):\n        super(TextClassificationModel, self).__init__()\n        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n        self.fc = nn.Linear(embed_dim, num_class)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.5\n        self.embedding.weight.data.uniform_(-initrange, initrange)\n        self.fc.weight.data.uniform_(-initrange, initrange)\n        self.fc.bias.data.zero_()\n\n    def forward(self, text, offsets):\n        embedded = self.embedding(text, offsets)\n        return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131\ud558\uae30\n-----------------\n\n``AG_NEWS`` \ub370\uc774\ud130\uc14b\uc5d0\ub294 4\uc885\ub958\uc758 \ub808\uc774\ube14\uc774 \uc874\uc7ac\ud558\ubbc0\ub85c \ud074\ub798\uc2a4\uc758 \uac1c\uc218\ub3c4 4\uac1c\uc785\ub2c8\ub2e4.\n\n::\n\n   1 : World (\uc138\uacc4)\n   2 : Sports (\uc2a4\ud3ec\uce20)\n   3 : Business (\uacbd\uc81c)\n   4 : Sci/Tec (\uacfc\ud559/\uae30\uc220)\n\n\uc784\ubca0\ub529 \ucc28\uc6d0\uc774 64\uc778 \ubaa8\ub378\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n\uc5b4\ud718\uc9d1\uc758 \ud06c\uae30(Vocab size)\ub294 \uc5b4\ud718\uc9d1(vocab)\uc758 \uae38\uc774\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n\ud074\ub798\uc2a4\uc758 \uac1c\uc218\ub294 \ub808\uc774\ube14\uc758 \uac1c\uc218\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_iter = AG_NEWS(split='train')\nnum_class = len(set([label for (label, text) in train_iter]))\nvocab_size = len(vocab)\nemsize = 64\nmodel = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378\uc744 \ud559\uc2b5\ud558\uace0 \uacb0\uacfc\ub97c \ud3c9\uac00\ud558\ub294 \ud568\uc218 \uc815\uc758\ud558\uae30\n---------------------------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\ndef train(dataloader):\n    model.train()\n    total_acc, total_count = 0, 0\n    log_interval = 500\n    start_time = time.time()\n    for idx, (label, text, offsets) in enumerate(dataloader):\n        optimizer.zero_grad()\n        predicted_label = model(text, offsets)\n        loss = criterion(predicted_label, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n        total_acc += (predicted_label.argmax(1) == label).sum().item()\n        total_count += label.size(0)\n        if idx % log_interval == 0 and idx > 0:\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches '\n                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n                                              total_acc/total_count))\n            total_acc, total_count = 0, 0\n            start_time = time.time()\n\ndef evaluate(dataloader):\n    model.eval()\n    total_acc, total_count = 0, 0\n\n    with torch.no_grad():\n        for idx, (label, text, offsets) in enumerate(dataloader):\n            predicted_label = model(text, offsets)\n            loss = criterion(predicted_label, label)\n            total_acc += (predicted_label.argmax(1) == label).sum().item()\n            total_count += label.size(0)\n    return total_acc/total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130\uc14b\uc744 \ubd84\ud560\ud558\uace0 \ubaa8\ub378 \uc218\ud589\ud558\uae30\n---------------------------------\n\n\uc6d0\ubcf8 ``AG_NEWS`` \uc5d0\ub294 \uac80\uc99d\uc6a9 \ub370\uc774\ud130\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0, \uc6b0\ub9ac\ub294 \ud559\uc2b5\n\ub370\uc774\ud130\ub97c \ud559\uc2b5 \ubc0f \uac80\uc99d \ub370\uc774\ud130\ub85c \ubd84\ud560\ud558\ub824 \ud569\ub2c8\ub2e4. \uc774\ub54c \ub370\uc774\ud130\ub97c \ubd84\ud560\ud558\ub294\n\ube44\uc728\uc740 0.95(\ud559\uc2b5)\uc640 0.05(\uac80\uc99d) \uc785\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \uc5ec\uae30\uc11c PyTorch\uc758\n\ud575\uc2ec \ub77c\uc774\ube0c\ub7ec\ub9ac \uc911 \ud558\ub098\uc778\n`torch.utils.data.dataset.random_split <https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>`__\n\ud568\uc218\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n`CrossEntropyLoss <https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n\uae30\uc900(criterion)\uc740 \uac01 \ud074\ub798\uc2a4\uc5d0 \ub300\ud574 ``nn.LogSoftmax()`` \uc640 ``nn.NLLLoss()`` \ub97c\n\ud569\uccd0\ub193\uc740 \ubc29\uc2dd\uc785\ub2c8\ub2e4.\n`SGD <https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>`__\noptimizer\ub294 \ud655\ub960\uc801 \uacbd\uc0ac \ud558\uac15\ubc95\ub97c \uad6c\ud604\ud574\ub193\uc740 \uac83\uc785\ub2c8\ub2e4. \ucc98\uc74c\uc758 \ud559\uc2b5\ub960\uc740\n5.0\uc73c\ub85c \ub450\uc5c8\uc2b5\ub2c8\ub2e4. \ub9e4 \uc5d0\ud3ed\uc744 \uc9c4\ud589\ud558\uba74\uc11c \ud559\uc2b5\ub960\uc744 \uc870\uc808\ud560 \ub54c\ub294\n`StepLR <https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>`__\n\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\nfrom torchtext.data.functional import to_map_style_dataset\n# Hyperparameters\nEPOCHS = 10 # epoch\nLR = 5  # learning rate\nBATCH_SIZE = 64 # batch size for training\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\ntotal_accu = None\ntrain_iter, test_iter = AG_NEWS()\ntrain_dataset = to_map_style_dataset(train_iter)\ntest_dataset = to_map_style_dataset(test_iter)\nnum_train = int(len(train_dataset) * 0.95)\nsplit_train_, split_valid_ = \\\n    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n\ntrain_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\nvalid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                             shuffle=True, collate_fn=collate_batch)\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n    train(train_dataloader)\n    accu_val = evaluate(valid_dataloader)\n    if total_accu is not None and total_accu > accu_val:\n      scheduler.step()\n    else:\n       total_accu = accu_val\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | '\n          'valid accuracy {:8.3f} '.format(epoch,\n                                           time.time() - epoch_start_time,\n                                           accu_val))\n    print('-' * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uac00 \ub370\uc774\ud130\ub85c \ubaa8\ub378 \ud3c9\uac00\ud558\uae30\n-------------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uac00 \ub370\uc774\ud130\uc14b\uc744 \ud1b5\ud55c \uacb0\uacfc\ub97c \ud655\uc778\ud569\ub2c8\ub2e4...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Checking the results of test dataset.')\naccu_test = evaluate(test_dataloader)\nprint('test accuracy {:8.3f}'.format(accu_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc784\uc758\uc758 \ub274\uc2a4\ub85c \ud3c9\uac00\ud558\uae30\n----------------------\n\n\ud604\uc7ac\uae4c\uc9c0 \ucd5c\uace0\uc758 \ubaa8\ub378\ub85c \uace8\ud504 \ub274\uc2a4\ub97c \ud14c\uc2a4\ud2b8\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ag_news_label = {1: \"World\",\n                 2: \"Sports\",\n                 3: \"Business\",\n                 4: \"Sci/Tec\"}\n\ndef predict(text, text_pipeline):\n    with torch.no_grad():\n        text = torch.tensor(text_pipeline(text))\n        output = model(text, torch.tensor([0]))\n        return output.argmax(1).item() + 1\n\nex_text_str = \"MEMPHIS, Tenn. \u2013 Four days ago, Jon Rahm was \\\n    enduring the season\u2019s worst weather conditions on Sunday at The \\\n    Open on his way to a closing 75 at Royal Portrush, which \\\n    considering the wind and the rain was a respectable showing. \\\n    Thursday\u2019s first round at the WGC-FedEx St. Jude Invitational \\\n    was another story. With temperatures in the mid-80s and hardly any \\\n    wind, the Spaniard was 13 strokes better in a flawless round. \\\n    Thanks to his best putting performance on the PGA Tour, Rahm \\\n    finished with an 8-under 62 for a three-stroke lead, which \\\n    was even more impressive considering he\u2019d never played the \\\n    front nine at TPC Southwind.\"\n\nmodel = model.to(\"cpu\")\n\nprint(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}