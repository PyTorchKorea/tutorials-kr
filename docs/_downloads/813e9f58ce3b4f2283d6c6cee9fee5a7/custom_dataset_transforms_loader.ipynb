{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc0ac\uc6a9\uc790 \uc815\uc758 PyTorch Dataloader \uc791\uc131\ud558\uae30\n=======================================\n\n\uba38\uc2e0\ub7ec\ub2dd \uc54c\uace0\ub9ac\uc998\uc744 \uac1c\ubc1c\ud558\uae30 \uc704\ud574\uc11c\ub294 \ub370\uc774\ud130 \uc804\ucc98\ub9ac\uc5d0 \ub9ce\uc740 \ub178\ub825\uc774\n\ud544\uc694\ud569\ub2c8\ub2e4. PyTorch\ub294 \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud558\ub294\ub370 \uc27d\uace0 \uac00\ub2a5\ud558\ub2e4\uba74 \ub354 \uc88b\uc740\n\uac00\ub3c5\uc131\uc744 \uac00\uc9c4 \ucf54\ub4dc\ub97c \ub9cc\ub4e4\uae30\uc704\ud574 \ub9ce\uc740 \ub3c4\uad6c\ub4e4\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774\n\ub808\uc2dc\ud53c\uc5d0\uc11c\ub294 \ub2e4\uc74c \uc138 \uac00\uc9c0\ub97c \ubc30\uc6b8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n> 1.  PyTorch \ub370\uc774\ud130\uc14b API\ub4e4\uc744 \uc774\uc6a9\ud558\uc5ec \uc0ac\uc6a9\uc790 \uc815\uc758 \ub370\uc774\ud130\uc14b \ub9cc\ub4e4\uae30.\n> 2.  \uad6c\uc131\uac00\ub2a5\ud558\uba70 \ud638\ucd9c \ub420 \uc218 \uc788\ub294 \uc0ac\uc6a9\uc790 \uc815\uc758 transform \ub9cc\ub4e4\uae30.\n> 3.  \uc774\ub7ec\ud55c \ucef4\ud3ec\ub10c\ud2b8\ub4e4\uc744 \ud569\uccd0\uc11c \uc0ac\uc6a9\uc790 \uc815\uc758 dataloader \ub9cc\ub4e4\uae30.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud574\uc11c\ub294 \ub2e4\uc74c\uc758 \ud328\ud0a4\uc9c0\ub4e4\uc774 \uc124\uce58 \ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud574 \uc8fc\uc138\uc694.\n\n:   -   `scikit-image`: \uc774\ubbf8\uc9c0 I/O\uc640 \uc774\ubbf8\uc9c0 \ubcc0\ud615\uc5d0 \ud544\uc694\ud569\ub2c8\ub2e4.\n    -   `pandas`: CSV\ub97c \ub354 \uc27d\uac8c \ud30c\uc2f1\ud558\uae30 \uc704\ud574 \ud544\uc694\ud569\ub2c8\ub2e4.\n\n\uc791\uc131\ub418\uace0 \uc788\ub294 \uc774 \uc2dc\uc810\uc5d0\uc11c, \uc774 \ub808\uc2dc\ud53c\ub294 [Sasank\nChilamkurthy](https://chsasank.github.io) \uc758 \uc624\ub9ac\uc9c0\ub110 \ud29c\ud1a0\ub9ac\uc5bc\uc744\n\ubc14\ud0d5\uc73c\ub85c \ud558\uba70 \ub098\uc911\uc5d0\ub294 [Joe Spisak](https://github.com/jspisak) \uc5d0 \uc758\ud574\n\uc218\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud55c\uad6d\uc5b4\ub85c [Jae Joong\nLee](https://https://github.com/JaeLee18) \uc5d0 \uc758\ud574 \ubc88\uc5ed\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc124\uc815\n====\n\n\uba3c\uc800 \uc774 \ub808\uc2dc\ud53c\uc5d0 \ud544\uc694\ud55c \ubaa8\ub4e0 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub4e4\uc744 \ubd88\ub7ec\uc624\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\nimport os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\n# \uacbd\uace0 \uba54\uc2dc\uc9c0 \ubb34\uc2dc\ud558\uae30\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.ion()   # \ubc18\uc751\ud615 \ubaa8\ub4dc \uc124\uc815"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uccab \ubc88\uc9f8: \ub370\uc774\ud130\uc14b\n=================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc6b0\ub9ac\uac00 \ub2e4\ub8f0 \ub370\uc774\ud130\uc14b\uc740 \uc5bc\uad74 \ud3ec\uc988\uc785\ub2c8\ub2e4. \uc804\ubc18\uc801\uc73c\ub85c, \ud55c \uc5bc\uad74\uc5d0\ub294 68\uac1c\uc758\n\ub79c\ub4dc\ub9c8\ud06c\ub4e4\uc774 \ud45c\uc2dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ub2e4\uc74c \ub2e8\uacc4\ub85c\ub294, [\uc5ec\uae30](https://download.pytorch.org/tutorial/faces.zip)\n\uc5d0\uc11c \ub370\uc774\ud130\uc14b\uc744 \ub2e4\uc6b4 \ubc1b\uc544 \uc774\ubbf8\uc9c0\ub4e4\uc774 'data/faces/' \uc758 \uacbd\ub85c\uc5d0 \uc704\uce58\ud558\uac8c\n\ud574\uc8fc\uc138\uc694.\n\n**\uc54c\ub9bc:** \uc0ac\uc2e4 \uc774 \ub370\uc774\ud130\uc14b\uc740 imagenet \ub370\uc774\ud130\uc14b\uc5d0\uc11c 'face' \ud0dc\uadf8\ub97c\n\ud3ec\ud568\ud558\uace0 \uc788\ub294 \uc774\ubbf8\uc9c0\uc5d0 [dlib]{.title-ref} \uc758 \ud3ec\uc988 \uc608\uce21\n<https://blog.dlib.net/2014/08/real-time-face-pose-estimation.html> \uc744\n\uc801\uc6a9\ud558\uc5ec \uc0dd\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n    !wget https://download.pytorch.org/tutorial/faces.zip\n    !mkdir data/faces/\n    import zipfile\n    with zipfile.ZipFile(\"faces.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"/data/faces/\")\n    %cd /data/faces/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc74c\uacfc \uac19\uc740 \uc124\uba85\uc774 \ub2ec\ub824\uc788\ub294 CSV\ud30c\uc77c\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\n    image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y\n    0805personali01.jpg,27,83,27,98, ... 84,134\n    1084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312\n\n\uc774\uc81c CSV\ud30c\uc77c\uc744 \ube60\ub974\uac8c \uc77d\uace0 \ud30c\uc77c \uc548\uc5d0 \uc788\ub294 \uc124\uba85\ub4e4\uc740 (N, 2) \ubc30\uc5f4\ub85c\n\uc77d\uc5b4\ubd05\uc2dc\ub2e4. \uc5ec\uae30\uc11c N\uc740 \ub79c\ub4dc\ub9c8\ud06c\uc758 \uac2f\uc218\uc785\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv')\n\nn = 65\nimg_name = landmarks_frame.iloc[n, 0]\nlandmarks = landmarks_frame.iloc[n, 1:]\nlandmarks = np.asarray(landmarks)\nlandmarks = landmarks.astype('float').reshape(-1, 2)\n\nprint('Image name: {}'.format(img_name))\nprint('Landmarks shape: {}'.format(landmarks.shape))\nprint('First 4 Landmarks: {}'.format(landmarks[:4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.1 \uc774\ubbf8\uc9c0\ub97c \ud45c\uc2dc\ud558\uae30 \uc704\ud574 \uac04\ub2e8\ud55c \ub3c4\uc6c0 \ud568\uc218 \uc791\uc131\ud558\uae30\n====================================================\n\n\ub2e4\uc74c\uc73c\ub85c\ub294 \uc774\ubbf8\uc9c0\ub97c \ubcf4\uc5ec\uc8fc\uae30 \uc704\ud574 \uac04\ub2e8\ud55c \ub3c4\uc6c0 \ud568\uc218\ub97c \uc791\uc131\ud558\uc5ec \uc774\ubbf8\uc9c0\uac00\n\uac00\uc9c0\uace0 \uc788\ub294 \ub79c\ub4dc\ub9c8\ud06c\ub4e4\uacfc \uc774\ubbf8\uc9c0 \uc0d8\ud50c\uc744 \ubcf4\uc5ec\uc8fc\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_landmarks(image, landmarks):\n    \"\"\" \ub79c\ub4dc\ub9c8\ud06c\uc640 \ud568\uaed8 \uc774\ubbf8\uc9c0 \ubcf4\uc5ec\uc8fc\uae30 \"\"\"\n    plt.imshow(image)\n    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n    plt.pause(0.001)  #  \uc7a0\uc2dc \uba48\ucd94\uc5b4 \ub3c4\ud45c\uac00 \uc5c5\ub370\uc774\ud2b8 \ub418\uac8c \ud569\ub2c8\ub2e4\n\nplt.figure()\nshow_landmarks(io.imread(os.path.join('faces/', img_name)),\n               landmarks)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.2 \ub370\uc774\ud130\uc14b \ud074\ub798\uc2a4 \ub9cc\ub4e4\uae30\n==========================\n\n\uc774\uc81c PyTorch \ub370\uc774\ud130\uc14b \ud074\ub798\uc2a4\uc5d0 \ub300\ud574 \uc54c\uc544\ubd05\uc2dc\ub2e4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`torch.utils.data.Dataset` \uc740 \ucd94\uc0c1 \ud074\ub798\uc2a4\ub85c\uc11c \ub370\uc774\ud130\uc14b\uc744 \ub9e1\uace0 \uc788\uc2b5\ub2c8\ub2e4\n`Dataset` \uc744 \uc0c1\uc18d\ubc1b\uc544\uc57c \ud558\uba70 \ub2e4\uc74c\uc758 \uba54\uc18c\ub4dc\ub4e4\uc744 \uc624\ubc84\ub77c\uc774\ub4dc \ud574\uc57c\ud569\ub2c8\ub2e4.\n\n-   `__len__` \uc5d0\ub294 `len(dataset)` \ub370\uc774\ud130\uc14b\uc758 \uc0ac\uc774\uc988\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4.\n\n-   \n\n    `__getitem__` \ub294 \uc774\ub7ec\ud55c \uc778\ub371\uc2f1\uc744 \uc9c0\uc6d0\ud558\uace0 `dataset[i]`\n\n    :   $`i$\\`\u00a0\ubc88\uc9f8 \uc0d8\ud50c\uc744 \uc5bb\uae30 \uc704\ud574 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\n\uc6b0\ub9ac\uc758 \uc5bc\uad74 \ub79c\ub4dc\ub9c8\ud06c \ub370\uc774\ud130\uc14b\uc744 \uc704\ud55c \ub370\uc774\ud130\uc14b \ud074\ub798\uc2a4\ub97c \ub9cc\ub4e4\uc5b4 \ubd05\uc2dc\ub2e4.\n\uc6b0\ub9ac\ub294 csv\ud30c\uc77c\uc740 `__init__` \uc5d0\uc11c \uc77d\uace0 \uc774\ubbf8\uc9c0\ub4e4\uc740 `__getitem__` \uc5d0\uc11c\n\uc77d\ub3c4\ub85d \ub0a8\uaca8\ub450\uaca0\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubc29\ubc95\uc740 \uba54\ubaa8\ub9ac\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\ub3c4\ub85d\n\ud558\ub294\ub370 \uadf8 \uc774\uc720\ub294 \ubaa8\ub4e0 \uc774\ubbf8\uc9c0\ub97c \ud55c \ubc88\uc5d0 \uba54\ubaa8\ub9ac\uc5d0 \uc800\uc7a5\ud558\uc9c0 \uc54a\uace0 \ud544\uc694\ud560\n\ub54c\ub9c8\ub2e4 \ubd88\ub7ec\uc624\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\n\uc6b0\ub9ac \ub370\uc774\ud130\uc14b\uc758 \uc0d8\ud50c\uc740 dict \ud615\ud0dc\ub85c \uc774\ub807\uac8c\n`{'image': image, 'landmarks': landmarks}` \ub418\uc5b4\uc788\uc2b5\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b\uc740\n\uc120\ud0dd\uc801 \ub9e4\uac1c\ubcc0\uc218\uc778 `transform` \uc744 \uac00\uc9c0\uace0 \uc788\uc5b4\uc11c \ud544\uc694\ud55c \ud504\ub85c\uc138\uc2f1\n\uc5b4\ub290\uac83\uc774\ub098 \uc0d8\ud50c\uc5d0 \uc801\uc6a9 \ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4. `transform` \uc774 \uc5bc\ub9c8\ub098 \uc720\uc6a9\ud55c\uc9c0\ub294\n\ub2e4\ub978 \ub808\uc2dc\ud53c\uc5d0\uc11c \ud655\uc778 \ud574 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class FaceLandmarksDataset(Dataset):\n    \"\"\" \uc5bc\uad74 \ub79c\ub4dc\ub9c8\ud06c \ub370\uc774\ud130\uc14b. \"\"\"\n\n    def __init__(self, csv_file, root_dir, transform=None):\n        \"\"\"\n        \ub9e4\uac1c\ubcc0\uc218 :\n            csv_file (\ubb38\uc790\uc5f4): \uc124\uba85\uc774 \ud3ec\ud568\ub41c csv \ud30c\uc77c \uacbd\ub85c. \n            root_dir (\ubb38\uc790\uc5ed): \ubaa8\ub4e0 \uc774\ubbf8\uc9c0\uac00 \uc788\ub294 \ud3f4\ub354 \uacbd\ub85c.\n            transform (\ud638\ucd9c\uac00\ub2a5\ud55c \ud568\uc218, \uc120\ud0dd\uc801 \ub9e4\uac1c\ubcc0\uc218): \uc0d8\ud50c\uc5d0 \uc801\uc6a9 \ub420 \uc218 \uc788\ub294 \uc120\ud0dd\uc801 \ubcc0\ud658.\n        \"\"\"\n        self.landmarks_frame = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.landmarks_frame)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,\n                                self.landmarks_frame.iloc[idx, 0])\n        image = io.imread(img_name)\n        landmarks = self.landmarks_frame.iloc[idx, 1:]\n        landmarks = np.array([landmarks])\n        landmarks = landmarks.astype('float').reshape(-1, 2)\n        sample = {'image': image, 'landmarks': landmarks}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.3 \ubc18\ubcf5\ubb38\uc744 \ud1b5\ud55c \ub370\uc774\ud130 \uc0d8\ud50c \uc0ac\uc6a9\n==================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e4\uc74c\uc73c\ub85c\ub294 \uc774 \ud074\ub798\uc2a4\ub97c \uc778\uc2a4\ud134\uc2a4\ud654\ud558\uace0 \ub370\uc774\ud130 \uc0d8\ud50c\uc744 \ubc18\ubcf5\ubb38\uc744 \uc774\uc6a9\ud558\uc5ec\n\uc0ac\uc6a9\ud574\ubd05\uc2dc\ub2e4. \uc6b0\ub9ac\ub294 \uccab 4\uac1c\uc758 \uc0d8\ud50c\ub4e4\ub9cc \ucd9c\ub825\ud558\uace0 \uadf8 4\uac1c \uc0d8\ud50c\ub4e4\uc758\n\ub79c\ub4dc\ub9c8\ud06c\ub97c \ubcf4\uc5ec\uc8fc\uaca0\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "face_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv',\n                                    root_dir='faces/')\n\nfig = plt.figure()\n\nfor i in range(len(face_dataset)):\n    sample = face_dataset[i]\n\n    print(i, sample['image'].shape, sample['landmarks'].shape)\n\n    ax = plt.subplot(1, 4, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{}'.format(i))\n    ax.axis('off')\n    show_landmarks(**sample)\n\n    if i == 3:\n        plt.show()\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub450 \ubc88\uc9f8: \ub370\uc774\ud130 \ubcc0\ud615\n====================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc6b0\ub9ac\ub294 \uc9c0\uae08\uae4c\uc9c0 \uc5b4\ub290\uc815\ub3c4 \uc0ac\uc6a9\uc790 \uc815\uc758 \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4e4\uc5b4 \ubcf4\uc558\ub294\ub370 \uc774\uc81c\ub294\n\uc0ac\uc6a9\uc790 \uc815\uc758 \ubcc0\ud615\uc744 \ub9cc\ub4e4 \ucc28\ub840 \uc785\ub2c8\ub2e4. \ucef4\ud4e8\ud130 \ube44\uc804\uc5d0\uc11c\ub294 \uc0ac\uc6a9\uc790 \uc815\uc758\n\ubcc0\ud615\uc740 \uc54c\uace0\ub9ac\uc998\uc744 \uc77c\ubc18\ud654\uc2dc\ud0a4\uace0 \uc815\ud655\ub3c4\ub97c \uc62c\ub9ac\ub294\ub370 \ub3c4\uc6c0\uc744 \uc90d\ub2c8\ub2e4. \ubcc0\ud615\ub4e4\uc740\n\ud6c8\ub828\uc2dc\uc5d0 \uc0ac\uc6a9\uc774 \ub418\uba70 \uc8fc\ub85c \ub370\uc774\ud130 \uc99d\uac15\uc73c\ub85c \ucc38\uc870\ub418\uba70 \ucd5c\uadfc\uc758 \ubaa8\ub378 \uac1c\ubc1c\uc5d0\uc120\n\ud754\ud788 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\n\ub370\uc774\ud130\uc14b\uc744 \ub2e4\ub8f0\ub54c \uc790\uc8fc \uc77c\uc5b4\ub098\ub294 \ubb38\uc81c\uc911 \ud558\ub098\ub294 \ubaa8\ub4e0 \uc0d8\ud50c\ub4e4\uc774 \uac19\uc740 \ud06c\uae30\ub97c\n\uac00\uc9c0\uace0 \uc788\uc9c0 \uc54a\uc744 \uacbd\uc6b0\uc785\ub2c8\ub2e4. \ub300\ubd80\ubd84\uc758 \uc2e0\uacbd\ub9dd\ub4e4\uc740 \ubbf8\ub9ac \uc815\ud574\uc9c4 \ud06c\uae30\uc758\n\uc774\ubbf8\uc9c0\ub4e4\uc744 \ubc1b\uc544\ub4e4\uc785\ub2c8\ub2e4. \uadf8\ub807\uae30 \ub54c\ubb38\uc5d0 \uc6b0\ub9ac\ub294 \uc804\ucc98\ub9ac \ucf54\ub4dc\ub97c \uc791\uc131\ud574\uc57c\ud560\n\ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uc81c \uc138\uac1c\uc758 \ubcc0\ud615\uc744 \ub9cc\ub4e4\uc5b4 \ubd05\uc2dc\ub2e4.\n\n-   `Rescale`: \uc774\ubbf8\uc9c0 \ud06c\uae30\ub97c \ubcc0\uacbd\ud560\ub54c \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n-   `RandomCrop`: \ubb34\uc791\uc704\ub85c \uc774\ubbf8\uc9c0\ub97c \uc798\ub77c\ub0b4\uba70 \ub370\uc774\ud130 \uc99d\uac15\uc5d0 \uc4f0\uc785\ub2c8\ub2e4.\n-   `ToTensor`: Numpy \uc774\ubbf8\uc9c0\ub4e4\uc744 \ud30c\uc774\ud1a0\uce58 \uc774\ubbf8\uc9c0\ub85c \ubcc0\ud658\ud560\ub54c \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n    (\uadf8\ub7ec\uae30 \uc704\ud574\uc11c\ub294 \uc774\ubbf8\uc9c0 \ucc28\uc6d0\uc758 \uc21c\uc11c\ub97c \ubc14\uafd4\uc57c\ud569\ub2c8\ub2e4.)\n\n\uc6b0\ub9ac\ub294 \uc704\uc758 \uc138\uac1c\uc758 \ubcc0\ud615\ub4e4\uc744 \ub2e8\uc21c\ud55c \ud568\uc218 \ub300\uc2e0\uc5d0 \ud638\ucd9c\uac00\ub2a5\ud55c \ud074\ub798\uc2a4\ub85c\n\ub9cc\ub4e4\uc5b4\uc11c \ub9e4\ubc88 \ubcc0\ud615\uc774 \ud638\ucd9c\ub420\ub54c \ud56d\uc0c1 \ub9e4\uac1c\ubcc0\uc218\uac00 \ub118\uaca8\uc9c0\uc9c0 \uc54a\ub3c4\ub85d \ud560\uac81\ub2c8\ub2e4.\n\uadf8\ub7ec\uae30 \uc704\ud574\uc11c\ub294 \uc6b0\ub9ac\ub294 \ub2e8\uc21c\ud788 `__call__` \uba54\uc18c\ub4dc\ub97c \ub9cc\ub4e4\uace0 \ud544\uc694\ud558\ub2e4\uba74\n`__init__` \ub97c \ub9cc\ub4e4\uba74 \ub429\ub2c8\ub2e4. \uadf8\ub7ec\uba74 \uc6b0\ub9ac\ub294 \ubcc0\ud615\uc744 \uc774\ub7f0\uc2dd\uc73c\ub85c \uc0ac\uc6a9\ud560 \uc218\n\uc788\uc2b5\ub2c8\ub2e4.\n\n    tsfm = Transform(params)\n    transformed_sample = tsfm(sample)\n\n\uc5b4\ub5bb\uac8c \uc774\ub7f0 \ubcc0\ud615\ub4e4\uc774 \uc774\ubbf8\uc9c0\uc640 \ub79c\ub4dc\ub9c8\ud06c\uc5d0 \uc801\uc6a9\uc774 \ub418\uc5c8\ub294\uc9c0 \uc544\ub798\ub97c \ubd10\uc8fc\uc2dc\uae38\n\ubc14\ub78d\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.1 \ud638\ucd9c \uac00\ub2a5\ud55c \ud074\ub798\uc2a4\ub4e4 \uc791\uc131\ud558\uae30\n=================================\n\n\uac01\uac01\uc758 \ubcc0\ud615\uc5d0 \ub9de\ub294 \ud638\ucd9c \uac00\ub2a5\ud55c \ud074\ub798\uc2a4 \uc791\uc131\uc744 \uc2dc\uc791\ud574 \ubd05\uc2dc\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Rescale(object):\n    \"\"\" \uc8fc\uc5b4\uc9c4 \ud06c\uae30\ub85c \uc0d8\ud50c\uc548\uc5d0 \uc788\ub294 \uc774\ubbf8\uc9c0\ub97c \uc7ac\ubcc0\ud658 \ud569\ub2c8\ub2e4.\n\n    Args:\n        output_size (tuple \ub610\ub294 int): \uc6d0\ud558\ub294 \uacb0\uacfc\uac12\uc758 \ud06c\uae30\uc785\ub2c8\ub2e4.\n        tuple\ub85c \uc8fc\uc5b4\uc9c4\ub2e4\uba74 \uacb0\uacfc\uac12\uc740 output_size \uc640 \ub3d9\uc77c\ud574\uc57c\ud558\uba70\n        int\uc77c\ub54c\ub294 \uc124\uc815\ub41c \uac12\ubcf4\ub2e4 \uc791\uc740 \uc774\ubbf8\uc9c0\ub4e4\uc758 \uac00\ub85c\uc640 \uc138\ub85c\ub294 output_size \uc5d0 \uc801\uc808\ud55c \ube44\uc728\ub85c \ubcc0\ud658\ub429\ub2c8\ub2e4.\n    \"\"\"\n\n    def __init__(self, output_size):\n        assert isinstance(output_size, (int, tuple))\n        self.output_size = output_size\n\n    def __call__(self, sample):\n        image, landmarks = sample['image'], sample['landmarks']\n\n        h, w = image.shape[:2]\n        if isinstance(self.output_size, int):\n            if h > w:\n                new_h, new_w = self.output_size * h / w, self.output_size\n            else:\n                new_h, new_w = self.output_size, self.output_size * w / h\n        else:\n            new_h, new_w = self.output_size\n\n        new_h, new_w = int(new_h), int(new_w)\n\n        img = transform.resize(image, (new_h, new_w))\n\n        # h \uc640 w  \ub294 \uc774\ubbf8\uc9c0\uc758 \ub79c\ub4dc\ub9c8\ud06c\ub4e4 \ub54c\ubb38\uc5d0 \uc11c\ub85c \ubc14\ub01d\ub2c8\ub2e4.\n        # x \uc640 y \ucd95\ub4e4\uc740 \uac01\uac01 1\uacfc 0 \uac12\uc744 \uac00\uc9d1\ub2c8\ub2e4.\n        landmarks = landmarks * [new_w / w, new_h / h]\n\n        return {'image': img, 'landmarks': landmarks}\n\n\nclass RandomCrop(object):\n    \"\"\" \uc0d8\ud50c\uc5d0 \uc788\ub294 \uc774\ubbf8\uc9c0\ub97c \ubb34\uc791\uc704\ub85c \uc790\ub974\uae30.\n\n    Args:\n        output_size (tuple \ub610\ub294 int): \uc6d0\ud558\ub294 \uacb0\uacfc\uac12\uc758 \ud06c\uae30\uc785\ub2c8\ub2e4.\n        int\ub85c \uc124\uc815\ud558\uc2dc\uba74 \uc815\uc0ac\uac01\ud615 \ud615\ud0dc\ub85c \uc790\ub974\uac8c \ub429\ub2c8\ub2e4.\n    \"\"\"\n\n    def __init__(self, output_size):\n        assert isinstance(output_size, (int, tuple))\n        if isinstance(output_size, int):\n            self.output_size = (output_size, output_size)\n        else:\n            assert len(output_size) == 2\n            self.output_size = output_size\n\n    def __call__(self, sample):\n        image, landmarks = sample['image'], sample['landmarks']\n\n        h, w = image.shape[:2]\n        new_h, new_w = self.output_size\n\n        top = np.random.randint(0, h - new_h)\n        left = np.random.randint(0, w - new_w)\n\n        image = image[top: top + new_h,\n                      left: left + new_w]\n\n        landmarks = landmarks - [left, top]\n\n        return {'image': image, 'landmarks': landmarks}\n\n\nclass ToTensor(object):\n    \"\"\" \uc0d8\ud50c \uc548\uc5d0 \uc788\ub294 n\ucc28\uc6d0 \ubc30\uc5f4\uc744 Tensor\ub85c \ubcc0\ud665\ud799\ub2c8\ub2e4. \"\"\"\n\n    def __call__(self, sample):\n        image, landmarks = sample['image'], sample['landmarks']\n\n        # \uc0c9\uae54 \ucd95\ub4e4\uc744 \ubc14\uafd4\uce58\uae30\ud574\uc57c\ud558\ub294\ub370 \uadf8 \uc774\uc720\ub294 numpy\uc640 torch\uc758 \uc774\ubbf8\uc9c0 \ud45c\ud604\ubc29\uc2dd\uc774 \ub2e4\ub974\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n        # numpy \uc774\ubbf8\uc9c0: H x W x C\n        # torch \uc774\ubbf8\uc9c0: C X H X W\n        image = image.transpose((2, 0, 1))\n        return {'image': torch.from_numpy(image),\n                'landmarks': torch.from_numpy(landmarks)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2 \ubcc0\ud658\ub4e4\uc744 \uad6c\uc131\ud558\uace0 \uc0d8\ud50c\uc5d0 \uc801\uc6a9\ud574\ubcf4\uae30.\n========================================\n\n\ub2e4\uc74c\uc5d0\ub294 \uc791\uc131\ud574\uc654\ub358 \ubcc0\ud658\ub4e4\uc744 \uad6c\uc131\ud558\uace0 \uc0d8\ud50c\uc5d0 \uc801\uc6a9\ud574\ubd05\uc2dc\ub2e4.\n\n\uc6b0\ub9ac\uac00 \ud55c \uc774\ubbf8\uc9c0\uc758 \uac00\ub85c\ub098 \uc138\ub85c\uc911\uc5d0\uc11c \ub354\uc791\uc740 \ucabd\uc744 256\uc73c\ub85c \ud06c\uae30\ub97c\n\ubc14\uafb8\uace0\uc2f6\uace0 \ubc14\ub010 \uc774\ubbf8\uc9c0\uc5d0\uc11c \ubb34\uc791\uc704\ud558\uac8c \uac00\ub85c \uc138\ub85c \uc804\ubd80 224\ub85c \uc790\ub974\uace0 \uc2f6\ub2e4\uace0\n\uc0c1\ud669\uc744 \uac00\uc815\ud574\ubd05\uc2dc\ub2e4. \uc608\ub97c\ub4e4\uba74, \uc6b0\ub9ac\ub294 `Rescale` \uacfc `RandomCrop` \ubcc0\ud658\uc744\n\uad6c\uc131\ud574\uc57c \ud569\ub2c8\ub2e4. `torchvision.transforms.Compose` \ub294 \uac04\ub2e8\ud55c \ud638\ucd9c\uac00\ub2a5\ud55c\n\ud074\ub798\uc2a4\ub85c \uc774\ub7ec\ud55c\uac83\ub4e4\uc744 \uc6b0\ub9ac\uc5d0\uac8c \uac00\ub2a5\ud558\uac8c \ud574\uc90d\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scale = Rescale(256)\ncrop = RandomCrop(128)\ncomposed = transforms.Compose([Rescale(256),\n                               RandomCrop(224)])\n\n# \uc704\uc5d0 \uc788\ub294 \ubcc0\ud658\ub4e4\uc744 \uac01\uac01 \uc0d8\ud50c\uc5d0 \uc801\uc6a9 \uc2dc\ud0b5\ub2c8\ub2e4.\nfig = plt.figure()\nsample = face_dataset[65]\nfor i, tsfrm in enumerate([scale, crop, composed]):\n    transformed_sample = tsfrm(sample)\n\n    ax = plt.subplot(1, 3, i + 1)\n    plt.tight_layout()\n    ax.set_title(type(tsfrm).__name__)\n    show_landmarks(**transformed_sample)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.3 \ub370\uc774\ud130\uc14b\uc744 \ubc18\ubcf5\ubb38\uc744 \ud1b5\ud574 \uc0ac\uc6a9\ud558\uae30\n=====================================\n\n\ub2e4\uc74c\uc73c\ub85c \uc6b0\ub9ac\ub294 \ub370\uc774\ud130\uc14b\uc744 \ubc18\ubcf5\ubb38\uc744 \ud1b5\ud574 \uc0ac\uc6a9\ud574\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc774\uc81c \uc774 \ubaa8\ub4e0\uac83\uc744 \ub2e4 \uaebc\ub0b4\uc5b4\uc11c \ubcc0\ud658\uc744 \uad6c\uc131\ud558\uace0 \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4.\n\uc694\uc57d\ud558\uc790\uba74 \ud56d\uc0c1 \uc774 \ub370\uc774\ud130\uc14b\uc744 \ub2e4\uc74c\uacfc \uac19\uc774 \ubd88\ub7ec\uc640\uc9d1\ub2c8\ub2e4.\n\n-   \uc774\ubbf8\uc9c0\ub294 \uc77d\uc73c\ub824\uace0 \ud560\ub54c\ub9c8\ub2e4 \ubd88\ub7ec\uc635\ub2c8\ub2e4.\n-   \ubcc0\ud615\ub4e4\uc740 \uc77d\uc740 \uc774\ubbf8\uc9c0\uc5d0 \uc801\uc6a9\uc774 \ub429\ub2c8\ub2e4.\n-   \ubcc0\ud615\ub4e4\uc911 \ud558\ub098\ub294 \ubb34\uc791\uc704\ub97c \uc774\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0, \ub370\uc774\ud130\ub294 \uc0d8\ud50c\ub9c1\uc5d0 \ub530\ub77c\n    \uc99d\uac15\ub429\ub2c8\ub2e4.\n\n\uc800\ubc88\uc5d0 \ud574\ubcf8\uac83\ucc98\ub7fc \uc0dd\uc131\ub41c \ub370\uc774\ud130\uc14b\uc744 `for i in range` \uc774\ub77c\ub294 \ubc18\ubcf5\ubb38\uc744\n\ud1b5\ud574 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transformed_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv',\n                                           root_dir='faces/',\n                                           transform=transforms.Compose([\n                                               Rescale(256),\n                                               RandomCrop(224),\n                                               ToTensor()\n                                           ]))\n\nfor i in range(len(transformed_dataset)):\n    sample = transformed_dataset[i]\n\n    print(i, sample['image'].size(), sample['landmarks'].size())\n\n    if i == 3:\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc138\ubc88\uc9f8: Dataloader\n==================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc9c1\uc811\uc801\uc73c\ub85c \ub370\uc774\ud130\uc14b\uc744 `for` \ubc18\ubcf5\ubb38\uc73c\ub85c \ub370\uc774\ud130\ub97c \uc774\uc6a9\ud558\ub294\uac74 \ub9ce\uc740 \ud2b9\uc131\ub4e4\uc744\n\ub193\uce60 \uc218 \ubc16\uc5d0 \uc5c6\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \uc6b0\ub9ac\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \ud2b9\uc131\ub4e4\uc744 \ub193\uce5c\ub2e4\uace0 \ud560 \uc218\n\uc788\uc2b5\ub2c8\ub2e4.\n\n-   \ub370\uc774\ud130 \ubc30\uce58\n-   \ub370\uc774\ud130 \uc11e\uae30\n-   `multiprocessing` \ub97c \uc774\uc6a9\ud558\uc5ec \ubcd1\ub82c\uc801\uc73c\ub85c \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\n\n`torch.utils.data.DataLoader` \ub294 \ubc18\ubcf5\uc790\ub85c\uc11c \uc704\uc5d0 \ub098\uc640\uc788\ub294 \ubaa8\ub4e0 \ud2b9\uc131\ub4e4\uc744\n\uc81c\uacf5\ud569\ub2c8\ub2e4. \uc544\ub798\uc5d0 \uc81c\uc2dc\ub41c \uc0ac\uc6a9\ub418\ub294 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc740 \uc27d\uac8c \uc774\ud574\uac00 \ub420\uac81\ub2c8\ub2e4.\n\ud765\ubbf8\ub85c\uc6b4 \ubc30\uac1c\ubcc0\uc218\ub294 `collate_fn` \uc778\ub370 \uc774\uac83\uc740 \uc815\ud655\ud558\uac8c `collate_fn` \uc744\n\ud1b5\ud574 \uba87\uac1c\uc758 \uc0d8\ud50c\ub4e4\uc774 \ubc30\uce58\uac00 \ub418\uc5b4\uc57c\ud558\ub294\uc9c0 \uc9c0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uad73\uc774\n\uc218\uc815\ud558\uc9c0 \uc54a\uc544\ub3c4 \ub300\ubd80\ubd84\uc758 \uacbd\uc6b0\uc5d0\ub294 \uc798 \uc791\ub3d9\ud560\uac81\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(transformed_dataset, batch_size=4,\n                        shuffle=True, num_workers=4)\n\n\n# \ubc30\uce58\ub97c \ubcf4\uc5ec\uc8fc\uae30\uc704\ud55c \ub3c4\uc6c0 \ud568\uc218\ndef show_landmarks_batch(sample_batched):\n    \"\"\" \uc0d8\ud50c\ub4e4\uc758 \ubc30\uce58\uc5d0\uc11c \uc774\ubbf8\uc9c0\uc640 \ud568\uaed8 \ub79c\ub4dc\ub9c8\ud06c\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4. \"\"\"\n    images_batch, landmarks_batch = \\\n            sample_batched['image'], sample_batched['landmarks']\n    batch_size = len(images_batch)\n    im_size = images_batch.size(2)\n\n    grid = utils.make_grid(images_batch)\n    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n\n    for i in range(batch_size):\n        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size,\n                    landmarks_batch[i, :, 1].numpy(),\n                    s=10, marker='.', c='r')\n\n        plt.title('Batch from dataloader')\n\nfor i_batch, sample_batched in enumerate(dataloader):\n    print(i_batch, sample_batched['image'].size(),\n          sample_batched['landmarks'].size())\n\n    # 4\ubc88\uc9f8 \ubc30\uce58\ub97c \ubcf4\uc5ec\uc8fc\uace0 \ubc18\ubcf5\ubb38\uc744 \uba48\ucda5\ub2c8\ub2e4.\n    if i_batch == 3:\n        plt.figure()\n        show_landmarks_batch(sample_batched)\n        plt.axis('off')\n        plt.ioff()\n        plt.show()\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c PyTorch\ub97c \uc774\uc6a9\ud574\uc11c \uc5b4\ub5bb\uac8c \uc0ac\uc6a9\uc790 \uc815\uc758 dataloader\ub97c \ub9cc\ub4dc\ub294\uc9c0\n\ubc30\uc6e0\uc2b5\ub2c8\ub2e4. \uc800\ud76c\ub294 \uc880 \ub354 \uad00\ub828\ub41c \ubb38\uc11c\ub4e4\uc744 \uae4a\uac8c \uc77d\uc73c\uc154\uc11c \ub354\uc6b1 \ub9de\ucda4\ud654\ub41c\n\uc791\uc5c5 \ud750\ub9bc\uc744 \uac00\uc9c0\uae38 \ucd94\ucc9c \ub4dc\ub9bd\ub2c8\ub2e4. \ub354 \ubc30\uc6cc\ubcf4\uc2dc\ub824\uba74 `torch.utils.data`\n\ubb38\uc11c\ub97c [\uc5ec\uae30](https://pytorch.org/docs/stable/data.html) \uc5d0\uc11c \uc77d\uc5b4 \ubcf4\uc2e4\n\uc218 \uc788\uc2b5\ub2c8\ub2e4.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}