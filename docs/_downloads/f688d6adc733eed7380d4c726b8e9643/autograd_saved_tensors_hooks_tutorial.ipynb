{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \ubbf8\ubd84 \uc790\ub3d9\ud654(autograd)\uc5d0\uc11c \uc800\uc7a5\ub41c tensor\ub97c \uc704\ud55c Hooks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud30c\uc774\ud1a0\uce58\ub294 \uc77c\ubc18\uc801\uc73c\ub85c \uc5ed\uc804\ud30c\ub97c \ud1b5\ud574 \uae30\uc6b8\uae30\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\uadf8\ub7ec\ub098 \ud2b9\uc815 \uc791\uc5c5\uc5d0\uc11c\ub294 \uc5ed\uc804\ud30c\ub97c \uc218\ud589\ud558\uae30 \uc704\ud55c \uc911\uac04\uacb0\uacfc\ub97c \uc800\uc7a5\ud574\uc57c \ud569\ub2c8\ub2e4.\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \uc774\ub7ec\ud55c tensor\ub97c \uc800\uc7a5/\uac80\uc0c9\ud558\ub294 \ubc29\ubc95\uacfc\n\ud328\ud0b9/\uc5b8\ud328\ud0b9 \uc808\ucc28\ub97c \uc81c\uc5b4\ud558\ub294 hooks\uc744 \uc815\uc758\ud558\ub294 \ubc29\ubc95\uc744 \uc548\ub0b4\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \ub3c5\uc790\uac00 \uc5ed\uc804\ud30c\uac00 \uc5b4\ub5bb\uac8c \ub3d9\uc791\ud558\ub294\uc9c0\ub97c \uc774\ub860\uc801\uc73c\ub85c \uc798 \uc54c\uace0 \uc788\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4.\n# \uc544\ub2c8\ub77c\uba74, `\uc774\uac83 <https://colab.research.google.com/drive/1aWNdmYt7RcHMbUk-Xz2Cv5-cGFSWPXe0#scrollTo=AHcEJ6nXUb7W>`_ \uc744 \uba3c\uc800 \uc77d\uc5b4\ubcf4\uc138\uc694.\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc800\uc7a5\ub41c tensor\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc77c\ubc18\uc801\uc73c\ub85c \ubaa8\ub378\uc744 \ucd94\ub860\ud558\ub294 \uac83\ubcf4\ub2e4 \ud559\uc2b5\ud558\ub294 \uacfc\uc815\uc5d0\uc11c \uba54\ubaa8\ub9ac\ub97c \ub354 \ub9ce\uc774 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\ub300\ub7b5\uc801\uc73c\ub85c \ub9d0\ud558\uba74 \ud30c\uc774\ud1a0\uce58\ub294 \uc5ed\uc804\ud30c\ub97c \ud638\ucd9c\ud558\ub294\ub370 \ud544\uc694\ud55c \uacc4\uc0b0 \uadf8\ub798\ud504\ub97c \uc800\uc7a5\ud574\uc57c\ud558\ubbc0\ub85c\n\ucd94\uac00 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \ubaa9\ud45c \uc911 \ud558\ub098\ub294 \uc774\ub7f0 \ub0b4\uc6a9\uc744 \uc774\ud574\uc640 \ubbf8\uc138 \uc870\uc815\uc744 \uc81c\uacf5\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\uc2e4\uc81c\ub85c \ub54c\ub54c\ub85c (\uc5f0\uc0b0) \uadf8\ub798\ud504 \uc790\uccb4\ub294 tensor\ub4e4\uc744 \uc804\ud600 \ubcf5\uc81c\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \ub9ce\uc740 \uba54\ubaa8\ub9ac\ub97c \uc18c\ubaa8\ud558\uc9c0\ub294 \uc54a\uc2b5\ub2c8\ub2e4.\n\ud558\uc9c0\ub9cc, \uadf8\ub798\ud504\ub294 \ubc94\uc704\uc5d0\uc11c \ubc97\uc5b4\ub09c tensor\ub4e4\uc5d0 \ub300\ud55c *\ucc38\uc870(reference)* \ub294 \uc720\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\ub7ec\ud55c tensor\ub4e4\uc744 **\uc800\uc7a5\ub41c tensor(saved tensor)** \ub77c\uace0 \ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (\uc77c\ubc18\uc801\uc73c\ub85c) \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\ub294\ub370 \ud3c9\uac00\ubcf4\ub2e4 \ub354 \ub9ce\uc740 \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud558\ub294 \uc774\uc720\ub294 \ubb34\uc5c7\uc77c\uae4c\uc694?\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uac04\ub2e8\ud55c \uc608\uc81c\ub97c \uc2dc\uc791\ud574\ubd05\uc2dc\ub2e4: $y = a \\cdot b$, \ubcc0\ud654\ub3c4\ub97c \uc54c\uace0\uc788\ub294 :math: `y`,\ub85c \uac01\uac01 :math: `a` and\n:math: `b`:\ub85c \ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# .. math::  \\frac{\\partial y}{\\partial a} = b\n# .. math::  \\frac{\\partial y}{\\partial b} = a\n\n\nimport torch\n\na = torch.randn(5, requires_grad=True)\nb = torch.ones(5, requires_grad=True)\ny = a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "torchviz\ub97c \uc0ac\uc6a9\ud574\uc11c, \uacc4\uc0b0\uadf8\ub798\ud504\ub97c \uc2dc\uac01\ud654 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n.. figure:: https://user-images.githubusercontent.com/8019486/130124513-72e016a3-c36f-42b9-88e2-53baf3e016c5.png\n  :width: 300\n  :align: center\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \uc608\uc81c\uc5d0\uc11c \ud30c\uc774\ud1a0\uce58\ub294 \uc911\uac04 \uac12 :math: `a` \ubc0f :math: `b` \ub97c \uc800\uc7a5\ud558\uc5ec\n\uc5ed\ubc29\ud5a5 \ub3d9\uc548 \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\n.. figure:: https://user-images.githubusercontent.com/8019486/130124538-3da50977-6f0b-46d0-8909-5456ade9b598.png\n  :width: 300\n  :align: center\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\ub7ec\ud55c \uc911\uac04 \uac12(\uc704\uc758 \uc8fc\ud669\uc0c9)\uc740 \uc811\ub450\uc0ac ``_saved``\ub85c \uc2dc\uc791\ud558\ub294\n``y``\uc758 ``grad_fn`` \uc18d\uc131\uc744 \ucc3e\uc544 (\ub514\ubc84\uae45 \ubaa9\uc801\uc73c\ub85c) \uc811\uadfc \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(y.grad_fn._saved_self)\nprint(y.grad_fn._saved_other)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacc4\uc0b0 \uadf8\ub798\ud504\uac00 \uae4a\uc5b4\uc9c8\uc218\ub85d *\uc800\uc7a5\ub41c tensor*\uac00 \ub354 \ub9ce\uc774 \uc800\uc7a5\ub429\ub2c8\ub2e4.\n\ud55c\ud3b8, tensor\ub294 \uadf8\ub798\ud504\uac00 \uc544\ub2c8\uc5c8\ub2e4\uba74 \ubc94\uc704\ub97c \ubc97\uc5b4\ub098\uac8c \ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def f(x):\n    return x * x\n\nx = torch.randn(5, requires_grad=True)\ny = f(f(f(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. figure :: https://user-images.githubusercontent.com/8019486/130124570-f1074098-1bb3-459e-bf5a-03bf6f65b403.png\n   :width: 500\n   :align: center\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc704\uc758 \uc608\uc81c\uc5d0\uc11c \ubbf8\ubd84(grad)\uc5c6\uc774 \uc2e4\ud589\ud558\uba74 \ubc94\uc704\ub0b4\uc758 ``x`` \uc640 ``y`` \ub294 \uc720\uc9c0\ub418\uc9c0\ub9cc\n\uadf8\ub798\ud504\uc5d0\uc11c\ub294 ``f(x)`` \uc640 ``f(f(x))`` \uac00 \ucd94\uac00\ub85c \uc800\uc7a5\ub429\ub2c8\ub2e4.\n\ub530\ub77c\uc11c \ud6c8\ub828 \uc911 \uc815\ubc29\ud5a5 \uacbd\ub85c\ub97c \uc2e4\ud589\ud558\uba74 \ud3c9\uac00\uc911\uc5d0\n(\ub354 \uc815\ud655\ud558\uac8c\ub294 \uc790\ub3d9\ubbf8\ubd84(auto grad)\uac00 \ud544\uc694\ud558\uc9c0 \uc54a\uc740 \uacbd\uc6b0\ubcf4\ub2e4)\n\uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc774 \ub354 \ub9ce\uc544\uc9c0\uac8c \ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud328\ud0b9\uacfc \uc5b8\ud328\ud0b9\uc758 \uac1c\ub150\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uccab \ubc88\uc9f8 \uc608\uc81c\ub85c \ub3cc\uc544\uac00\uc11c ``y.grad_fn._saved_self`` \uc640 ``y.grad_fn._saved_other`` \ub294\n\uac01\uac01 \uc6d0\ub798 tensor \uac1d\uccb4 ``a`` \uc640 ``b`` \ub97c \uac00\ub9ac\ud0b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = torch.randn(5, requires_grad=True)\nb = torch.ones(5, requires_grad=True)\ny = a * b\n\nprint(y.grad_fn._saved_self is a)   # True\nprint(y.grad_fn._saved_other is b)  # True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uadf8\ub7ec\ub098 \uc774\uac83\uc740 \ud56d\uc0c1 \uac19\uc740 \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = torch.randn(5, requires_grad=True)\ny = torch.exp(a)\nprint(y.grad_fn._saved_result.equal(y))  # True\nprint(y.grad_fn._saved_result is y)      # False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub0b4\ubd80\uc801\uc73c\ub85c\ub294 \ud30c\uc774\ud1a0\uce58\ub294 \ucc38\uc870\uc8fc\uae30\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud574\uc11c tensor ``y`` \ub97c\n**\ud328\ud0b9** \ubc0f **\uc5b8\ud328\ud0b9** \ud588\uc2b5\ub2c8\ub2e4\n\uacbd\ud5d8\uc0c1, \uc5ed\uc804\ud30c \uc800\uc7a5\ub41c tensor\uc5d0 \uc5d1\uc138\uc2a4\ud558\uba74 \uc6d0\ub798 tensor\uc640\n\ub3d9\uc77c\ud55c tensor\uc758 \uac1d\uccb4\uac00 \uc0dd\uc131\ub41c\ub2e4\ub294 \uacb0\uacfc\ub97c \uae30\ub300\ud574\uc11c\ub294 *\uc548\ub429\ub2c8\ub2e4*.\n\uadf8\ub7ec\ub098 tensor\ub294 \ub3d9\uc77c\ud55c *\uc800\uc7a5\uc18c*\ub97c \uacf5\uc720\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc800\uc7a5\ub41c tensor hooks\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud30c\uc774\ud1a0\uce58\ub294 tensor\ub4e4\uc774 \uc5b4\ub5bb\uac8c \ud328\ud0b9\ub418\uace0 \uc5b8\ud328\ud0b9\ub418\ub294\uc9c0\n\uc800\uc7a5\ud560 \uc218 \uc788\ub294 \uc81c\uc5b4 \uac00\ub2a5\ud55c API\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def pack_hook(x):\n    print(\"Packing\", x)\n    return x\n\ndef unpack_hook(x):\n    print(\"Unpacking\", x)\n    return x\na = torch.ones(5, requires_grad=True)\nb = torch.ones(5, requires_grad=True) * 2\n\nwith torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):\n    y = a * b\n\ny.sum().backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``pack_hook`` \ud568\uc218\ub294 \uc791\uc5c5\uc774 \uc5ed\uc804\ud30c\ub97c \uc704\ud574 tensor\ub97c \uc800\uc7a5\ud560 \ub54c \ub9c8\ub2e4 \ud638\ucd9c\ub429\ub2c8\ub2e4. \uadf8\ub7ec\uba74\n``pack_hook`` \uc758 \ucd9c\ub825\uc774 \uc6d0\ub798 tensor \ub300\uc2e0 \uacc4\uc0b0 \uadf8\ub798\ud504\uc5d0 \uc800\uc7a5\ub429\ub2c8\ub2e4.\n``unpack_hook`` \uc740 \ud574\ub2f9 \ubc18\ud658 \uac12\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc5ed\ubc29\ud5a5 \uc804\ub2ec \uc911\uc5d0 \uc2e4\uc81c\ub85c \uc0ac\uc6a9\ub41c tensor\ub97c \uc0c8 tensor\ub85c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\uc77c\ubc18\uc801\uc73c\ub85c ``unpack_hook(pack_hook(t))`` \uac00 ``t`` \uc640 \uac19\uae38 \uae30\ub300\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.randn(5, requires_grad=True)\nwith torch.autograd.graph.saved_tensors_hooks(lambda x: x * 4, lambda x: x / 4):\n    y = torch.pow(x, 2)\ny.sum().backward()\nassert(x.grad.equal(2 * x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud55c \uac00\uc9c0 \uc8fc\uc758\ud560 \uc810\uc740 ``unpack_hook`` \uc774 \uc62c\ubc14\ub978 \uac12\uc744 \uac00\uc9c4 tensor\ub97c \ud30c\uc0dd\ud560 \uc218 \uc788\ub294 \ud55c\n``pack_hook`` \uc758 \ucd9c\ub825\uc740 *any \ud30c\uc774\uc36c \uac1d\uccb4* \uac00 \ub420 \uc218 \uc788\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uba87 \uac00\uc9c0 \ud2b9\uc774\ud55c \uc608\uc81c\ub4e4\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uba3c\uc800, \uac00\ub2a5\uc740 \ud558\uc9c0\ub9cc \ubc14\ubcf4\uac19\uc544\uc11c \ub204\uad6c\ub3c4 \ud558\uace0 \uc2f6\uc5b4\ud558\uc9c0 \uc54a\ub294 \uc608\uc81c \uba87\uac00\uc9c0\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ``int`` \ubc18\ud658\n\n\ud30c\uc774\uc36c \ub9ac\uc2a4\ud2b8\uc758 \uc778\ub371\uc2a4 \ubc18\ud658\n\uc0c1\ub300\uc801\uc73c\ub85c\ub294 \uc704\ud5d8\ud558\uc9c4 \uc54a\uc9c0\ub9cc \ub17c\ub780\uc758 \uc5ec\uc9c0\uac00 \uc788\ub294 \uc720\uc6a9\uc131\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "storage = []\n\ndef pack(x):\n    storage.append(x)\n    return len(storage) - 1\n\ndef unpack(x):\n    return storage[x]\n\nx = torch.randn(5, requires_grad=True)\nwith torch.autograd.graph.saved_tensors_hooks(pack, unpack):\n    y = x * x\ny.sum().backward()\n\nassert(x.grad.equal(2 * x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \ud29c\ud50c(tuple) \ubc18\ud658\n\n\uc77c\ubd80 tensor\uc640 \ud568\uc218\ub97c \ubc18\ud658\ud558\uace0 \ud328\ud0b9\uc744 \ud478\ub294 \ubc29\ubc95\uc740 \uc774\ub7f0 \ud615\ud0dc\ub85c\ub294 \uc720\uc6a9\ud558\uc9c0 \uc54a\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def pack(x):\n    delta = torch.randn(*x.size())\n    return x - delta, lambda x: x + delta\n\ndef unpack(packed):\n    x, f = packed\n    return f(x)\n\n\nx = torch.randn(5, requires_grad=True)\nwith torch.autograd.graph.saved_tensors_hooks(pack, unpack):\n    y = x * x\ny.sum().backward()\n\nassert(torch.allclose(x.grad, 2 * x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ``str`` \ubc18\ud658\n\ntensor\uc758 __repr__ \ubc18\ud658\n\uc544\ub9c8\ub3c4 \uc774\ub807\uac8c\ub294 \ud558\uc9c0 \uc54a\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.randn(5, requires_grad=True)\nwith torch.autograd.graph.saved_tensors_hooks(lambda x: repr(x), lambda x: eval(\"torch.\" + x)):\n    y = x * x\ny.sum().backward()\nassert(torch.all(x.grad - 2 * x <= 1e-4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\ub7ec\ud55c \uc608\uc81c\ub294 \uc2e4\uc81c\ub85c \uc720\uc6a9\ud558\uc9c0 \uc54a\uc744 \uac83\uc774\uc9c0\ub9cc\n\uc6d0\ub798 tensor\uc758 \ub0b4\uc6a9\uc744 \uac00\uc838\uc624\uae30\uc5d0 \ucda9\ubd84\ud55c \uc815\ubcf4\ub97c \uac00\uc9c0\uace0 \uc788\ub2e4\uba74\n``pack_hook`` \uc758 \uacb0\uacfc\ubb3c\uc774 \uc5b4\ub5a4 \ud30c\uc774\uc36c \uac1d\uccb4\ub77c\ub3c4\n\ub420 \uc218 \uc788\uc74c\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\n\ub2e4\uc74c \uc139\uc158\uc5d0\uc11c\ub294 \ub354 \uc720\uc6a9\ud55c \uc751\uc6a9\ud504\ub85c\uadf8\ub7a8\uc5d0 \uc911\uc810\uc744 \ub450\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### tensor\ub97c CPU\uc5d0 \uc800\uc7a5\ud558\uae30\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub9e4\uc6b0 \ube48\ubc88\ud558\uac8c, tensor \uacc4\uc0b0 \uadf8\ub798\ud504 GPU\uc5d0 \uc0b4\uc544 \uc788\uc2b5\ub2c8\ub2e4.\n\ub300\ubd80\ubd84 \uacbd\uc6b0\uc5d0\uc11c \ubaa8\ub378\uc774 \ud3c9\uac00\uc911\uc5d0 \uc815\uc0c1\uc801\uc73c\ub85c \uc218\ud589\ub418\uc9c0\ub9cc \ud6c8\ub828 \uc911\uc5d0 \uba54\ubaa8\ub9ac\uac00 \ubd80\uc871\ud558\ub2e4\uba74,\n\uacc4\uc0b0 \uadf8\ub798\ud504\uc5d0\uc11c tensor\uc5d0 \ub300\ud55c \ucc38\uc870 \uc720\uc9c0\uac00\nGPU \uba54\ubaa8\ub9ac\ub97c \ubd80\uc871\ud558\uac8c \ub9cc\ub4dc\ub294 \uc6d0\uc778\uc774 \ub429\ub2c8\ub2e4.\n\nhooks\ub294 \uc774\ub97c \uad6c\ud604\ud558\ub294 \ub9e4\uc6b0 \uac04\ub2e8\ud55c \ubc29\ubc95\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def pack_hook(x):\n    return (x.device, x.cpu())\n\ndef unpack_hook(packed):\n    device, tensor = packed\n    return tensor.to(device)\n\nx = torch.randn(5, requires_grad=True)\nwith torch.autograd.graph.saved_tensors_hooks(pack, unpack):\n    y = x * x\ny.sum().backward()\n\ntorch.allclose(x.grad, (2 * x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc2e4\uc81c\ub85c \ud30c\uc774\ud1a0\uce58\ub294 \uc774\ub7ec\ud55c hooks\ub97c \ud3b8\ub9ac\ud558\uac8c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 API\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n(\uace0\uc815\ub41c \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud558\ub294 \uae30\ub2a5\ub3c4 \ud3ec\ud568).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.w = nn.Parameter(torch.randn(5))\n\n    def forward(self, x):\n        with torch.autograd.graph.save_on_cpu(pin_memory=True):\n            # some computation\n            return self.w * x\n\nx = torch.randn(5)\nmodel = Model()\nloss = model(x).sum()\nloss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc2e4\uc81c\ub85c A100 GPU\uc5d0\uc11c \ubc30\uce58\ud06c\uae30\uac00 256\uc778 ResNet-152\uc758 \uacbd\uc6b0 \uc774\ub294 GPU \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9\uc774\n48G\uc5d0\uc11c 5GB\ub85c \uc904\uc5b4\ub4e4\uc9c0\ub9cc, \uc774\ub294 6\ubc30 \ub290\ub824\uc9c0\ub294 \ub300\uac00\ub97c \uce58\ub7ec\uc57c\ud569\ub2c8\ub2e4.\n\n\ubb3c\ub860 \ub124\ud2b8\uc6cc\ud06c \ud2b9\uc815\ubd80\ubd84\ub9cc CPU\uc5d0 \uc800\uc7a5\ud558\uc5ec \uc808\ucda9\uc548\uc744 \uc870\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc608\ub97c \ub4e4\uc5b4, \uc5b4\ub5a4 \ubaa8\ub4c8\uc744 \uac10\uc2f8\ub450\uace0 \ud574\ub2f9 tensor\ub97c CPU\uc5d0 \uc800\uc7a5\ud558\ub294 \ud2b9\ubcc4\ud55c\n``nn.Module`` \uc744 \uc815\uc758\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SaveToCpu(nn.Module):\n    def __init__(self, module):\n        super().__init__()\n        self.module = module\n\n    def forward(self, *args, **kwargs):\n        with torch.autograd.graph.save_on_cpu(pin_memory=True):\n            return self.module(*args, **kwargs)\n\nmodel = nn.Sequential(\n    nn.Linear(10, 100),\n    SaveToCpu(nn.Linear(100, 100)),\n    nn.Linear(100, 10),\n)\n\nx = torch.randn(10)\nloss = model(x).sum()\nloss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### tensor\ub97c \ub514\uc2a4\ud06c\uc5d0 \uc800\uc7a5\ud558\uae30\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ube44\uc2b7\ud558\uac8c, \uc774\ub7ec\ud55c tensor\ub97c \ub514\uc2a4\ud06c\uc5d0 \uc800\uc7a5\ud558\uace0 \uc2f6\uc744 \uc218 \ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n\ub2e4\uc2dc \ub9d0\ud558\uc9c0\ub9cc \uc774\uac83\uc740 \uc55e\uc11c\ub9d0\ud55c hooks\ub85c \ub2ec\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\uc790\ub780 \ubc84\uc804\uc740 \ubcf4\ud1b5 \uc774\ub7f4\uac83\uc785\ub2c8\ub2e4.\n\n\ubaa8\uc790\ub780 \ubc84\uc804(naive version) - \ud78c\ud2b8: \uc774\ub807\uac8c \ud558\uc9c0 \ub9c8\uc2dc\uc624.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import uuid\ntmp_dir = \"temp\"\n\ndef pack_hook(tensor):\n    name = os.path.join(tmp_dir, str(uuid.uuid4()))\n    torch.save(tensor, name)\n    return name\n\ndef unpack_hook(name):\n    return torch.load(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc704\uc758 \ucf54\ub4dc\uac00 \ub098\uc05c \uc774\uc720\ub294 \ub514\uc2a4\ud06c\uc5d0 \uc800\uc7a5\ub41c \ud30c\uc77c\uc774 \ub204\ucd9c\ub418\uace0 \ud574\ub2f9 \ud30c\uc77c\uc744 \uc9c0\uc6b8\uc218\ub3c4 \uc5c6\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\uc774 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \uac83\uc740 \uadf8\ub807\uac8c \uac04\ub2e8\ud558\uc9c0 \uc54a\uc544 \ubcf4\uc785\ub2c8\ub2e4.\n\n\uc798\ubabb\ub41c \ubc84\uc804 - \ud78c\ud2b8: \uc774\ub807\uac8c \ud558\uc9c0 \ub9c8\uc2dc\uc624.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import uuid\nimport os\nimport tempfile\ntmp_dir_obj = tempfile.TemporaryDirectory()\ntmp_dir = tmp_dir_obj.name\n\ndef pack_hook(tensor):\n    name = os.path.join(tmp_dir, str(uuid.uuid4()))\n    torch.save(tensor, name)\n    return name\n\ndef unpack_hook(name):\n    tensor = torch.load(name)\n    os.remove(name)\n    return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc704\uc758 \ucf54\ub4dc\uac00 \uc791\ub3d9\ud558\uc9c0 \uc54a\ub294 \uc774\uc720\ub294 ``unpack_hook`` \uac00 \uc5ec\ub7ec\ubc88 \ud638\ucd9c\ub418\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\uba3c\uc800 \uc555\ucd95\uc744 \ud480 \ub54c \ud30c\uc77c\uc744 \uc0ad\uc81c\ud558\uba74 \ucc98\uc74c\uc5d0, \uc800\uc7a5\ub41c tensor\uc5d0 \uc811\uadfc\uc2dc\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\n\ub450 \ubc88\uc9f8\uc5d0\ub294 \uc624\ub958\uac00 \ubc1c\uc0dd\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.ones(5, requires_grad=True)\nwith torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):\n    y = x.pow(2)\nprint(y.grad_fn._saved_self)\ntry:\n    print(y.grad_fn._saved_self)\n    print(\"Double access succeeded!\")\nexcept:\n    print(\"Double access failed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574,\n\ud30c\uc774\ud1a0\uce58\ub294 \uc800\uc7a5\ub41c \ub370\uc774\ud130\ub97c \ub354\uc774\uc0c1 \ud544\uc694\ud558\uc9c0 \uc54a\uc744 \ub54c\n\uc790\ub3d9\uc73c\ub85c \ud574\uc81c(\uc0ad\uc81c) \ud558\ub294 \uc774\uc810\uc744 \ud65c\uc6a9\ud558\ub294 hooks\uc758 \ubc84\uc804\uc744 \uc791\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SelfDeletingTempFile():\n    def __init__(self):\n        self.name = os.path.join(tmp_dir, str(uuid.uuid4()))\n\n    def __del__(self):\n        os.remove(self.name)\n\ndef pack_hook(tensor):\n    temp_file = SelfDeletingTempFile()\n    torch.save(tensor, temp_file.name)\n    return temp_file\n\ndef unpack_hook(temp_file):\n    return torch.load(temp_file.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``backward`` \ub97c \ud638\ucd9c\ud558\uba74 ``pack_hook`` \uc774 \uc0ad\uc81c\ub418\uace0,\n\ud30c\uc77c\uc774 \uc81c\uac70\ub418\ub3c4\ub85d \ud558\ubbc0\ub85c \ub354 \uc774\uc0c1 \ud30c\uc77c\uc774 \ub204\ucd9c\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n\n\ub2e4\uc74c\uacfc \uac19\uc740 \ubc29\uc2dd\uc73c\ub85c \ubaa8\ub378\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc0ac\uc774\uc988 >=1000\uc778 tensor\ub9cc\uc774 \ub514\uc2a4\ud06c\uc5d0 \uc800\uc7a5\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\nSAVE_ON_DISK_THRESHOLD = 1000\n\ndef pack_hook(x):\n    if x.numel() < SAVE_ON_DISK_THRESHOLD:\n        return x\n    temp_file = SelfDeletingTempFile()\n    torch.save(tensor, temp_file.name)\n    return temp_file\n\ndef unpack_hook(tensor_or_sctf):\n    if isinstance(tensor_or_sctf, torch.Tensor):\n        return tensor_or_sctf\n    return torch.load(tensor_or_sctf.name)\n\nclass SaveToDisk(nn.Module):\n    def __init__(self, module):\n        super().__init__()\n        self.module = module\n\n    def forward(self, *args, **kwargs):\n        with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):\n            return self.module(*args, **kwargs)\n\nnet = nn.DataParallel(SaveToDisk(Model()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ub9c8\uc9c0\ub9c9 \uc608\uc81c\uc5d0\uc11c\ub294 \uc800\uc7a5\ud574\uc57c \ud558\ub294 (\uc5ec\uae30\uc5d0\uc11c\ub294 \uc6d0\uc18c\uc758 \uc218\uac00 1000 \uc774\uc0c1\uc778) tensor\ub4e4\uc744 \uace8\ub77c\ub0b4\ub294 \ubc29\ubc95\uacfc\n\uc774 \uae30\ub2a5\uc744 ``nn.DataParallel`` \uacfc \ud568\uaed8 \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc744 \uc0b4\ud3b4\ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc5ec\uae30\uae4c\uc9c0 \uc798 \ub530\ub77c\uc624\uc168\ub098\uc694? \ucd95\ud558\ud569\ub2c8\ub2e4!\n\uc774\uc81c \uc800\uc7a5\ub41c tensor hooks\ub97c \uc5b4\ub5bb\uac8c \uc0ac\uc6a9\ud558\ub294\uc9c0\uc640\n\uc5f0\uc0b0 \uc2dc \uba54\ubaa8\ub9ac \uad00\ub9ac(trade-offs)\uc5d0 \uc720\uc6a9\ud558\uac8c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ubc29\ubc95\uc744 \uc54c\uac8c \ub418\uc168\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}