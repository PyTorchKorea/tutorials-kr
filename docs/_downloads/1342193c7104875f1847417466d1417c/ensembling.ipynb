{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \ubaa8\ub378 \uc559\uc0c1\ube14\n\n**\ubc88\uc5ed**: [\uc870\ud615\uc11c](https://github.com/ChoHyoungSeo/)\n\n\ubcf8 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 ``torch.vmap`` \uc744 \ud65c\uc6a9\ud558\uc5ec \ubaa8\ub378 \uc559\uc0c1\ube14\uc744 \ubca1\ud130\ud654\ud558\ub294 \ubc29\ubc95\uc744 \uc124\uba85\ud569\ub2c8\ub2e4.\n\n## \ubaa8\ub378 \uc559\uc0c1\ube14\uc774\ub780?\n\ubaa8\ub378 \uc559\uc0c1\ube14\uc740 \uc5ec\ub7ec \ubaa8\ub378\uc758 \uc608\uce21\uac12\uc744 \ud568\uaed8 \uacb0\ud569\ud558\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.\n\uc77c\ubc18\uc801\uc73c\ub85c \uc774 \uc791\uc5c5\uc740 \uc77c\ubd80 \uc785\ub825\uac12\uc5d0 \ub300\ud574 \uac01 \ubaa8\ub378\uc744 \uac1c\ubcc4\uc801\uc73c\ub85c \uc2e4\ud589\ud55c \ub2e4\uc74c \uc608\uce21\uc744 \uacb0\ud569\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc2e4\ud589\ub429\ub2c8\ub2e4.\n\ud558\uc9c0\ub9cc \ub3d9\uc77c\ud55c \uc544\ud0a4\ud14d\ucc98\ub85c \ubaa8\ub378\uc744 \uc2e4\ud589\ud558\ub294 \uacbd\uc6b0, ``torch.vmap`` \uc744 \ud65c\uc6a9\ud558\uc5ec \ud568\uaed8 \uacb0\ud569\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n``vmap`` \uc740 \uc785\ub825 tensor\uc758 \uc5ec\ub7ec \ucc28\uc6d0\uc5d0 \uac78\uccd0 \ud568\uc218\ub97c \ub9e4\ud551\ud558\ub294 \ud568\uc218 \ubcc0\ud658\uc785\ub2c8\ub2e4. \uc774 \ud568\uc218\uc758\n\uc0ac\uc6a9 \uc0ac\ub840 \uc911 \ud558\ub098\ub294 for \ubb38\uc744 \uc81c\uac70\ud558\uace0 \ubca1\ud130\ud654\ub97c \ud1b5\ud574 \uc18d\ub3c4\ub97c \ub192\uc774\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\uac04\ub2e8\ud55c MLP \uc559\uc0c1\ube14\uc744 \ud65c\uc6a9\ud558\uc5ec \uc774\ub97c \uc218\ud589\ud558\ub294 \ubc29\ubc95\uc744 \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \uc2e4\ud589\uc744 \uc704\ud574\uc11c\ub294 PyTorch 2.0 \ub610\ub294 \uc774\uc0c1\uc758 \ubc84\uc804\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\ntorch.manual_seed(0)\n\n# \ub2e4\uc74c\uc740 \uac04\ub2e8\ud55c MLP \uc785\ub2c8\ub2e4.\nclass SimpleMLP(nn.Module):\n    def __init__(self):\n        super(SimpleMLP, self).__init__()\n        self.fc1 = nn.Linear(784, 128)\n        self.fc2 = nn.Linear(128, 128)\n        self.fc3 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = x.flatten(1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.fc3(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub354\ubbf8 \ub370\uc774\ud130\ub97c \uc0dd\uc131\ud558\uace0 MNIST \ub370\uc774\ud130 \uc14b\uc73c\ub85c \uc791\uc5c5\ud55c\ub2e4\uace0 \uac00\uc815\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\ub530\ub77c\uc11c \uc774\ubbf8\uc9c0\ub294 28x28 \uc0ac\uc774\uc988\uc774\uba70 \ubbf8\ub2c8 \ubc30\uce58 \ud06c\uae30\ub294 64\uc785\ub2c8\ub2e4.\n\ub354 \ub098\uc544\uac00 10\uac1c\uc758 \uc11c\ub85c \ub2e4\ub978 \ubaa8\ub378\uc5d0\uc11c \ub098\uc628 \uc608\uce21\uac12\uc744 \uacb0\ud569\ud558\uace0 \uc2f6\ub2e4\uace0 \uac00\uc815\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\nnum_models = 10\n\ndata = torch.randn(100, 64, 1, 28, 28, device=device)\ntargets = torch.randint(10, (6400,), device=device)\n\nmodels = [SimpleMLP().to(device) for _ in range(num_models)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc608\uce21\uac12\uc744 \uc0dd\uc131\ud558\ub294 \ub370\ub294 \uba87 \uac00\uc9c0 \uc635\uc158\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\uac01\uac01\uc758 \ubaa8\ub378\uc5d0 \ub2e4\ub978 \ubb34\uc791\uc704 \ubbf8\ub2c8 \ubc30\uce58 \ub370\uc774\ud130\ub97c \uc904 \uc218 \uc788\uace0\n\uac01\uac01\uc758 \ubaa8\ub378\uc5d0 \ub3d9\uc77c\ud55c \ubbf8\ub2c8 \ubc30\uce58\uc758 \ub370\uc774\ud130\ub97c \uc904 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n(\uc608\ub97c \ub4e4\uc5b4, \ub2e4\ub978 \ubaa8\ub378 \ucd08\uae30\uac12\uc758 \uc601\ud5a5\uc744 \ud14c\uc2a4\ud2b8\ud560 \uacbd\uc6b0)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc635\uc158 1: \uac01\uac01\uc758 \ubaa8\ub378\uc5d0 \ub2e4\ub978 \ubbf8\ub2c8 \ubc30\uce58\ub97c \uc8fc\ub294 \uacbd\uc6b0\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "minibatches = data[:num_models]\npredictions_diff_minibatch_loop = [model(minibatch) for model, minibatch in zip(models, minibatches)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc635\uc158 2: \uac19\uc740 \ubbf8\ub2c8 \ubc30\uce58\ub97c \uc8fc\ub294 \uacbd\uc6b0\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "minibatch = data[0]\npredictions2 = [model(minibatch) for model in models]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ``vmap`` \uc744 \ud65c\uc6a9\ud558\uc5ec \uc559\uc0c1\ube14 \ubca1\ud130\ud654\ud558\uae30\n\n``vmap`` \uc744 \uc0ac\uc6a9\ud558\uc5ec for \ubb38\uc758 \uc18d\ub3c4\ub97c \ub192\uc5ec\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uba3c\uc800 ``vmap`` \uacfc \ud568\uaed8 \uc0ac\uc6a9\ud560 \ubaa8\ub378\uc744 \uc900\ube44\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n\n\uba3c\uc800, \uac01 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc313\uc544 \ubaa8\ub378\uc758 \uc0c1\ud0dc\ub97c \uacb0\ud569\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\uc608\ub97c \ub4e4\uc5b4, ``model[i].fc1.weight`` \uc758 shape\uc740 ``[784, 128]`` \uc785\ub2c8\ub2e4.\n\uc774 10\uac1c\uc758 \ubaa8\ub378 \uac01\uac01\uc5d0 \ub300\ud574 ``.fc1.weight`` \ub97c \uc313\uc544 ``[10, 784, 128]`` shape\uc758 \ud070 \uac00\uc911\uce58\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ud30c\uc774\ud1a0\uce58\uc5d0\uc11c\ub294 \uc774\ub97c \uc704\ud574 ``torch.func.stack_module_state`` \ub77c\ub294 \ud568\uc218\ub97c \uc81c\uacf5\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.func import stack_module_state\n\nparams, buffers = stack_module_state(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e4\uc74c\uc73c\ub85c, ``vmap`` \uc5d0 \ub300\ud55c \ud568\uc218\ub97c \uc815\uc758\ud574\uc57c \ud569\ub2c8\ub2e4. \uc774 \ud568\uc218\ub294 \ud30c\ub77c\ubbf8\ud130, \ubc84\ud37c, \uc785\ub825\uac12\uc774 \uc8fc\uc5b4\uc9c0\uba74 \ubaa8\ub378\uc744 \uc2e4\ud589\ud569\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 ``torch.func.functional_call`` \uc744 \ud65c\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.func import functional_call\nimport copy\n\n# \ubaa8\ub378 \uc911 \ud558\ub098\uc758 \"stateless\" \ubc84\uc804\uc744 \uad6c\ucd95\ud569\ub2c8\ub2e4.\n# \"stateless\"\ub294 \ub9e4\uac1c\ubcc0\uc218\uac00 \uba54\ud0c0 tensor\uc774\uba70 \uc800\uc7a5\uc18c\uac00 \uc5c6\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.\nbase_model = copy.deepcopy(models[0])\nbase_model = base_model.to('meta')\n\ndef fmodel(params, buffers, x):\n    return functional_call(base_model, (params, buffers), (x,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc635\uc158 1: \uac01 \ubaa8\ub378\uc5d0 \ub300\ud574 \uc11c\ub85c \ub2e4\ub978 \ubbf8\ub2c8 \ubc30\uce58\ub97c \ud65c\uc6a9\ud558\uc5ec \uc608\uce21\ud569\ub2c8\ub2e4.\n\n\uae30\ubcf8\uc801\uc73c\ub85c, ``vmap`` \uc740 \ubaa8\ub4e0 \uc785\ub825\uc758 \uccab \ubc88\uc9f8 \ucc28\uc6d0\uc5d0 \uac78\uccd0 \ud568\uc218\uc5d0 \ub9e4\ud551\ud569\ub2c8\ub2e4.\n``stack_module_state`` \ub97c \uc0ac\uc6a9\ud558\uba74 \uac01 ``params`` \uc640 \ubc84\ud37c\ub294 \uc55e\ucabd\uc5d0 'num_models'\n\ud06c\uae30\uc758 \ucd94\uac00 \ucc28\uc6d0\uc744 \uac00\uc9c0\uba70, \ubbf8\ub2c8 \ubc30\uce58\ub294 'num_models' \ud06c\uae30\uac00 \ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print([p.size(0) for p in params.values()]) # \uc120\ud589 'num_models' \ucc28\uc6d0 \ud45c\uc2dc\n\nassert minibatches.shape == (num_models, 64, 1, 28, 28) # \ubbf8\ub2c8 \ubc30\uce58\uc758 \uc120\ud589 \ucc28\uc6d0\uc774 'num_models' \ud06c\uae30\uc778\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\n\nfrom torch import vmap\n\npredictions1_vmap = vmap(fmodel)(params, buffers, minibatches)\n\n# ``vmap`` \uc608\uce21\uc774 \ub9de\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\nassert torch.allclose(predictions1_vmap, torch.stack(predictions_diff_minibatch_loop), atol=1e-3, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc635\uc158 2: \ub3d9\uc77c\ud55c \ubbf8\ub2c8 \ubc30\uce58 \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud558\uc5ec \uc608\uce21\ud569\ub2c8\ub2e4.\n\n``vmap`` \uc5d0\ub294 \ub9e4\ud551\ud560 \ucc28\uc6d0\uc744 \uc9c0\uc815\ud558\ub294 ``in_dims`` \ub77c\ub294 \uc778\uc790\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n``None`` \uc744 \uc0ac\uc6a9\ud558\uba74 10\uac1c \ubaa8\ub378\uc5d0 \ubaa8\ub450 \ub3d9\uc77c\ud55c \ubbf8\ub2c8 \ubc30\uce58\ub97c \uc801\uc6a9\ud558\ub3c4\ub85d\n``vmap`` \uc5d0 \uc54c\ub824\uc904 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions2_vmap = vmap(fmodel, in_dims=(0, 0, None))(params, buffers, minibatch)\n\nassert torch.allclose(predictions2_vmap, torch.stack(predictions2), atol=1e-3, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucc38\uace0 \uc0ac\ud56d: ``vmap`` \uc73c\ub85c \ubcc0\ud658\ud560 \uc218 \uc788\ub294 \ud568\uc218 \uc720\ud615\uc5d0\ub294 \uc81c\ud55c\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\ubcc0\ud658\ud558\uae30\uc5d0 \uac00\uc7a5 \uc88b\uc740 \ud568\uc218\ub294 \uc785\ub825\uac12\uc5d0 \uc758\ud574\uc11c\ub9cc \ucd9c\ub825\uc774 \uacb0\uc815\ub418\uace0\n\ub2e4\ub978 \ubd80\uc791\uc6a9 (\uc608. \ubcc0\uc774) \uc774 \uc5c6\ub294 \uc21c\uc218 \ud568\uc218(pure function) \uc785\ub2c8\ub2e4.\n``vmap`` \uc740 \uc784\uc758\uc758 \ubcc0\uc774\ub41c \ud30c\uc774\uc36c \uc790\ub8cc\uad6c\uc870\ub294 \ucc98\ub9ac\ud560 \uc218 \uc5c6\uc9c0\ub9cc,\n\ub2e4\uc591\ud55c \ub0b4\uc7a5\ub41c \ud30c\uc774\ud1a0\uce58 \uc5f0\uc0b0\uc740 \ucc98\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc131\ub2a5\n\uc131\ub2a5 \uc218\uce58\uac00 \uad81\uae08\ud558\uc2e0\uac00\uc694? \uc218\uce58\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.benchmark import Timer\nwithout_vmap = Timer(\n    stmt=\"[model(minibatch) for model, minibatch in zip(models, minibatches)]\",\n    globals=globals())\nwith_vmap = Timer(\n    stmt=\"vmap(fmodel)(params, buffers, minibatches)\",\n    globals=globals())\nprint(f'Predictions without vmap {without_vmap.timeit(100)}')\nprint(f'Predictions with vmap {with_vmap.timeit(100)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``vmap`` \uc744 \uc0ac\uc6a9\ud558\uba74 \uc18d\ub3c4\uac00 \ud06c\uac8c \ud5a5\uc0c1\ub429\ub2c8\ub2e4!\n\n\uc77c\ubc18\uc801\uc73c\ub85c, ``vmap`` \uc744 \uc0ac\uc6a9\ud55c \ubca1\ud130\ud654\ub294 for \ubb38\uc5d0\uc11c \ud568\uc218\ub97c \uc2e4\ud589\ud558\ub294 \uac83\ubcf4\ub2e4\n\ube60\ub974\uba70 \uc218\ub3d9 \uc77c\uad04 \ucc98\ub9ac\uc640 \ube44\uc2b7\ud55c \uc18d\ub3c4\ub97c \ub0c5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \ud2b9\uc815 \uc5f0\uc0b0\uc5d0 \ub300\ud574 ``vmap`` \uaddc\uce59\uc744\n\uad6c\ud604\ud558\uc9c0 \uc54a\uc558\uac70\ub098 \uae30\ubcf8 \ucee4\ub110\uc774 \uad6c\ud615 \ud558\ub4dc\uc6e8\uc5b4(GPUs)\uc5d0 \ucd5c\uc801\ud654\ub418\uc9c0 \uc54a\uc740 \uacbd\uc6b0\uc640 \uac19\uc774\n\uba87 \uac00\uc9c0 \uc608\uc678\uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uacbd\uc6b0\uac00 \ubc1c\uacac\ub418\uba74, GitHub\uc5d0 \uc774\uc288\ub97c \uc0dd\uc131\ud574\uc11c \uc54c\ub824\uc8fc\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}