{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: Sequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 Attention\uc744 \uc774\uc6a9\ud55c \ubc88\uc5ed\n********************************************************************************\n**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n  **\ubc88\uc5ed**: `\ud669\uc131\uc218 <https://github.com/adonisues>`_\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 \"\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP\"\uc758 \uc138\ubc88\uc9f8\uc774\uc790 \ub9c8\uc9c0\ub9c9 \ud3b8\uc73c\ub85c, NLP \ubaa8\ub378\ub9c1 \uc791\uc5c5\uc744\n\uc704\ud55c \ub370\uc774\ud130 \uc804\ucc98\ub9ac\uc5d0 \uc0ac\uc6a9\ud560 \uc790\uccb4 \ud074\ub798\uc2a4\uc640 \ud568\uc218\ub4e4\uc744 \uc791\uc131\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \ub9c8\uce5c \ub4a4\uc5d0\ub294 `torchtext` \uac00 \uc5b4\ub5bb\uac8c \uc9c0\uae08\uae4c\uc9c0\uc758 \ud29c\ud1a0\ub9ac\uc5bc\ub4e4\uc5d0\uc11c\uc758\n\uc804\ucc98\ub9ac \uacfc\uc815\uc744 \ub2e4\ub8e8\ub294\uc9c0\ub97c \uc774\ud6c4 \ud29c\ud1a0\ub9ac\uc5bc\ub4e4\uc5d0\uc11c \ubc30\uc6b8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ud504\ub85c\uc81d\ud2b8\uc5d0\uc11c\ub294 \uc2e0\uacbd\ub9dd\uc774 \ubd88\uc5b4\ub97c \uc601\uc5b4\ub85c \ubc88\uc5ed\ud558\ub3c4\ub85d \uac00\ub974\uce60 \uc608\uc815\uc785\ub2c8\ub2e4.\n\n::\n\n    [KEY: > input, = target, < output]\n\n    > il est en train de peindre un tableau .\n    = he is painting a picture .\n    < he is painting a picture .\n\n    > pourquoi ne pas essayer ce vin delicieux ?\n    = why not try that delicious wine ?\n    < why not try that delicious wine ?\n\n    > elle n est pas poete mais romanciere .\n    = she is not a poet but a novelist .\n    < she not not a poet but a novelist .\n\n    > vous etes trop maigre .\n    = you re too skinny .\n    < you re all alone .\n\n... \uc131\uacf5\uc728\uc740 \ubcc0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ud558\ub098\uc758 \uc2dc\ud000\uc2a4\ub97c \ub2e4\ub978 \uc2dc\ud000\uc2a4\ub85c \ubc14\uafb8\ub294 \ub450\uac1c\uc758 RNN\uc774 \ud568\uaed8 \ub3d9\uc791\ud558\ub294\n`sequence to sequence network <https://arxiv.org/abs/1409.3215>`__ \uc758 \uac04\ub2e8\ud558\uc9c0\ub9cc \uac15\ub825\ud55c \uc544\uc774\ub514\uc5b4\uac00\n\uc774\uac83(\ubc88\uc5ed)\uc744 \uac00\ub2a5\ud558\uac8c \ud569\ub2c8\ub2e4. \uc778\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ubca1\ud130\ub85c \uc555\ucd95\ud558\uace0,\n\ub514\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\ub294 \ud574\ub2f9 \ubca1\ud130\ub97c \uc0c8\ub85c\uc6b4 \uc2dc\ud000\uc2a4\ub85c \ud3bc\uce69\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\n\uc774 \ubaa8\ub378\uc744 \uac1c\uc120\ud558\uae30 \uc704\ud574 `Attention Mechanism <https://arxiv.org/abs/1409.0473>`__ \uc744\n\uc0ac\uc6a9\ud558\uba74 \ub514\ucf54\ub354\uac00 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \ubc94\uc704\uc5d0 \uc9d1\uc911\ud560 \uc218 \uc788\ub3c4\ub85d \ud569\ub2c8\ub2e4.\n\n**\ucd94\ucc9c \uc790\ub8cc:**\n\n\ucd5c\uc18c\ud55c Pytorch\ub97c \uc124\uce58\ud588\uace0, Python\uc744 \uc54c\uace0, Tensor\ub97c \uc774\ud574\ud55c\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4.:\n\n-  http://pytorch.org/ \uc124\uce58 \uc548\ub0b4\ub97c \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/deep_learning_60min_blitz` \uc77c\ubc18\uc801\uc778 PyTorch \uc2dc\uc791\uc744 \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/pytorch_with_examples` \ub113\uace0 \uae4a\uc740 \ud1b5\ucc30\uc744 \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/former_torchies_tutorial` \uc774\uc804 Lua Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c \uc790\ub8cc\n\n\nSequence to Sequence \ub124\ud2b8\uc6cc\ud06c\uc640 \ub3d9\uc791 \ubc29\ubc95\uc5d0 \uad00\ud574\uc11c \uc544\ub294 \uac83\uc740 \uc720\uc6a9\ud569\ub2c8\ub2e4:\n\n-  `Learning Phrase Representations using RNN Encoder-Decoder for\n   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n-  `Sequence to Sequence Learning with Neural\n   Networks <https://arxiv.org/abs/1409.3215>`__\n-  `Neural Machine Translation by Jointly Learning to Align and\n   Translate <https://arxiv.org/abs/1409.0473>`__\n-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__\n\n\uc774\uc804 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0 \uc788\ub294\n:doc:`/intermediate/char_rnn_classification_tutorial`\n\uc640 :doc:`/intermediate/char_rnn_generation_tutorial` \ub294\n\uac01\uac01 \uc778\ucf54\ub354, \ub514\ucf54\ub354 \ubaa8\ub378\uacfc \ube44\uc2b7\ud55c \ucee8\uc13c\uc744 \uac00\uc9c0\uae30 \ub54c\ubb38\uc5d0 \ub3c4\uc6c0\uc774 \ub429\ub2c8\ub2e4.\n\n**\uc694\uad6c \uc0ac\ud56d**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \ud30c\uc77c \ub85c\ub529\n==================\n\n\uc774 \ud504\ub85c\uc81d\ud2b8\uc758 \ub370\uc774\ud130\ub294 \uc218\ucc9c \uac1c\uc758 \uc601\uc5b4-\ud504\ub791\uc2a4\uc5b4 \ubc88\uc5ed \uc30d\uc785\ub2c8\ub2e4.\n\n`Open Data Stack Exchange <https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages>`__\n\uc5d0 \uad00\ud55c \uc774 \uc9c8\ubb38\uc740 https://tatoeba.org/eng/downloads \uc5d0\uc11c \ub2e4\uc6b4 \ub85c\ub4dc\uac00 \uac00\ub2a5\ud55c\n\uacf5\uac1c \ubc88\uc5ed \uc0ac\uc774\ud2b8 https://tatoeba.org/ \ub97c \uc54c\ub824 \uc8fc\uc5c8\uc2b5\ub2c8\ub2e4. \ub354 \ub098\uc740 \ubc29\ubc95\uc73c\ub85c\n\uc5b8\uc5b4 \uc30d\uc744 \uac1c\ubcc4 \ud14d\uc2a4\ud2b8 \ud30c\uc77c\ub85c \ubd84\ud560\ud558\ub294 \ucd94\uac00 \uc791\uc5c5\uc744 \uc218\ud589\ud55c\nhttps://www.manythings.org/anki/ \uac00 \uc788\uc2b5\ub2c8\ub2e4:\n\n\uc601\uc5b4-\ud504\ub791\uc2a4\uc5b4 \uc30d\uc774 \ub108\ubb34 \ucee4\uc11c \uc800\uc7a5\uc18c\uc5d0 \ud3ec\ud568 \ud560 \uc218 \uc5c6\uae30 \ub54c\ubb38\uc5d0\n\uacc4\uc18d\ud558\uae30 \uc804\uc5d0 ``data/eng-fra.txt`` \ub85c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc2ed\uc2dc\uc624.\n\uc774 \ud30c\uc77c\uc740 \ud0ed\uc73c\ub85c \uad6c\ubd84\ub41c \ubc88\uc5ed \uc30d \ubaa9\ub85d\uc785\ub2c8\ub2e4:\n\n::\n\n    I am cold.    J'ai froid.\n\n.. Note::\n   `\uc5ec\uae30 <https://download.pytorch.org/tutorial/data.zip>`_\n   \uc5d0\uc11c \ub370\uc774\ud130\ub97c \ub2e4\uc6b4 \ubc1b\uace0 \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubb38\uc790 \ub2e8\uc704 RNN \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ub41c \ubb38\uc790 \uc778\ucf54\ub529\uacfc \uc720\uc0ac\ud558\uac8c, \uc5b8\uc5b4\uc758 \uac01\n\ub2e8\uc5b4\ub4e4\uc744 One-Hot \ubca1\ud130 \ub610\ub294 \uadf8 \ub2e8\uc5b4\uc758 \uc8fc\uc18c\uc5d0\ub9cc \ub2e8 \ud558\ub098\uc758 1\uc744 \uc81c\uc678\ud558\uace0\n\ubaa8\ub450 0\uc778 \ud070 \ubca1\ud130\ub85c \ud45c\ud604\ud569\ub2c8\ub2e4. \ud55c \uac00\uc9c0 \uc5b8\uc5b4\uc5d0 \uc788\ub294 \uc218\uc2ed \uac1c\uc758 \ubb38\uc790\uc640\n\ub2ec\ub9ac \ubc88\uc5ed\uc5d0\ub294 \uc544\uc8fc \ub9ce\uc740 \ub2e8\uc5b4\ub4e4\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc778\ucf54\ub529 \ubca1\ud130\ub294 \ub9e4\uc6b0 \ub354 \ud07d\ub2c8\ub2e4.\n\uadf8\ub7ec\ub098 \uc6b0\ub9ac\ub294 \uc57d\uac04\uc758 \ud2b8\ub9ad\ub97c \uc368\uc11c \uc5b8\uc5b4 \ub2f9 \uc218\ucc9c \ub2e8\uc5b4 \ub9cc\n\uc0ac\uc6a9\ud558\ub3c4\ub85d \ub370\uc774\ud130\ub97c \ub2e4\ub4ec\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/word-encoding.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub098\uc911\uc5d0 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc785\ub825 \ubc0f \ubaa9\ud45c\ub85c \uc0ac\uc6a9\ud558\ub824\uba74 \ub2e8\uc5b4 \ub2f9 \uace0\uc720 \ubc88\ud638\uac00\n\ud544\uc694\ud569\ub2c8\ub2e4. \uc774 \ubaa8\ub4e0 \uac83\uc744 \ucd94\uc801\ud558\uae30 \uc704\ud574 \uc6b0\ub9ac\ub294\n\ub2e8\uc5b4\u2192\uc0c9\uc778(``word2index``)\uacfc \uc0c9\uc778\u2192\ub2e8\uc5b4(``index2word``) \uc0ac\uc804,\n\uadf8\ub9ac\uace0 \ub098\uc911\uc5d0 \ud76c\uadc0 \ub2e8\uc5b4\ub97c \ub300\uccb4\ud558\ub294\ub370 \uc0ac\uc6a9\ud560 \uac01 \ub2e8\uc5b4\uc758 \ube48\ub3c4\n``word2count`` \ub97c \uac00\uc9c4 ``Lang`` \uc774\ub77c\ub294 \ud5ec\ud37c \ud074\ub798\uc2a4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\nEOS_token = 1\n\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # SOS \uc640 EOS \ud3ec\ud568\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud30c\uc77c\uc740 \ubaa8\ub450 \uc720\ub2c8 \ucf54\ub4dc\ub85c \ub418\uc5b4\uc788\uc5b4 \uac04\ub2e8\ud558\uac8c\ud558\uae30 \uc704\ud574 \uc720\ub2c8 \ucf54\ub4dc \ubb38\uc790\ub97c\nASCII\ub85c \ubcc0\ud658\ud558\uace0, \ubaa8\ub4e0 \ubb38\uc790\ub97c \uc18c\ubb38\uc790\ub85c \ub9cc\ub4e4\uace0, \ub300\ubd80\ubd84\uc758 \uad6c\ub450\uc810\uc744\n\uc9c0\uc6cc\uc90d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc720\ub2c8 \ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 \uc77c\ubc18 ASCII\ub85c \ubcc0\ud658\ud558\uc2ed\uc2dc\uc624.\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# \uc18c\ubb38\uc790, \ub2e4\ub4ec\uae30, \uadf8\ub9ac\uace0 \ubb38\uc790\uac00 \uc544\ub2cc \ubb38\uc790 \uc81c\uac70\n\n\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To read the data file we will split the file into lines, and then split\nlines into pairs. The files are all English \u2192 Other Language, so if we\nwant to translate from Other Language \u2192 English I added the ``reverse``\nflag to reverse the pairs.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # \ud30c\uc77c\uc744 \uc77d\uace0 \uc904\ub85c \ubd84\ub9ac\n    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # \ubaa8\ub4e0 \uc904\uc744 \uc30d\uc73c\ub85c \ubd84\ub9ac\ud558\uace0 \uc815\uaddc\ud654\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n\n    # \uc30d\uc744 \ub4a4\uc9d1\uace0, Lang \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*\ub9ce\uc740* \uc608\uc81c \ubb38\uc7a5\uc774 \uc788\uace0 \uc2e0\uc18d\ud558\uac8c \ud559\uc2b5\ud558\uae30\ub97c \uc6d0\ud558\uae30 \ub54c\ubb38\uc5d0\n\ube44\uad50\uc801 \uc9e7\uace0 \uac04\ub2e8\ud55c \ubb38\uc7a5\uc73c\ub85c\ub9cc \ub370\uc774\ud130 \uc14b\uc744 \uc815\ub9ac\ud560 \uac83\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc11c\n\ucd5c\ub300 \uae38\uc774\ub294 10 \ub2e8\uc5b4 (\uc885\ub8cc \ubb38\uc7a5 \ubd80\ud638 \ud3ec\ud568)\uc774\uba70 \"I am\" \ub610\ub294\n\"He is\" \ub4f1\uc758 \ud615\ud0dc\ub85c \ubc88\uc5ed\ub418\ub294 \ubb38\uc7a5\uc73c\ub85c \ud544\ud130\ub9c1\ub429\ub2c8\ub2e4.(\uc774\uc804\uc5d0\n\uc544\ud3ec\uc2a4\ud2b8\ub85c\ud53c\ub294 \ub300\uccb4 \ub428)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH and \\\n        p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \uc900\ube44\ub97c \uc704\ud55c \uc804\uccb4 \uacfc\uc815:\n\n-  \ud14d\uc2a4\ud2b8 \ud30c\uc77c\uc744 \uc77d\uace0 \uc904\ub85c \ubd84\ub9ac\ud558\uace0, \uc904\uc744 \uc30d\uc73c\ub85c \ubd84\ub9ac\ud569\ub2c8\ub2e4.\n-  \ud14d\uc2a4\ud2b8\ub97c \uc815\uaddc\ud654 \ud558\uace0 \uae38\uc774\uc640 \ub0b4\uc6a9\uc73c\ub85c \ud544\ud130\ub9c1 \ud569\ub2c8\ub2e4.\n-  \uc30d\uc744 \uc774\ub8ec \ubb38\uc7a5\ub4e4\ub85c \ub2e8\uc5b4 \ub9ac\uc2a4\ud2b8\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\n\ninput_lang, output_lang, pairs = prepareData('eng', 'fra', True)\nprint(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seq2Seq \ubaa8\ub378\n=================\n\nRecurrent Neural Network(RNN)\ub294 \uc2dc\ud000\uc2a4\uc5d0\uc11c \uc791\ub3d9\ud558\uace0 \ub2e4\uc74c \ub2e8\uacc4\uc758\n\uc785\ub825\uc73c\ub85c \uc790\uc2e0\uc758 \ucd9c\ub825\uc744 \uc0ac\uc6a9\ud558\ub294 \ub124\ud2b8\uc6cc\ud06c\uc785\ub2c8\ub2e4.\n\n`Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, \ub610\ub294\nSeq2Seq \ub124\ud2b8\uc6cc\ud06c, \ub610\ub294 `Encoder Decoder\nnetwork <https://arxiv.org/pdf/1406.1078v3.pdf>`__ \ub294 \uc778\ucf54\ub354 \ubc0f\n\ub514\ucf54\ub354\ub77c\uace0 \ud558\ub294 \ub450 \uac1c\uc758 RNN\uc73c\ub85c \uad6c\uc131\ub41c \ubaa8\ub378\uc785\ub2c8\ub2e4.\n\uc778\ucf54\ub354\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \uc77d\uace0 \ub2e8\uc77c \ubca1\ud130\ub97c \ucd9c\ub825\ud558\uace0,\n\ub514\ucf54\ub354\ub294 \ud574\ub2f9 \ubca1\ud130\ub97c \uc77d\uc5b4 \ucd9c\ub825 \uc2dc\ud000\uc2a4\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\n\ubaa8\ub4e0 \uc785\ub825\uc5d0 \ud574\ub2f9\ud558\ub294 \ucd9c\ub825\uc774 \uc788\ub294 \ub2e8\uc77c RNN\uc758 \uc2dc\ud000\uc2a4 \uc608\uce21\uacfc \ub2ec\ub9ac\nSeq2Seq \ubaa8\ub378\uc740 \uc2dc\ud000\uc2a4 \uae38\uc774\uc640 \uc21c\uc11c\ub97c \uc790\uc720\ub86d\uac8c\ud558\uae30 \ub54c\ubb38\uc5d0\n\ub450 \uc5b8\uc5b4 \uc0ac\uc774\uc758 \ubc88\uc5ed\uc5d0 \uc774\uc0c1\uc801\uc785\ub2c8\ub2e4.\n\n\ub2e4\uc74c \ubb38\uc7a5 \"Je ne suis pas le chat noir\" \u2192 \"I am not the black cat\"\n\ub97c \uc0b4\ud3b4 \ubd05\uc2dc\ub2e4. \uc785\ub825 \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \ub300\ubd80\ubd84\uc740 \ucd9c\ub825 \ubb38\uc7a5\uc5d0\uc11c\n\uc9c1\uc5ed(\"chat noir\" \uc640 \"black cat\")\ub418\uc9c0\ub9cc \uc57d\uac04 \ub2e4\ub978 \uc21c\uc11c\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n\"ne/pas\" \uad6c\uc870\ub85c \uc778\ud574 \uc785\ub825 \ubb38\uc7a5\uc5d0 \ub2e8\uc5b4\uac00 \ud558\ub098 \ub354 \uc788\uc2b5\ub2c8\ub2e4.\n\uc785\ub825 \ub2e8\uc5b4\uc758 \uc2dc\ud000\uc2a4\ub97c \uc9c1\uc5ed\ud574\uc11c \uc815\ud655\ud55c \ubc88\uc5ed\uc744 \ub9cc\ub4dc\ub294\n\uac83\uc740 \uc5b4\ub824\uc6b8 \uac83\uc785\ub2c8\ub2e4.\n\nSeq2Seq \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uba74 \uc778\ucf54\ub354\ub294 \ud558\ub098\uc758 \ubca1\ud130\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\uc774\uc0c1\uc801\uc778 \uacbd\uc6b0\uc5d0 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \"\uc758\ubbf8\"\ub97c \ubb38\uc7a5\uc758 N \ucc28\uc6d0 \uacf5\uac04\uc5d0 \uc788\ub294\n\ub2e8\uc77c \uc9c0\uc810\uc778 \ub2e8\uc77c \ubca1\ud130\uc73c\ub85c \uc778\ucf54\ub529\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc778\ucf54\ub354\n-----------\n\nSeq2Seq \ub124\ud2b8\uc6cc\ud06c\uc758 \uc778\ucf54\ub354\ub294 \uc785\ub825 \ubb38\uc7a5\uc758 \ubaa8\ub4e0 \ub2e8\uc5b4\uc5d0 \ub300\ud574 \uc5b4\ub5a4 \uac12\uc744\n\ucd9c\ub825\ud558\ub294 RNN\uc785\ub2c8\ub2e4. \ubaa8\ub4e0 \uc785\ub825 \ub2e8\uc5b4\uc5d0 \ub300\ud574 \uc778\ucf54\ub354\ub294 \ubca1\ud130\uc640\n\uc740\ub2c9 \uc0c1\ud0dc\ub97c \ucd9c\ub825\ud558\uace0 \ub2e4\uc74c \uc785\ub825 \ub2e8\uc5b4\ub97c \uc704\ud574 \uadf8 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/encoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub514\ucf54\ub354\n-----------\n\n\ub514\ucf54\ub354\ub294 \uc778\ucf54\ub354 \ucd9c\ub825 \ubca1\ud130\ub97c \ubc1b\uc544\uc11c \ubc88\uc5ed\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud55c \ub2e8\uc5b4 \uc2dc\ud000\uc2a4\ub97c\n\ucd9c\ub825\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uac04\ub2e8\ud55c \ub514\ucf54\ub354\n^^^^^^^^^^^^^^\n\n\uac00\uc7a5 \uac04\ub2e8\ud55c Seq2Seq \ub514\ucf54\ub354\ub294 \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\ub9cc\uc744 \uc774\uc6a9\ud569\ub2c8\ub2e4.\n\uc774 \ub9c8\uc9c0\ub9c9 \ucd9c\ub825\uc740 \uc804\uccb4 \uc2dc\ud000\uc2a4\uc5d0\uc11c \ubb38\ub9e5\uc744 \uc778\ucf54\ub4dc\ud558\uae30 \ub54c\ubb38\uc5d0\n*\ubb38\ub9e5 \ubca1\ud130(context vector)* \ub85c \ubd88\ub9bd\ub2c8\ub2e4. \uc774 \ubb38\ub9e5 \ubca1\ud130\ub294 \ub514\ucf54\ub354\uc758 \ucd08\uae30 \uc740\ub2c9 \uc0c1\ud0dc\ub85c\n\uc0ac\uc6a9 \ub429\ub2c8\ub2e4.\n\n\ub514\ucf54\ub529\uc758 \ub9e4 \ub2e8\uacc4\uc5d0\uc11c \ub514\ucf54\ub354\uc5d0\uac8c \uc785\ub825 \ud1a0\ud070\uacfc \uc740\ub2c9 \uc0c1\ud0dc\uac00 \uc8fc\uc5b4\uc9d1\ub2c8\ub2e4.\n\ucd08\uae30 \uc785\ub825 \ud1a0\ud070\uc740 \ubb38\uc790\uc5f4-\uc2dc\uc791 (start-of-string) ``<SOS>`` \ud1a0\ud070\uc774\uace0,\n\uccab \uc740\ub2c9 \uc0c1\ud0dc\ub294 \ubb38\ub9e5 \ubca1\ud130(\uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc) \uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/decoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        output = self.embedding(input).view(1, 1, -1)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.softmax(self.out(output[0]))\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ubaa8\ub378\uc758 \uacb0\uacfc\ub97c \ud559\uc2b5\ud558\uace0 \uad00\ucc30\ud558\ub294 \uac83\uc744 \uad8c\uc7a5\ud558\uc9c0\ub9cc,\n\uacf5\uac04\uc744 \uc808\uc57d\ud558\uae30 \uc704\ud574 \ucd5c\uc885 \ubaa9\uc801\uc9c0\ub85c \ubc14\ub85c \uc774\ub3d9\ud574\uc11c\nAttention \uba54\ucee4\ub2c8\uc998\uc744 \uc18c\uac1c \ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Attention \ub514\ucf54\ub354\n^^^^^^^^^^^^^^^^^\n\n\ubb38\ub9e5 \ubca1\ud130\ub9cc \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354 \uc0ac\uc774\ub85c \uc804\ub2ec \ub41c\ub2e4\uba74, \ub2e8\uc77c \ubca1\ud130\uac00 \uc804\uccb4 \ubb38\uc7a5\uc744\n\uc778\ucf54\ub529 \ud574\uc57c\ud558\ub294 \ubd80\ub2f4\uc744 \uac00\uc9c0\uac8c \ub429\ub2c8\ub2e4.\n\nAttention\uc740 \ub514\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c\uac00 \uc790\uae30 \ucd9c\ub825\uc758 \ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc778\ucf54\ub354 \ucd9c\ub825\uc758\n\ub2e4\ub978 \ubd80\ubd84\uc5d0 \"\uc9d1\uc911\" \ud560 \uc218 \uc788\uac8c \ud569\ub2c8\ub2e4. \uccab\uc9f8 *Attention \uac00\uc911\uce58* \uc758 \uc138\ud2b8\ub97c\n\uacc4\uc0b0\ud569\ub2c8\ub2e4. \uc774\uac83\uc740 \uac00\uc911\uce58 \uc870\ud569\uc744 \ub9cc\ub4e4\uae30 \uc704\ud574\uc11c \uc778\ucf54\ub354 \ucd9c\ub825 \ubca1\ud130\uc640\n\uacf1\ud574\uc9d1\ub2c8\ub2e4. \uadf8 \uacb0\uacfc(\ucf54\ub4dc\uc5d0\uc11c ``attn_applied``)\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758\n\ud2b9\uc815 \ubd80\ubd84\uc5d0 \uad00\ud55c \uc815\ubcf4\ub97c \ud3ec\ud568\ud574\uc57c\ud558\uace0 \ub530\ub77c\uc11c \ub514\ucf54\ub354\uac00 \uc54c\ub9de\uc740 \ucd9c\ub825\n\ub2e8\uc5b4\ub97c \uc120\ud0dd\ud558\ub294 \uac83\uc744 \ub3c4\uc640\uc90d\ub2c8\ub2e4.\n\n.. figure:: https://i.imgur.com/1152PYf.png\n   :alt:\n\n\uc5b4\ud150\uc158 \uac00\uc911\uce58 \uacc4\uc0b0\uc740 \ub514\ucf54\ub354\uc758 \uc785\ub825 \ubc0f \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc785\ub825\uc73c\ub85c\n\uc0ac\uc6a9\ud558\ub294 \ub2e4\ub978 feed-forwad \uacc4\uce35\uc778 ``attn`` \uc73c\ub85c \uc218\ud589\ub429\ub2c8\ub2e4.\n\ud559\uc2b5 \ub370\uc774\ud130\uc5d0\ub294 \ubaa8\ub4e0 \ud06c\uae30\uc758 \ubb38\uc7a5\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc774 \uacc4\uce35\uc744 \uc2e4\uc81c\ub85c\n\ub9cc\ub4e4\uace0 \ud559\uc2b5\uc2dc\ud0a4\ub824\uba74 \uc801\uc6a9 \ud560 \uc218 \uc788\ub294 \ucd5c\ub300 \ubb38\uc7a5 \uae38\uc774 (\uc778\ucf54\ub354 \ucd9c\ub825\uc744 \uc704\ud55c \uc785\ub825 \uae38\uc774)\ub97c\n\uc120\ud0dd\ud574\uc57c \ud569\ub2c8\ub2e4. \ucd5c\ub300 \uae38\uc774\uc758 \ubb38\uc7a5\uc740 \ubaa8\ub4e0 Attention \uac00\uc911\uce58\ub97c \uc0ac\uc6a9\ud558\uc9c0\ub9cc\n\ub354 \uc9e7\uc740 \ubb38\uc7a5\uc740 \ucc98\uc74c \uba87 \uac1c\ub9cc \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n        super(AttnDecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n        self.out = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, input, hidden, encoder_outputs):\n        embedded = self.embedding(input).view(1, 1, -1)\n        embedded = self.dropout(embedded)\n\n        attn_weights = F.softmax(\n            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n                                 encoder_outputs.unsqueeze(0))\n\n        output = torch.cat((embedded[0], attn_applied[0]), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n\n        output = F.log_softmax(self.out(output[0]), dim=1)\n        return output, hidden, attn_weights\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n  limitation by using a relative position approach. Read about \"local\n  attention\" in `Effective Approaches to Attention-based Neural Machine\n  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n\n\ud559\uc2b5\n========\n\n\ud559\uc2b5 \ub370\uc774\ud130 \uc900\ube44\n-----------------------\n\n\ud559\uc2b5\uc744 \uc704\ud574\uc11c, \uac01 \uc30d\ub9c8\ub2e4 \uc785\ub825 Tensor(\uc785\ub825 \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \uc8fc\uc18c)\uc640\n\ubaa9\ud45c Tensor(\ubaa9\ud45c \ubb38\uc7a5\uc758 \ub2e8\uc5b4 \uc8fc\uc18c)\uac00 \ud544\uc694\ud569\ub2c8\ub2e4. \uc774 \ubca1\ud130\ub4e4\uc744\n\uc0dd\uc131\ud558\ub294 \ub3d9\uc548 \ub450 \uc2dc\ud000\uc2a4\uc5d0 EOS \ud1a0\ud070\uc744 \ucd94\uac00 \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \ud559\uc2b5\n------------------\n\n\ud559\uc2b5\uc744 \uc704\ud574\uc11c \uc778\ucf54\ub354\uc5d0 \uc785\ub825 \ubb38\uc7a5\uc744 \ub123\uace0 \ubaa8\ub4e0 \ucd9c\ub825\uacfc \ucd5c\uc2e0 \uc740\ub2c9 \uc0c1\ud0dc\ub97c\n\ucd94\uc801\ud569\ub2c8\ub2e4. \uadf8\ub7f0 \ub2e4\uc74c \ub514\ucf54\ub354\uc5d0 \uccab \ubc88\uc9f8 \uc785\ub825\uc73c\ub85c ``<SOS>`` \ud1a0\ud070\uacfc\n\uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\uac00 \uccab\ubc88\uca68 \uc740\ub2c9 \uc0c1\ud0dc\ub85c \uc81c\uacf5\ub429\ub2c8\ub2e4.\n\n\"Teacher forcing\"\uc740 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \ub514\ucf54\ub354\uc758 \uc608\uce21\uc744 \uc0ac\uc6a9\ud558\ub294 \ub300\uc2e0\n\uc2e4\uc81c \ubaa9\ud45c \ucd9c\ub825\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ucee8\uc149\uc785\ub2c8\ub2e4.\n\"Teacher forcing\"\uc744 \uc0ac\uc6a9\ud558\uba74 \uc218\ub834\uc774 \ube68\ub9ac\ub418\uc9c0\ub9cc `\ud559\uc2b5\ub41c \ub124\ud2b8\uc6cc\ud06c\uac00\n\uc798\ubabb \uc0ac\uc6a9\ub420 \ub54c \ubd88\uc548\uc815\uc131\uc744 \ubcf4\uc785\ub2c8\ub2e4.\n<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf>`__.\n\nTeacher-forced \ub124\ud2b8\uc6cc\ud06c\uc758 \ucd9c\ub825\uc774 \uc77c\uad00\ub41c \ubb38\ubc95\uc73c\ub85c \uc77d\uc9c0\ub9cc \uc815\ud655\ud55c\n\ubc88\uc5ed\uacfc\ub294 \uac70\ub9ac\uac00 \uba40\ub2e4\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc9c1\uad00\uc801\uc73c\ub85c \ucd9c\ub825 \ubb38\ubc95\uc744\n\ud45c\ud604\ud558\ub294 \ubc95\uc744 \ubc30\uc6b0\uace0 \uad50\uc0ac\uac00 \ucc98\uc74c \uba87 \ub2e8\uc5b4\ub97c \ub9d0\ud558\uba74 \uc758\ubbf8\ub97c \"\uc120\ud0dd\" \ud560 \uc218 \uc788\uc9c0\ub9cc,\n\ubc88\uc5ed\uc5d0\uc11c \ucc98\uc74c\uc73c\ub85c \ubb38\uc7a5\uc744 \ub9cc\ub4dc\ub294 \ubc95\uc740 \uc798 \ubc30\uc6b0\uc9c0 \ubabb\ud569\ub2c8\ub2e4.\n\nPyTorch\uc758 autograd \uac00 \uc81c\uacf5\ud558\ub294 \uc790\uc720 \ub355\ubd84\uc5d0 \uac04\ub2e8\ud55c If \ubb38\uc73c\ub85c\nTeacher Forcing\uc744 \uc0ac\uc6a9\ud560\uc9c0 \uc544\ub2c8\uba74 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc744\uc9c0\ub97c \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\ub354 \ub9ce\uc774 \uc0ac\uc6a9\ud558\ub824\uba74 ``teacher_forcing_ratio`` \ub97c \ud655\uc778\ud558\uc2ed\uc2dc\uc624.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    encoder_hidden = encoder.initHidden()\n\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing \ud3ec\ud568: \ubaa9\ud45c\ub97c \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc804\ub2ec\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Teacher forcing \ubbf8\ud3ec\ud568: \uc790\uc2e0\uc758 \uc608\uce21\uc744 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud560 \ubd80\ubd84\uc744 \ud788\uc2a4\ud1a0\ub9ac\uc5d0\uc11c \ubd84\ub9ac\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uac83\uc740 \ud604\uc7ac \uc2dc\uac04\uacfc \uc9c4\ud589\ub960%\uc744 \uace0\ub824\ud574 \uacbd\uacfc\ub41c \uc2dc\uac04\uacfc \ub0a8\uc740 \uc608\uc0c1\n\uc2dc\uac04\uc744 \ucd9c\ub825\ud558\ub294 \ud5ec\ud37c \ud568\uc218\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc804\uccb4 \ud559\uc2b5 \uacfc\uc815\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n-  \ud0c0\uc774\uba38 \uc2dc\uc791\n-  optimizers\uc640 criterion \ucd08\uae30\ud654\n-  \ud559\uc2b5 \uc30d\uc758 \uc138\ud2b8 \uc0dd\uc131\n-  \ub3c4\uc2dd\ud654\ub97c \uc704\ud55c \ube48 \uc190\uc2e4 \ubc30\uc5f4 \uc2dc\uc791\n\n\uadf8\ub7f0 \ub2e4\uc74c \uc6b0\ub9ac\ub294 \uc5ec\ub7ec \ubc88 ``train`` \uc744 \ud638\ucd9c\ud558\uba70 \ub54c\ub85c\ub294 \uc9c4\ud589\ub960\n(\uc608\uc81c\uc758 %, \ud604\uc7ac\uae4c\uc9c0\uc758 \uc608\uc0c1 \uc2dc\uac04)\uacfc \ud3c9\uade0 \uc190\uc2e4\uc744 \ucd9c\ub825\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # print_every \ub9c8\ub2e4 \ucd08\uae30\ud654\n    plot_loss_total = 0  # plot_every \ub9c8\ub2e4 \ucd08\uae30\ud654\n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacb0\uacfc \ub3c4\uc2dd\ud654\n----------------\n\nmatplotlib\ub85c \ud559\uc2b5 \uc911\uc5d0 \uc800\uc7a5\ub41c \uc190\uc2e4 \uac12 ``plot_losses`` \uc758 \ubc30\uc5f4\uc744\n\uc0ac\uc6a9\ud558\uc5ec \ub3c4\uc2dd\ud654\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # \uc8fc\uae30\uc801\uc778 \uac04\uaca9\uc5d0 \uc774 locator\uac00 tick\uc744 \uc124\uc815\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uac00\n==========\n\n\ud3c9\uac00\ub294 \ub300\ubd80\ubd84 \ud559\uc2b5\uacfc \ub3d9\uc77c\ud558\uc9c0\ub9cc \ubaa9\ud45c\uac00 \uc5c6\uc73c\ubbc0\ub85c \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \ub514\ucf54\ub354\uc758\n\uc608\uce21\uc744 \ub418\ub3cc\ub824 \uc804\ub2ec\ud569\ub2c8\ub2e4.\n\ub2e8\uc5b4\ub97c \uc608\uce21\ud560 \ub54c\ub9c8\ub2e4 \uadf8 \ub2e8\uc5b4\ub97c \ucd9c\ub825 \ubb38\uc790\uc5f4\uc5d0 \ucd94\uac00\ud569\ub2c8\ub2e4.\n\ub9cc\uc57d EOS \ud1a0\ud070\uc744 \uc608\uce21\ud558\uba74 \uac70\uae30\uc5d0\uc11c \uba48\ucda5\ub2c8\ub2e4.\n\ub098\uc911\uc5d0 \ub3c4\uc2dd\ud654\ub97c \uc704\ud574\uc11c \ub514\ucf54\ub354\uc758 Attention \ucd9c\ub825\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n\n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n        decoder_attentions = torch.zeros(max_length, max_length)\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            decoder_attentions[di] = decoder_attention.data\n            topv, topi = decoder_output.data.topk(1)\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(output_lang.index2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \uc138\ud2b8\uc5d0 \uc788\ub294 \uc784\uc758\uc758 \ubb38\uc7a5\uc744 \ud3c9\uac00\ud558\uace0\n\uc785\ub825, \ubaa9\ud45c \ubc0f \ucd9c\ub825\uc744 \ucd9c\ub825\ud558\uc5ec \uc8fc\uad00\uc801\uc778 \ud488\uc9c8 \ud310\ub2e8\uc744 \ub0b4\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, attentions = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5\uacfc \ud3c9\uac00\n=======================\n\n\uc774\ub7ec\ud55c \ubaa8\ub4e0 \ud5ec\ud37c \ud568\uc218\ub97c \uc774\uc6a9\ud574\uc11c (\ucd94\uac00 \uc791\uc5c5\ucc98\ub7fc \ubcf4\uc774\uc9c0\ub9cc \uc5ec\ub7ec \uc2e4\ud5d8\uc744\n\ub354 \uc27d\uac8c \uc218\ud589 \ud560 \uc218 \uc788\uc74c) \uc2e4\uc81c\ub85c \ub124\ud2b8\uc6cc\ud06c\ub97c \ucd08\uae30\ud654\ud558\uace0 \ud559\uc2b5\uc744\n\uc2dc\uc791\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc785\ub825 \ubb38\uc7a5\uc774 \ub9ce\uc774 \ud544\ud130\ub9c1\ub418\uc5c8\uc74c\uc744 \uae30\uc5b5\ud558\uc2ed\uc2dc\uc624. \uc774 \uc791\uc740 \ub370\uc774\ud130 \uc138\ud2b8\uc758\n\uacbd\uc6b0 256 \ud06c\uae30\uc758 \uc740\ub2c9 \ub178\ub4dc(hidden node)\uc640 \ub2e8\uc77c GRU \uacc4\uce35 \uac19\uc740 \uc0c1\ub300\uc801\uc73c\ub85c \uc791\uc740\n\ub124\ud2b8\uc6cc\ud06c\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. MacBook CPU\uc5d0\uc11c \uc57d 40\ubd84 \ud6c4\uc5d0\n\ud569\ub9ac\uc801\uc778 \uacb0\uacfc\ub97c \uc5bb\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n.. Note::\n   \uc774 \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uba74 \ud559\uc2b5, \ucee4\ub110 \uc911\ub2e8, \ud3c9\uac00\ub97c \ud560 \uc218 \uc788\uace0 \ub098\uc911\uc5d0\n   \uc774\uc5b4\uc11c \ud559\uc2b5\uc744 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\uac00 \ucd08\uae30\ud654 \ub41c \ud589\uc744\n   \uc8fc\uc11d \ucc98\ub9ac\ud558\uace0 ``trainIters`` \ub97c \ub2e4\uc2dc \uc2e4\ud589\ud558\uc2ed\uc2dc\uc624.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hidden_size = 256\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n\ntrainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Attention \uc2dc\uac01\ud654\n---------------------\n\nAttention \uba54\ucee4\ub2c8\uc998\uc758 \uc720\uc6a9\ud55c \uc18d\uc131\uc740 \ud558\ub098\ub294 \ud574\uc11d \uac00\ub2a5\uc131\uc774 \ub192\uc740 \ucd9c\ub825\uc785\ub2c8\ub2e4.\n\uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \uc778\ucf54\ub354 \ucd9c\ub825\uc5d0 \uac00\uc911\uce58\ub97c \ubd80\uc5ec\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\ubbc0\ub85c\n\uac01 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ub124\ud2b8\uc6cc\ud06c\uac00 \uac00\uc7a5 \uc9d1\uc911\ub418\ub294 \uc704\uce58\ub97c \ud30c\uc545\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\nAttention \ucd9c\ub825\uc744 \ud589\ub82c\ub85c \ud45c\uc2dc\ud558\uae30 \uc704\ud574 ``plt.matshow(attentions)`` \ub97c\n\uac04\ub2e8\ud558\uac8c \uc2e4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc5f4\uc740 \uc785\ub825 \ub2e8\uacc4\uc640 \ud589\uc774 \ucd9c\ub825 \ub2e8\uacc4\uc785\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output_words, attentions = evaluate(\n    encoder1, attn_decoder1, \"je suis trop froid .\")\nplt.matshow(attentions.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub354 \ub098\uc740 \ubcf4\uae30\ub97c \uc704\ud574 \ucd95\uacfc \ub77c\ubca8\uc744 \ub354\ud558\ub294 \ucd94\uac00 \uc791\uc5c5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n    # colorbar\ub85c \uadf8\ub9bc \uc124\uc815\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.numpy(), cmap='bone')\n    fig.colorbar(cax)\n\n    # \ucd95 \uc124\uc815\n    ax.set_xticklabels([''] + input_sentence.split(' ') +\n                       ['<EOS>'], rotation=90)\n    ax.set_yticklabels([''] + output_words)\n\n    # \ub9e4 \ud2f1\ub9c8\ub2e4 \ub77c\ubca8 \ubcf4\uc5ec\uc8fc\uae30\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n\n\ndef evaluateAndShowAttention(input_sentence):\n    output_words, attentions = evaluate(\n        encoder1, attn_decoder1, input_sentence)\n    print('input =', input_sentence)\n    print('output =', ' '.join(output_words))\n    showAttention(input_sentence, output_words, attentions)\n\n\nevaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n\nevaluateAndShowAttention(\"elle est trop petit .\")\n\nevaluateAndShowAttention(\"je ne crains pas de mourir .\")\n\nevaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc5f0\uc2b5\n=========\n\n-  \ub2e4\ub978 \ub370\uc774\ud130 \uc14b\uc744 \uc2dc\ub3c4\ud574 \ubcf4\uc2ed\uc2dc\uc624\n\n   -  \ub2e4\ub978 \uc5b8\uc5b4\uc30d\n   -  \uc0ac\ub78c \u2192 \uae30\uacc4 (e.g. IOT \uba85\ub839\uc5b4)\n   -  \ucc44\ud305 \u2192 \uc751\ub2f5\n   -  \uc9c8\ubb38 \u2192 \ub2f5\ubcc0\n\n-  word2vec \ub610\ub294 GloVe \uac19\uc740 \ubbf8\ub9ac \ud559\uc2b5\ub41c word embedding \uc73c\ub85c\n   embedding \uc744 \uad50\uccb4\ud558\uc2ed\uc2dc\uc624\n\n-  \ub354 \ub9ce\uc740 \ub808\uc774\uc5b4, \uc740\ub2c9 \uc720\ub2db, \ub354 \ub9ce\uc740 \ubb38\uc7a5\uc744 \uc0ac\uc6a9\ud558\uc2ed\uc2dc\uc624.\n   \ud559\uc2b5 \uc2dc\uac04\uacfc \uacb0\uacfc\ub97c \ube44\uad50\ud574 \ubcf4\uc2ed\uc2dc\uc624\n-  \ub9cc\uc57d \uac19\uc740 \uad6c\ubb38 \ub450\uac1c\uc758 \uc30d\uc73c\ub85c \ub41c \ubc88\uc5ed \ud30c\uc77c\uc744 \uc774\uc6a9\ud55c\ub2e4\uba74,\n   (``I am test \\t I am test``), \uc774\uac83\uc744 \uc624\ud1a0\uc778\ucf54\ub354\ub85c\n   \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n   \uc774\uac83\uc744 \uc2dc\ub3c4\ud574 \ubcf4\uc2ed\uc2dc\uc624:\n\n   -  \uc624\ud1a0\uc778\ucf54\ub354 \ud559\uc2b5\n   -  \uc778\ucf54\ub354 \ub124\ud2b8\uc6cc\ud06c \uc800\uc7a5\ud558\uae30\n   -  \uadf8 \uc0c1\ud0dc\uc5d0\uc11c \ubc88\uc5ed\uc744 \uc704\ud55c \uc0c8\ub85c\uc6b4 \ub514\ucf54\ub354 \ud559\uc2b5\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}