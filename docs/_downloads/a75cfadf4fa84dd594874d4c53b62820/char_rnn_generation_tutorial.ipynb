{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP:  \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \uc0dd\uc131\ud558\uae30\n********************************************************************************\n**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n  **\ubc88\uc5ed**: `\ud669\uc131\uc218 <https://github.com/adonisues>`_\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 3\uac1c\ub85c \uc774\ub904\uc9c4 \"\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP\"\uc758 2\ubc88\uc9f8 \ud29c\ud1a0\ub9ac\uc5bc\uc785\ub2c8\ub2e4.\n`\uccab\ubc88\uc9f8 \ud29c\ud1a0\ub9ac\uc5bc </intermediate/char_rnn_classification_tutorial>`\n\uc5d0\uc11c\ub294 \uc774\ub984\uc758 \uc5b8\uc5b4\ub97c \ubd84\ub958\ud558\uae30 \uc704\ud574 RNN\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n\uc774\ubc88\uc5d0\ub294 \ubc18\ub300\ub85c \uc5b8\uc5b4\ub85c \uc774\ub984\uc744 \uc0dd\uc131\ud560 \uc608\uc815\uc785\ub2c8\ub2e4.\n\n::\n\n    > python sample.py Russian RUS\n    Rovakov\n    Uantov\n    Shavakov\n\n    > python sample.py German GER\n    Gerren\n    Ereng\n    Rosher\n\n    > python sample.py Spanish SPA\n    Salla\n    Parer\n    Allan\n\n    > python sample.py Chinese CHI\n    Chan\n    Hang\n    Iun\n\n\uc6b0\ub9ac\ub294 \uba87 \uac1c\uc758 \uc120\ud615 \uacc4\uce35\uc73c\ub85c \uc791\uc740 RNN\uc744 \uc9c1\uc811 \ub9cc\ub4e4\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\uc804 \ud29c\ud1a0\ub9ac\uc5bc\uc778 \uc774\ub984\uc744 \uc77d\uc740 \ud6c4 \uadf8 \uc5b8\uc5b4\ub97c \uc608\uce21\ud558\ub294 \uac83\uacfc\uc758 \ud070 \ucc28\uc774\uc810\uc740\n\uc5b8\uc5b4\ub97c \uc785\ub825\ud558\uace0 \ud55c \ubc88\uc5d0 \ud55c \uae00\uc790\ub97c \uc0dd\uc131\ud558\uc5ec \ucd9c\ub825\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\uc5b8\uc5b4 \ud615\uc131(\ub2e8\uc5b4 \ub610\ub294 \ub2e4\ub978 \uace0\ucc28\uc6d0 \uad6c\uc870\ub85c\ub3c4 \uc218\ud589\ub420 \uc218 \uc788\uc74c)\uc744 \uc704\ud574\n\ubb38\uc790\ub97c \ubc18\ubcf5\uc801\uc73c\ub85c \uc608\uce21\ud558\ub294 \uac83\uc744 \"\uc5b8\uc5b4 \ubaa8\ub378\" \uc774\ub77c\uace0 \ud569\ub2c8\ub2e4.\n\n**\ucd94\ucc9c \uc790\ub8cc:**\n\nPytorch\ub97c \uc124\uce58\ud588\uace0, Python\uc744 \uc54c\uace0, Tensor\ub97c \uc774\ud574\ud55c\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4:\n\n-  https://pytorch.org/ \uc124\uce58 \uc548\ub0b4\n-  :doc:`/beginner/deep_learning_60min_blitz` PyTorch \uc2dc\uc791\ud558\uae30\n-  :doc:`/beginner/pytorch_with_examples` \ub113\uace0 \uae4a\uc740 \ud1b5\ucc30\uc744 \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/former_torchies_tutorial` \uc774\uc804 Lua Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c \uc790\ub8cc\n\nRNN\uacfc \uc791\ub3d9 \ubc29\uc2dd\uc744 \uc544\ub294 \uac83 \ub610\ud55c \uc720\uc6a9\ud569\ub2c8\ub2e4:\n\n-  `The Unreasonable Effectiveness of Recurrent Neural\n   Networks <https://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n   \uc2e4\uc0dd\ud65c \uc608\uc81c\ub97c \ubcf4\uc5ec \uc90d\ub2c8\ub2e4.\n-  `Understanding LSTM\n   Networks <https://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n   LSTM\uc5d0 \uad00\ud55c \uac83\uc774\uc9c0\ub9cc RNN\uc5d0 \uad00\ud574\uc11c\ub3c4 \uc720\uc775\ud569\ub2c8\ub2e4.\n\n\uc774\uc804 \ud29c\ud1a0\ub9ac\uc5bc\ub3c4 \ucd94\ucc9c\ud569\ub2c8\ub2e4. :doc:`/intermediate/char_rnn_classification_tutorial`\n\n\n\ub370\uc774\ud130 \uc900\ube44\n==================\n\n.. Note::\n   `\uc5ec\uae30 <https://download.pytorch.org/tutorial/data.zip>`_\n   \uc5d0\uc11c \ub370\uc774\ud130\ub97c \ub2e4\uc6b4 \ubc1b\uace0, \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624.\n\n\uc774 \uacfc\uc815\uc758 \ub354 \uc790\uc138\ud55c \uc0ac\ud56d\uc740 \uc9c0\ub09c \ud29c\ud1a0\ub9ac\uc5bc\uc744 \ubcf4\uc2ed\uc2dc\uc624.\n\uc694\uc57d\ud558\uba74, \uc904\ub9c8\ub2e4 \uc774\ub984\uc774 \uc801\ud78c \ud14d\uc2a4\ud2b8 \ud30c\uc77c ``data/names/[Language].txt`` \uc788\uc2b5\ub2c8\ub2e4.\n\uc774\uac83\uc744 array\ub85c \ubd84\ub9ac\ud558\uace0, Unicode\ub97c ASCII\ub85c \ubcc0\uacbd\ud558\uace0,\n\uc0ac\uc804 ``{language: [names ...]}`` \uc744 \ub9cc\ub4e4\uc5b4\uc11c \ub9c8\ubb34\ub9ac\ud569\ub2c8\ub2e4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport glob\nimport os\nimport unicodedata\nimport string\n\nall_letters = string.ascii_letters + \" .,;'-\"\nn_letters = len(all_letters) + 1 # EOS(end of sentence) \uae30\ud638 \ucd94\uac00\n\ndef findFiles(path): return glob.glob(path)\n\n# \uc720\ub2c8\ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 ASCII\ub85c \ubcc0\ud658, https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in all_letters\n    )\n\n# \ud30c\uc77c\uc744 \uc77d\uace0 \uc904 \ub2e8\uc704\ub85c \ubd84\ub9ac\ndef readLines(filename):\n    with open(filename, encoding='utf-8') as some_file:\n        return [unicodeToAscii(line.strip()) for line in some_file]\n\n# \uac01 \uc5b8\uc5b4\uc758 \uc774\ub984 \ubaa9\ub85d\uc778 category_lines \uc0ac\uc804 \uc0dd\uc131\ncategory_lines = {}\nall_categories = []\nfor filename in findFiles('data/names/*.txt'):\n    category = os.path.splitext(os.path.basename(filename))[0]\n    all_categories.append(category)\n    lines = readLines(filename)\n    category_lines[category] = lines\n\nn_categories = len(all_categories)\n\nif n_categories == 0:\n    raise RuntimeError('Data not found. Make sure that you downloaded data '\n        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n        'the current directory.')\n\nprint('# categories:', n_categories, all_categories)\nprint(unicodeToAscii(\"O'N\u00e9\u00e0l\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub124\ud2b8\uc6cc\ud06c \uc0dd\uc131\n====================\n\n\uc774 \ub124\ud2b8\uc6cc\ud06c\ub294 `\uc9c0\ub09c \ud29c\ud1a0\ub9ac\uc5bc\uc758 RNN <#Creating-the-Network>`__ \uc774\n\ub2e4\ub978 \uc785\ub825\ub4e4\uacfc \uc5f0\uacb0\ub418\ub294 category tensor\ub97c \ucd94\uac00 \uc778\uc790\ub85c \uac00\uc9c0\uac8c \ud655\uc7a5\ud569\ub2c8\ub2e4.\ncategory tensor\ub294 \ubb38\uc790 \uc785\ub825\uacfc \ub9c8\ucc2c\uac00\uc9c0\ub85c one-hot \ubca1\ud130\uc785\ub2c8\ub2e4.\n\n\uc5ed\uc790\uc8fc: \uae30\uc874 \uc785\ub825\uacfc category tensor\ub97c \uacb0\ud569\ud558\uc5ec \uc785\ub825\uc73c\ub85c \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0\n\uc785\ub825\uc758 \uc0ac\uc774\uc988\uac00 n_categories \ub9cc\ud07c \ucee4\uc9d1\ub2c8\ub2e4.\n\n\uc6b0\ub9ac\ub294 \ucd9c\ub825\uc744 \ub2e4\uc74c \ubb38\uc790\uc758 \ud655\ub960\ub85c \ud574\uc11d\ud569\ub2c8\ub2e4. \uc0d8\ud50c\ub9c1 \ud560 \ub54c,\n\uac00\uc7a5 \ud655\ub960\uc774 \ub192\uc740 \ubb38\uc790\uac00 \ub2e4\uc74c \uc785\ub825 \ubb38\uc790\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\n\ub354 \ub098\uc740 \ub3d9\uc791\uc744 \uc704\ud574 \ub450 \ubc88\uc9f8 \uc120\ud615 \ub808\uc774\uc5b4\n``o2o`` (\uc740\ub2c9\uacfc \ucd9c\ub825\uc744 \uacb0\ud569\ud55c \ud6c4) \ub97c \ucd94\uac00\ud588\uc2b5\ub2c8\ub2e4 .\n\ub610\ud55c Drop-out \uacc4\uce35\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uacc4\uce35\uc740 \uc8fc\uc5b4\uc9c4 \ud655\ub960(\uc5ec\uae30\uc11c\ub294 0.1)\ub85c\n`\ubb34\uc791\uc704\ub85c \uc785\ub825\uc744 0 # <https://arxiv.org/abs/1207.0580>`__ \uc73c\ub85c \ub9cc\ub4ed\ub2c8\ub2e4.\n\uc77c\ubc18\uc801\uc73c\ub85c \uc785\ub825\uc744 \ud750\ub9ac\uac8c \ud574\uc11c \uacfc\uc801\ud569\uc744 \ub9c9\ub294 \ub370 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c \uc6b0\ub9ac\ub294 \uace0\uc758\ub85c \uc77c\ubd80 \ud63c\ub3c8\uc744 \ucd94\uac00\ud558\uace0 \uc0d8\ud50c\ub9c1 \ub2e4\uc591\uc131\uc744 \ub192\uc774\uae30\n\uc704\ud574 \ub124\ud2b8\uc6cc\ud06c\uc758 \ub9c8\uc9c0\ub9c9\uc5d0 \uc774\uac83\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n.. figure:: https://i.imgur.com/jzVrf7f.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n        self.dropout = nn.Dropout(0.1)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, category, input, hidden):\n        input_combined = torch.cat((category, input, hidden), 1)\n        hidden = self.i2h(input_combined)\n        output = self.i2o(input_combined)\n        output_combined = torch.cat((hidden, output), 1)\n        output = self.o2o(output_combined)\n        output = self.dropout(output)\n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5\n=========\n\ud559\uc2b5 \uc900\ube44\n----------------------\n\n\uc81c\uc77c \uba3c\uc800 (category, line)\uc758 \ubb34\uc791\uc704 \uc30d\uc744 \uc5bb\ub294 \ud568\uc218:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\n# \ubaa9\ub85d\uc5d0\uc11c \ubb34\uc791\uc704 \uc544\uc774\ud15c \ubc18\ud658\ndef randomChoice(l):\n    return l[random.randint(0, len(l) - 1)]\n\n# \uc784\uc758\uc758 category \ubc0f \uadf8 category\uc5d0\uc11c \ubb34\uc791\uc704 \uc904(\uc774\ub984) \uc5bb\uae30\ndef randomTrainingPair():\n    category = randomChoice(all_categories)\n    line = randomChoice(category_lines[category])\n    return category, line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uac01 \uc2dc\uac04 \ub2e8\uacc4 \ub9c8\ub2e4 (\uc989, \ud559\uc2b5 \ub2e8\uc5b4\uc758 \uac01 \ubb38\uc790 \ub9c8\ub2e4) \ub124\ud2b8\uc6cc\ud06c\uc758 \uc785\ub825\uc740\n``(\uc5b8\uc5b4, \ud604\uc7ac \ubb38\uc790, \uc740\ub2c9 \uc0c1\ud0dc)`` \uac00 \ub418\uace0, \ucd9c\ub825\uc740\n``(\ub2e4\uc74c \ubb38\uc790, \ub2e4\uc74c \uc740\ub2c9 \uc0c1\ud0dc)`` \uac00 \ub41c\ub2e4. \ub530\ub77c\uc11c \uac01 \ud559\uc2b5 \uc138\ud2b8 \ub9c8\ub2e4\n\uc5b8\uc5b4, \uc785\ub825 \ubb38\uc790\uc758 \uc138\ud2b8, \ucd9c\ub825/\ubaa9\ud45c \ubb38\uc790\uc758 \uc138\ud2b8\uac00 \ud544\uc694\ud558\ub2e4.\n\n\uac01 \uc2dc\uac04 \ub2e8\uacc4\ub9c8\ub2e4 \ud604\uc7ac \ubb38\uc790\uc5d0\uc11c \ub2e4\uc74c \ubb38\uc790\ub97c \uc608\uce21\ud558\uae30 \ub54c\ubb38\uc5d0,\n\ubb38\uc790 \uc30d\uc740 \ud55c \uc904(\ud558\ub098\uc758 \uc774\ub984)\uc5d0\uc11c \uc5f0\uc18d\ub41c \ubb38\uc790 \uadf8\ub8f9\uc785\ub2c8\ub2e4. - \uc608\ub97c \ub4e4\uc5b4 ``\"ABCD<EOS>\"`` \ub294\n(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"D\"), (\"D\", \"EOS\") \ub85c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\n.. figure:: https://i.imgur.com/JH58tXY.png\n   :alt:\n\nCategory(\uc5b8\uc5b4) Tensor\ub294 ``<1 x n_categories>`` \ud06c\uae30\uc758 `One-hot\nTensor <https://en.wikipedia.org/wiki/One-hot>`__ \uc785\ub2c8\ub2e4.\n\ud559\uc2b5\uc2dc\uc5d0 \ubaa8\ub4e0 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc774\uac83\uc744 \uc804\ub2ec\ud569\ub2c8\ub2e4.\n- \uc774\uac83\uc740 \uc124\uacc4 \uc120\ud0dd\uc0ac\ud56d\uc73c\ub85c, \ucd08\uae30 \uc740\ub2c9 \uc0c1\ud0dc \ub610\ub294\n\ub610 \ub2e4\ub978 \uc804\ub7b5\uc758 \ubd80\ubd84\uc73c\ub85c \ud3ec\ud568\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Category\ub97c \uc704\ud55c One-hot \ubca1\ud130\ndef categoryTensor(category):\n    li = all_categories.index(category)\n    tensor = torch.zeros(1, n_categories)\n    tensor[0][li] = 1\n    return tensor\n\n# \uc785\ub825\uc744 \uc704\ud55c \ucc98\uc74c\ubd80\ud130 \ub9c8\uc9c0\ub9c9 \ubb38\uc790(EOS \uc81c\uc678)\uae4c\uc9c0\uc758  One-hot \ud589\ub82c\ndef inputTensor(line):\n    tensor = torch.zeros(len(line), 1, n_letters)\n    for li in range(len(line)):\n        letter = line[li]\n        tensor[li][0][all_letters.find(letter)] = 1\n    return tensor\n\n# \ubaa9\ud45c\ub97c \uc704\ud55c \ub450\ubc88\uc9f8 \ubb38\uc790 \ubd80\ud130 \ub9c8\uc9c0\ub9c9(EOS) \uae4c\uc9c0\uc758 LongTensor\ndef targetTensor(line):\n    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n    letter_indexes.append(n_letters - 1) # EOS\n    return torch.LongTensor(letter_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ub3d9\uc548 \ud3b8\uc758\ub97c \uc704\ud574 \ubb34\uc791\uc704\ub85c (category[\uc5b8\uc5b4], line[\uc774\ub984])\uc744 \uac00\uc838\uc624\uace0\n\uadf8\uac83\uc744 \ud544\uc694\ud55c \ud615\ud0dc (category[\uc5b8\uc5b4], input[\ud604\uc7ac \ubb38\uc790], target[\ub2e4\uc74c \ubb38\uc790]) Tensor\ub85c \ubc14\uafb8\ub294\n``randomTrainingExample`` \ud568\uc218\ub97c \ub9cc\ub4e4 \uc608\uc815\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc784\uc758\uc758 Category\uc5d0\uc11c Category, Input, Target Tensor\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\ndef randomTrainingExample():\n    category, line = randomTrainingPair()\n    category_tensor = categoryTensor(category)\n    input_line_tensor = inputTensor(line)\n    target_line_tensor = targetTensor(line)\n    return category_tensor, input_line_tensor, target_line_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub124\ud2b8\uc6cc\ud06c \ud559\uc2b5\n--------------------\n\n\ub9c8\uc9c0\ub9c9 \ucd9c\ub825\ub9cc \uc0ac\uc6a9\ud558\ub294 \ubd84\ub958\uc640 \ub2ec\ub9ac, \ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc608\uce21\uc744 \uc218\ud589\ud558\ubbc0\ub85c\n\ubaa8\ub4e0 \ub2e8\uacc4\uc5d0\uc11c \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\nAutograd\uc758 \ub9c8\ubc95\uc774 \uac01 \ub2e8\uacc4\uc758 \uc190\uc2e4\ub4e4\uc744 \uac04\ub2e8\ud558\uac8c \ud569\ud558\uace0 \ub9c8\uc9c0\ub9c9\uc5d0\n\uc5ed\uc804\ud30c\ub97c \ud638\ucd9c\ud558\uac8c \ud574\uc90d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n\nlearning_rate = 0.0005\n\ndef train(category_tensor, input_line_tensor, target_line_tensor):\n    target_line_tensor.unsqueeze_(-1)\n    hidden = rnn.initHidden()\n\n    rnn.zero_grad()\n\n    loss = 0\n\n    for i in range(input_line_tensor.size(0)):\n        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n        l = criterion(output, target_line_tensor[i])\n        loss += l\n\n    loss.backward()\n\n    for p in rnn.parameters():\n        p.data.add_(p.grad.data, alpha=-learning_rate)\n\n    return output, loss.item() / input_line_tensor.size(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5\uc5d0 \uac78\ub9ac\ub294 \uc2dc\uac04\uc744 \ucd94\uc801\ud558\uae30 \uc704\ud574 \uc0ac\ub78c\uc774 \uc77d\uc744 \uc218 \uc788\ub294 \ubb38\uc790\uc5f4\uc744\n\ubc18\ud658\ud558\ub294``timeSince (timestamp)`` \ud568\uc218\ub97c \ucd94\uac00\ud569\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5\uc740 \uc77c\uc0c1\uc801\uc778 \uc77c\uc785\ub2c8\ub2e4. - \uba87 \ubc88 train() \uc744 \ud638\ucd9c\ud558\uace0, \uba87 \ubd84 \uc815\ub3c4\n\uae30\ub2e4\ub838\ub2e4\uac00 ``print_every`` \ub9c8\ub2e4 \ud604\uc7ac \uc2dc\uac04\uacfc \uc190\uc2e4\uc744 \ucd9c\ub825\ud558\uace0,\n\ub098\uc911\uc5d0 \ub3c4\uc2dd\ud654\ub97c \uc704\ud574  ``plot_every`` \ub9c8\ub2e4 ``all_losses`` \uc5d0\n\ud3c9\uade0 \uc190\uc2e4\uc744 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rnn = RNN(n_letters, 128, n_letters)\n\nn_iters = 100000\nprint_every = 5000\nplot_every = 500\nall_losses = []\ntotal_loss = 0 # plot_every \ub9c8\ub2e4 \ucd08\uae30\ud654\n\nstart = time.time()\n\nfor iter in range(1, n_iters + 1):\n    output, loss = train(*randomTrainingExample())\n    total_loss += loss\n\n    if iter % print_every == 0:\n        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n\n    if iter % plot_every == 0:\n        all_losses.append(total_loss / plot_every)\n        total_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc190\uc2e4 \ub3c4\uc2dd\ud654\n-------------------\n\nall\\_losses\ub97c \uc774\uc6a9\ud55c \uc190\uc2e4\uc758 \ub3c4\uc2dd\ud654\ub294\n\ub124\ud2b8\uc6cc\ud06c\uc758 \ud559\uc2b5 \uc0c1\ud0dc\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub124\ud2b8\uc6cc\ud06c \uc0d8\ud50c\ub9c1\n====================\n\n\uc0d8\ud50c\ub9c1\uc744 \uc704\ud574\uc11c, \ub124\ud2b8\uc6cc\ud06c\uc5d0 \ud558\ub098\uc758 \uae00\uc790\ub97c \uc8fc\uace0 \ub2e4\uc74c \ubb38\uc790\ub97c \ubb3c\uc5b4\ubcf4\uace0\n\uc774\uac83\uc744 \ub2e4\uc74c \ubb38\uc790\ub85c \uc804\ub2ec\ud558\ub294 \uac83\uc744 EOS \ud1a0\ud070\uae4c\uc9c0 \ubc18\ubcf5\ud569\ub2c8\ub2e4.\n\n-  \uc785\ub825 \uce74\ud14c\uace0\ub9ac(\uc5b8\uc5b4), \uc2dc\uc791 \ubb38\uc790, \ube44\uc5b4 \uc788\ub294 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc704\ud55c Tensor\ub97c \uc0dd\uc131\ud558\uc2ed\uc2dc\uc624\n-  \uc2dc\uc791 \ubb38\uc790\ub85c ``output_name`` \ubb38\uc790\uc5f4\uc744 \uc0dd\uc131\ud558\uc2ed\uc2dc\uc624\n-  \ucd5c\ub300 \ucd9c\ub825 \uae38\uc774\uae4c\uc9c0,\n\n   -  \ud604\uc7ac \ubb38\uc790\ub97c \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc804\ub2ec\ud558\uc2ed\uc2dc\uc624.\n   -  \uac00\uc7a5 \ub192\uc740 \ucd9c\ub825\uc5d0\uc11c \ub2e4\uc74c \ubb38\uc790\uc640 \ub2e4\uc74c \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc5bb\uc73c\uc2ed\uc2dc\uc624\n   -  \ub9cc\uc77c \ubb38\uc790\uac00 EOS\uba74, \uc5ec\uae30\uc11c \uba48\ucd94\uc2ed\uc2dc\uc624\n   -  \ub9cc\uc77c \uc77c\ubc18\uc801\uc778 \ubb38\uc790\ub77c\uba74, ``output_name`` \uc5d0 \ucd94\uac00\ud558\uace0 \uacc4\uc18d\ud558\uc2ed\uc2dc\uc624\n\n-  \ub9c8\uc9c0\ub9c9 \uc774\ub984\uc744 \ubc18\ud658\ud558\uc2ed\uc2dc\uc624\n\n.. Note::\n   \uc2dc\uc791 \ubb38\uc790\ub97c \uc8fc\ub294 \uac83 \uc678\uc5d0 \"\ubb38\uc790\uc5f4 \uc2dc\uc791\" \ud1a0\ud070\uc744 \ud559\uc2b5\uc5d0\n   \ud3ec\ud568\ub418\uac8c \ud558\uace0 \ub124\ud2b8\uc6cc\ud06c\uac00 \uc790\uccb4\uc801\uc73c\ub85c \uc2dc\uc791 \ubb38\uc790\ub97c \uc120\ud0dd\ud558\uac8c \ud558\ub294\n   \ub2e4\ub978 \ubc29\ubc95\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_length = 20\n\n# \uce74\ud14c\uace0\ub9ac\uc640 \uc2dc\uc791 \ubb38\uc790\ub85c \ubd80\ud130 \uc0d8\ud50c\ub9c1 \ud558\uae30\ndef sample(category, start_letter='A'):\n    with torch.no_grad():  # \uc0d8\ud50c\ub9c1\uc5d0\uc11c \ud788\uc2a4\ud1a0\ub9ac\ub97c \ucd94\uc801\ud560 \ud544\uc694 \uc5c6\uc74c\n        category_tensor = categoryTensor(category)\n        input = inputTensor(start_letter)\n        hidden = rnn.initHidden()\n\n        output_name = start_letter\n\n        for i in range(max_length):\n            output, hidden = rnn(category_tensor, input[0], hidden)\n            topv, topi = output.topk(1)\n            topi = topi[0][0]\n            if topi == n_letters - 1:\n                break\n            else:\n                letter = all_letters[topi]\n                output_name += letter\n            input = inputTensor(letter)\n\n        return output_name\n\n# \ud558\ub098\uc758 \uce74\ud14c\uace0\ub9ac\uc640 \uc5ec\ub7ec \uc2dc\uc791 \ubb38\uc790\ub4e4\ub85c \uc5ec\ub7ec \uac1c\uc758 \uc0d8\ud50c \uc5bb\uae30\ndef samples(category, start_letters='ABC'):\n    for start_letter in start_letters:\n        print(sample(category, start_letter))\n\nsamples('Russian', 'RUS')\n\nsamples('German', 'GER')\n\nsamples('Spanish', 'SPA')\n\nsamples('Chinese', 'CHI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exercises\n=========\n\n-  Try with a different dataset of category -> line, for example:\n\n   -  Fictional series -> Character name\n   -  Part of speech -> Word\n   -  Country -> City\n\n-  Use a \"start of sentence\" token so that sampling can be done without\n   choosing a start letter\n-  Get better results with a bigger and/or better shaped network\n\n   -  Try the nn.LSTM and nn.GRU layers\n   -  \uc0c1\uc704 \uc218\uc900 \ub124\ud2b8\uc6cc\ud06c\ub85c \uc5ec\ub7ec \uac1c\uc758 \uc774\ub7f0 RNN\uc744  \uacb0\ud569\ud574 \ubcf4\uc2ed\uc2dc\uc624\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}