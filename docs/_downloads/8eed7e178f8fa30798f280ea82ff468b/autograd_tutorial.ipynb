{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n``torch.autograd`` \uc5d0 \ub300\ud55c \uac04\ub2e8\ud55c \uc18c\uac1c\n-------------------------------------------\n\n``torch.autograd`` \ub294 \uc2e0\uacbd\ub9dd \ud559\uc2b5\uc744 \uc9c0\uc6d0\ud558\ub294 PyTorch\uc758 \uc790\ub3d9 \ubbf8\ubd84 \uc5d4\uc9c4\uc785\ub2c8\ub2e4.\n\uc774 \ub2e8\uc6d0\uc5d0\uc11c\ub294 autograd\uac00 \uc2e0\uacbd\ub9dd \ud559\uc2b5\uc744 \uc5b4\ub5bb\uac8c \ub3d5\ub294\uc9c0\uc5d0 \ub300\ud55c \uac1c\ub150\uc801 \uc774\ud574\ub97c \ud560 \uc218\n\uc788\uc2b5\ub2c8\ub2e4.\n\n\ubc30\uacbd(Background)\n~~~~~~~~~~~~~~~~~~~\n\uc2e0\uacbd\ub9dd(NN; Neural Network)\uc740 \uc5b4\ub5a4 \uc785\ub825 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \uc2e4\ud589\ub418\ub294 \uc911\ucca9(nested)\ub41c\n\ud568\uc218\ub4e4\uc758 \ubaa8\uc74c(collection)\uc785\ub2c8\ub2e4. \uc774 \ud568\uc218\ub4e4\uc740 PyTorch\uc5d0\uc11c Tensor\ub85c \uc800\uc7a5\ub418\ub294,\n(\uac00\uc911\uce58(weight)\uc640 \ud3b8\ud5a5(bias)\ub85c \uad6c\uc131\ub41c) \ub9e4\uac1c\ubcc0\uc218\ub4e4\ub85c \uc815\uc758\ub429\ub2c8\ub2e4.\n\n\uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\ud558\ub294 \uac83\uc740 2\ub2e8\uacc4\ub85c \uc774\ub8e8\uc5b4\uc9d1\ub2c8\ub2e4:\n\n**\uc21c\uc804\ud30c(Forward Propagation)**: \uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c, \uc2e0\uacbd\ub9dd\uc740 \uc815\ub2f5\uc744 \ub9de\ucd94\uae30 \uc704\ud574\n\ucd5c\uc120\uc758 \ucd94\uce21(best guess)\uc744 \ud569\ub2c8\ub2e4. \uc774\ub807\uac8c \ucd94\uce21\uc744 \ud558\uae30 \uc704\ud574\uc11c \uc785\ub825 \ub370\uc774\ud130\ub97c \uac01\n\ud568\uc218\ub4e4\uc5d0\uc11c \uc2e4\ud589\ud569\ub2c8\ub2e4.\n\n**\uc5ed\uc804\ud30c(Backward Propagation)**: \uc5ed\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c, \uc2e0\uacbd\ub9dd\uc740 \ucd94\uce21\ud55c \uac12\uc5d0\uc11c \ubc1c\uc0dd\ud55c\n\uc624\ub958(error)\uc5d0 \ube44\ub840\ud558\uc5ec(proportionate) \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc744 \uc801\uc808\ud788 \uc870\uc808(adjust)\ud569\ub2c8\ub2e4.\n\ucd9c\ub825(output)\ub85c\ubd80\ud130 \uc5ed\ubc29\ud5a5\uc73c\ub85c \uc774\ub3d9\ud558\uba74\uc11c \uc624\ub958\uc5d0 \ub300\ud55c \ud568\uc218\ub4e4\uc758 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc758\n\ubbf8\ubd84\uac12( *\ubcc0\ud654\ub3c4(gradient)* )\uc744 \uc218\uc9d1\ud558\uace0, \uacbd\uc0ac\ud558\uac15\ubc95(gradient descent)\uc744 \uc0ac\uc6a9\ud558\uc5ec\n\ub9e4\uac1c\ubcc0\uc218\ub4e4\uc744 \ucd5c\uc801\ud654 \ud569\ub2c8\ub2e4. \uc5ed\uc804\ud30c\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc124\uba85\uc740 `3Blue1Brown\uc758 \ube44\ub514\uc624\n<https://www.youtube.com/watch?v=tIeHLnjs5U8>`__ \ub97c \ucc38\uace0\ud558\uc138\uc694.\n\n\nPyTorch\uc5d0\uc11c \uc0ac\uc6a9\ubc95\n~~~~~~~~~~~~~~~~~~~~\n\n\ud559\uc2b5 \ub2e8\uacc4\ub97c \ud558\ub098\ub9cc \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\uc11c\ub294 ``torchvision`` \uc5d0\uc11c \ubbf8\ub9ac \ud559\uc2b5\ub41c resnet18 \ubaa8\ub378\uc744 \ubd88\ub7ec\uc635\ub2c8\ub2e4.\n3\ucc44\ub110\uc9dc\ub9ac \ub192\uc774\uc640 \ub113\uc774\uac00 64\uc778 \uc774\ubbf8\uc9c0 \ud558\ub098\ub97c \ud45c\ud604\ud558\ub294 \ubb34\uc791\uc704\uc758 \ub370\uc774\ud130 \ud150\uc11c\ub97c \uc0dd\uc131\ud558\uace0, \uc774\uc5d0 \uc0c1\uc751\ud558\ub294 ``label(\uc815\ub2f5)`` \uc744\n\ubb34\uc791\uc704 \uac12\uc73c\ub85c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4. \ubbf8\ub9ac \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 \uc815\ub2f5(label)\uc740 (1, 1000)\uc758 \ubaa8\uc591(shape)\uc744 \uac16\uc2b5\ub2c8\ub2e4.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 (\ud150\uc11c\ub97c CUDA\ub85c \uc774\ub3d9\ud558\ub354\ub77c\ub3c4) GPU\uc5d0\uc11c\ub294 \ub3d9\uc791\ud558\uc9c0 \uc54a\uc73c\uba70 CPU\uc5d0\uc11c\ub9cc \ub3d9\uc791\ud569\ub2c8\ub2e4.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\nmodel = torchvision.models.resnet18(pretrained=True)\ndata = torch.rand(1, 3, 64, 64)\nlabels = torch.rand(1, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e4\uc74c\uc73c\ub85c, \uc785\ub825(input) \ub370\uc774\ud130\ub97c \ubaa8\ub378\uc758 \uac01 \uce35(layer)\uc5d0 \ud1b5\uacfc\uc2dc\ucf1c \uc608\uce21\uac12(prediction)\uc744 \uc0dd\uc131\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\uc774\uac83\uc774 **\uc21c\uc804\ud30c \ub2e8\uacc4** \uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prediction = model(data) # \uc21c\uc804\ud30c \ub2e8\uacc4(forward pass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378\uc758 \uc608\uce21\uac12\uacfc \uadf8\uc5d0 \ud574\ub2f9\ud558\ub294 \uc815\ub2f5(label)\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc624\ucc28(error, ``\uc190\uc2e4(loss)`` )\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\ub2e4\uc74c \ub2e8\uacc4\ub294 \uc2e0\uacbd\ub9dd\uc744 \ud1b5\ud574 \uc774 \uc5d0\ub7ec\ub97c \uc5ed\uc804\ud30c\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\uc624\ucc28 \ud150\uc11c(error tensor)\uc5d0 ``.backward()`` \ub97c \ud638\ucd9c\ud558\uba74 \uc5ed\uc804\ud30c\uac00 \uc2dc\uc791\ub429\ub2c8\ub2e4.\n\uadf8 \ub2e4\uc74c Autograd\uac00 \ub9e4\uac1c\ubcc0\uc218(parameter)\uc758 ``.grad`` \uc18d\uc131(attribute)\uc5d0, \ubaa8\ub378\uc758\n\uac01 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub300\ud55c \ubcc0\ud654\ub3c4(gradient)\ub97c \uacc4\uc0b0\ud558\uace0 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss = (prediction - labels).sum()\nloss.backward() # \uc5ed\uc804\ud30c \ub2e8\uacc4(backward pass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e4\uc74c\uc73c\ub85c, \uc635\ud2f0\ub9c8\uc774\uc800(optimizer)\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4.\n\uc774 \uc608\uc81c\uc5d0\uc11c\ub294 \ud559\uc2b5\uc728(learning rate) 0.1\uacfc `\ubaa8\uba58\ud140(momentum) <https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d>`__\n0.9\ub97c \uac16\ub294 SGD\uc785\ub2c8\ub2e4. \uc635\ud2f0\ub9c8\uc774\uc800(optimizer)\uc5d0 \ubaa8\ub378\uc758 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub97c \ub4f1\ub85d\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub9c8\uc9c0\ub9c9\uc73c\ub85c ``.step`` \uc744 \ud638\ucd9c\ud558\uc5ec \uacbd\uc0ac\ud558\uac15\ubc95(gradient descent)\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4.\n\uc635\ud2f0\ub9c8\uc774\uc800\ub294 ``.grad`` \uc5d0 \uc800\uc7a5\ub41c \ubcc0\ud654\ub3c4\uc5d0 \ub530\ub77c \uac01 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc870\uc815(adjust)\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optim.step() # \uacbd\uc0ac\ud558\uac15\ubc95(gradient descent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc9c0\uae08\uae4c\uc9c0 \uc2e0\uacbd\ub9dd \ud559\uc2b5\uc5d0 \ud544\uc694\ud55c \ubaa8\ub4e0 \uac83\uc744 \uc54c\uc544\ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n\uc544\ub798\ub294 autograd\uc758 \ub3d9\uc791\uc5d0 \ub300\ud55c \uc138\ubd80\uc801\uc778 \ub0b4\uc6a9\uc744 \uc124\uba85\ud558\ubbc0\ub85c, \uac74\ub108\ub6f0\uc5b4\ub3c4 \ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Autograd\uc5d0\uc11c \ubbf8\ubd84(differentiation)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n``autograd`` \uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud654\ub3c4(gradient)\ub97c \uc218\uc9d1\ud558\ub294\uc9c0 \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n``requires_grad=True`` \ub97c \uac16\ub294 2\uac1c\uc758 \ud150\uc11c(tensor) ``a`` \uc640 ``b`` \ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n``requires_grad=True`` \ub294 ``autograd`` \uc5d0 \ubaa8\ub4e0 \uc5f0\uc0b0(operation)\ub4e4\uc744 \ucd94\uc801\ud574\uc57c \ud55c\ub2e4\uace0 \uc54c\ub824\uc90d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\na = torch.tensor([2., 3.], requires_grad=True)\nb = torch.tensor([6., 4.], requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c ``a`` \uc640 ``b`` \ub85c\ubd80\ud130 \uc0c8\ub85c\uc6b4 \ud150\uc11c ``Q`` \ub97c \ub9cc\ub4ed\ub2c8\ub2e4\nWe create another tensor ``Q`` from ``a`` and ``b``.\n\n\\begin{align}Q = 3a^3 - b^2\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Q = 3*a**3 - b**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c ``a`` \uc640 ``b`` \uac00 \ubaa8\ub450 \uc2e0\uacbd\ub9dd(NN)\uc758 \ub9e4\uac1c\ubcc0\uc218\uc774\uace0, ``Q`` \uac00\n\uc624\ucc28(error)\ub77c\uace0 \uac00\uc815\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\ud560 \ub54c, \uc544\ub798\uc640 \uac19\uc774\n\ub9e4\uac1c\ubcc0\uc218\ub4e4\uc5d0 \ub300\ud55c \uc624\ucc28\uc758 \ubcc0\ud654\ub3c4(gradient)\ub97c \uad6c\ud574\uc57c \ud569\ub2c8\ub2e4. \uc989,\n\n\\begin{align}\\frac{\\partial Q}{\\partial a} = 9a^2\\end{align}\n\n\\begin{align}\\frac{\\partial Q}{\\partial b} = -2b\\end{align}\n\n\n``Q`` \uc5d0 \ub300\ud574\uc11c ``.backward()`` \ub97c \ud638\ucd9c\ud560 \ub54c, autograd\ub294 \uc774\ub7ec\ud55c \ubcc0\ud654\ub3c4\ub4e4\uc744 \uacc4\uc0b0\ud558\uace0\n\uc774\ub97c \uac01 \ud150\uc11c\uc758 ``.grad`` \uc18d\uc131(attribute)\uc5d0 \uc800\uc7a5\ud569\ub2c8\ub2e4.\n\n``Q`` \ub294 \ubca1\ud130(vector)\uc774\ubbc0\ub85c ``Q.backward()`` \uc5d0 ``gradient`` \uc778\uc790(argument)\ub97c \uba85\uc2dc\uc801\uc73c\ub85c\n\uc804\ub2ec\ud574\uc57c \ud569\ub2c8\ub2e4. ``gradient`` \ub294 ``Q`` \uc640 \uac19\uc740 \ubaa8\uc591(shape)\uc758 \ud150\uc11c\ub85c, ``Q`` \uc790\uae30 \uc790\uc2e0\uc5d0 \ub300\ud55c\n\ubcc0\ud654\ub3c4(gradient)\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \uc989\n\n\\begin{align}\\frac{dQ}{dQ} = 1\\end{align}\n\n\ub3d9\uc77c\ud558\uac8c, ``Q.sum().backward()`` \uc640 \uac19\uc774 ``Q`` \ub97c \uc2a4\uce7c\ub77c(scalar) \uac12\uc73c\ub85c \uc9d1\uacc4(aggregate)\ud55c \ub4a4 \uc554\uc2dc\uc801\uc73c\ub85c\n``.backward()`` \ub97c \ud638\ucd9c\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "external_grad = torch.tensor([1., 1.])\nQ.backward(gradient=external_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \ubcc0\ud654\ub3c4\ub294 ``a.grad`` \uc640 ``b.grad`` \uc5d0 \uc800\uc7a5\ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc218\uc9d1\ub41c \ubcc0\ud654\ub3c4\uac00 \uc62c\ubc14\ub978\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\nprint(9*a**2 == a.grad)\nprint(-2*b == b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc120\ud0dd\uc801\uc73c\ub85c \uc77d\uae30(Optional Reading) - ``autograd`` \ub97c \uc0ac\uc6a9\ud55c \ubca1\ud130 \ubbf8\uc801\ubd84(calculus)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\uc218\ud559\uc801\uc73c\ub85c, \ubca1\ud130 \ud568\uc218 $\\vec{y}=f(\\vec{x})$ \uc5d0\uc11c $\\vec{x}$ \uc5d0\n\ub300\ud55c $\\vec{y}$ \uc758 \ubcc0\ud654\ub3c4\ub294 \uc57c\ucf54\ube44\uc548 \ud589\ub82c(Jacobian Matrix) $J$: \uc785\ub2c8\ub2e4:\n\n\\begin{align}J\n     =\n      \\left(\\begin{array}{cc}\n      \\frac{\\partial \\bf{y}}{\\partial x_{1}} &\n      ... &\n      \\frac{\\partial \\bf{y}}{\\partial x_{n}}\n      \\end{array}\\right)\n     =\n     \\left(\\begin{array}{ccc}\n      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n      \\vdots & \\ddots & \\vdots\\\\\n      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n      \\end{array}\\right)\\end{align}\n\n\uc77c\ubc18\uc801\uc73c\ub85c, ``torch.autograd`` \ub294 \ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc744 \uacc4\uc0b0\ud558\ub294 \uc5d4\uc9c4\uc785\ub2c8\ub2e4. \uc774\ub294, \uc8fc\uc5b4\uc9c4\n\uc5b4\ub5a4 \ubca1\ud130 $\\vec{v}$ \uc5d0 \ub300\ud574 $J^{T}\\cdot \\vec{v}$ \uc744 \uc5f0\uc0b0\ud569\ub2c8\ub2e4.\n\n\ub9cc\uc57d $\\vec{v}$ \uac00 \uc2a4\uce7c\ub77c \ud568\uc218 $l=g\\left(\\vec{y}\\right)$ \uc758 \ubcc0\ud654\ub3c4(gradient)\uc778 \uacbd\uc6b0:\n\n\\begin{align}\\vec{v}\n   =\n   \\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}\\end{align}\n\n\uc774\uba70, \uc5f0\uc1c4 \ubc95\uce59(chain rule)\uc5d0 \ub530\ub77c, \ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc740 $\\vec{x}$ \uc5d0 \ub300\ud55c\n$l$ \uc758 \ubcc0\ud654\ub3c4(gradient)\uac00 \ub429\ub2c8\ub2e4:\n\n\\begin{align}J^{T}\\cdot \\vec{v}=\\left(\\begin{array}{ccc}\n      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n      \\vdots & \\ddots & \\vdots\\\\\n      \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n      \\end{array}\\right)\\left(\\begin{array}{c}\n      \\frac{\\partial l}{\\partial y_{1}}\\\\\n      \\vdots\\\\\n      \\frac{\\partial l}{\\partial y_{m}}\n      \\end{array}\\right)=\\left(\\begin{array}{c}\n      \\frac{\\partial l}{\\partial x_{1}}\\\\\n      \\vdots\\\\\n      \\frac{\\partial l}{\\partial x_{n}}\n      \\end{array}\\right)\\end{align}\n\n\uc704 \uc608\uc81c\uc5d0\uc11c \ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc758 \uc774\ub7ec\ud55c \ud2b9\uc131\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4;\n``external_grad`` \uac00 $\\vec{v}$ \ub97c \ub73b\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc5f0\uc0b0 \uadf8\ub798\ud504(Computational Graph)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uac1c\ub150\uc801\uc73c\ub85c, autograd\ub294 \ub370\uc774\ud130(\ud150\uc11c)\uc758 \ubc0f \uc2e4\ud589\ub41c \ubaa8\ub4e0 \uc5f0\uc0b0\ub4e4(\ubc0f \uc5f0\uc0b0 \uacb0\uacfc\uac00 \uc0c8\ub85c\uc6b4 \ud150\uc11c\uc778 \uacbd\uc6b0\ub3c4 \ud3ec\ud568\ud558\uc5ec)\uc758\n\uae30\ub85d\uc744 `Function <https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function>`__ \uac1d\uccb4\ub85c\n\uad6c\uc131\ub41c \ubc29\ud5a5\uc131 \ube44\uc21c\ud658 \uadf8\ub798\ud504(DAG; Directed Acyclic Graph)\uc5d0 \uc800\uc7a5(keep)\ud569\ub2c8\ub2e4.\n\uc774 \ubc29\ud5a5\uc131 \ube44\uc21c\ud658 \uadf8\ub798\ud504(DAG)\uc758 \uc78e(leave)\uc740 \uc785\ub825 \ud150\uc11c\uc774\uace0, \ubfcc\ub9ac(root)\ub294 \uacb0\uacfc \ud150\uc11c\uc785\ub2c8\ub2e4.\n\uc774 \uadf8\ub798\ud504\ub97c \ubfcc\ub9ac\uc5d0\uc11c\ubd80\ud130 \uc78e\uae4c\uc9c0 \ucd94\uc801\ud558\uba74 \uc5f0\uc1c4 \ubc95\uce59(chain rule)\uc5d0 \ub530\ub77c \ubcc0\ud654\ub3c4\ub97c \uc790\ub3d9\uc73c\ub85c \uacc4\uc0b0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c, autograd\ub294 \ub2e4\uc74c \ub450 \uac00\uc9c0 \uc791\uc5c5\uc744 \ub3d9\uc2dc\uc5d0 \uc218\ud589\ud569\ub2c8\ub2e4:\n\n- \uc694\uccad\ub41c \uc5f0\uc0b0\uc744 \uc218\ud589\ud558\uc5ec \uacb0\uacfc \ud150\uc11c\ub97c \uacc4\uc0b0\ud558\uace0,\n- DAG\uc5d0 \uc5f0\uc0b0\uc758 *\ubcc0\ud654\ub3c4 \uae30\ub2a5(gradient function)* \ub97c \uc720\uc9c0(maintain)\ud569\ub2c8\ub2e4.\n\n\uc5ed\uc804\ud30c \ub2e8\uacc4\ub294 DAG \ubfcc\ub9ac(root)\uc5d0\uc11c ``.backward()`` \uac00 \ud638\ucd9c\ub420 \ub54c \uc2dc\uc791\ub429\ub2c8\ub2e4. ``autograd`` \ub294 \uc774 \ub54c:\n\n- \uac01 ``.grad_fn`` \uc73c\ub85c\ubd80\ud130 \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\uace0,\n- \uac01 \ud150\uc11c\uc758 ``.grad`` \uc18d\uc131\uc5d0 \uacc4\uc0b0 \uacb0\uacfc\ub97c \uc313\uace0(accumulate),\n- \uc5f0\uc1c4 \ubc95\uce59\uc744 \uc0ac\uc6a9\ud558\uc5ec, \ubaa8\ub4e0 \uc78e(leaf) \ud150\uc11c\ub4e4\uae4c\uc9c0 \uc804\ud30c(propagate)\ud569\ub2c8\ub2e4.\n\n\ub2e4\uc74c\uc740 \uc9c0\uae08\uae4c\uc9c0 \uc0b4\ud3b4\ubcf8 \uc608\uc81c\uc758 DAG\ub97c \uc2dc\uac01\uc801\uc73c\ub85c \ud45c\ud604\ud55c \uac83\uc785\ub2c8\ub2e4. \uadf8\ub798\ud504\uc5d0\uc11c \ud654\uc0b4\ud45c\ub294 \uc21c\uc804\ud30c \ub2e8\uacc4\uc758 \ubc29\ud5a5\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\n\ub178\ub4dc(node)\ub4e4\uc740 \uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c\uc758 \uac01 \uc5f0\uc0b0\ub4e4\uc5d0 \ub300\ud55c \uc5ed\uc804\ud30c \ud568\uc218\ub4e4\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ud30c\ub780\uc0c9 \uc78e(leaf) \ub178\ub4dc\ub294 \uc78e \ud150\uc11c ``a`` \uc640 ``b`` \ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\n\n.. figure:: /_static/img/dag_autograd.png\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>**PyTorch\uc5d0\uc11c DAG\ub4e4\uc740 \ub3d9\uc801(dynamic)\uc785\ub2c8\ub2e4.**\n  \uc8fc\ubaa9\ud574\uc57c \ud560 \uc911\uc694\ud55c \uc810\uc740 \uadf8\ub798\ud504\uac00 \ucc98\uc74c\ubd80\ud130(from scratch) \ub2e4\uc2dc \uc0dd\uc131\ub41c\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4; \ub9e4\ubc88 ``.backward()`` \uac00\n  \ud638\ucd9c\ub418\uace0 \ub098\uba74, autograd\ub294 \uc0c8\ub85c\uc6b4 \uadf8\ub798\ud504\ub97c \ucc44\uc6b0\uae30(populate) \uc2dc\uc791\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc810 \ub355\ubd84\uc5d0 \ubaa8\ub378\uc5d0\uc11c\n  \ud750\ub984 \uc81c\uc5b4(control flow) \uad6c\ubb38\ub4e4\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ub418\ub294 \uac83\uc785\ub2c8\ub2e4; \ub9e4\ubc88 \ubc18\ubcf5(iteration)\ud560 \ub54c\ub9c8\ub2e4 \ud544\uc694\ud558\uba74\n  \ubaa8\uc591(shape)\uc774\ub098 \ud06c\uae30(size), \uc5f0\uc0b0(operation)\uc744 \ubc14\uafc0 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p></div>\n\nDAG\uc5d0\uc11c \uc81c\uc678\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^\n\n``torch.autograd`` \ub294 ``requires_grad`` \ud50c\ub798\uadf8(flag)\uac00 ``True`` \ub85c \uc124\uc815\ub41c \ubaa8\ub4e0 \ud150\uc11c\uc5d0 \ub300\ud55c\n\uc5f0\uc0b0\ub4e4\uc744 \ucd94\uc801\ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \ubcc0\ud654\ub3c4\uac00 \ud544\uc694\ud558\uc9c0 \uc54a\uc740 \ud150\uc11c\ub4e4\uc5d0 \ub300\ud574\uc11c\ub294 \uc774 \uc18d\uc131\uc744 ``False`` \ub85c \uc124\uc815\ud558\uc5ec\nDAG \ubcc0\ud654\ub3c4 \uacc4\uc0b0\uc5d0\uc11c \uc81c\uc678\ud569\ub2c8\ub2e4.\n\n\uc785\ub825 \ud150\uc11c \uc911 \ub2e8 \ud558\ub098\ub77c\ub3c4 ``requres_grad=True`` \ub97c \uac16\ub294 \uacbd\uc6b0, \uc5f0\uc0b0\uc758 \uacb0\uacfc \ud150\uc11c\ub3c4 \ubcc0\ud654\ub3c4\ub97c \uac16\uac8c \ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.rand(5, 5)\ny = torch.rand(5, 5)\nz = torch.rand((5, 5), requires_grad=True)\n\na = x + y\nprint(f\"Does `a` require gradients? : {a.requires_grad}\")\nb = x + z\nprint(f\"Does `b` require gradients?: {b.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc2e0\uacbd\ub9dd\uc5d0\uc11c, \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\uc9c0 \uc54a\ub294 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc77c\ubc18\uc801\uc73c\ub85c **\uace0\uc815\ub41c \ub9e4\uac1c\ubcc0\uc218(frozen parameter)** \uc774\ub77c\uace0 \ubd80\ub985\ub2c8\ub2e4.\n\uc774\ub7ec\ud55c \ub9e4\uac1c\ubcc0\uc218\uc758 \ubcc0\ud654\ub3c4\uac00 \ud544\uc694\ud558\uc9c0 \uc54a\ub2e4\ub294 \uac83\uc744 \ubbf8\ub9ac \uc54c\uace0 \uc788\uc73c\uba74, \uc2e0\uacbd\ub9dd \ubaa8\ub378\uc758 \uc77c\ubd80\ub97c \"\uace0\uc815(freeze)\"\ud558\ub294 \uac83\uc774 \uc720\uc6a9\ud569\ub2c8\ub2e4.\n(\uc774\ub807\uac8c \ud558\uba74 autograd \uc5f0\uc0b0\ub7c9\uc744 \uc904\uc784\uc73c\ub85c\uc368 \uc131\ub2a5 \uc0c1\uc758 \uc774\ub4dd\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.)\n\nDAG\uc5d0\uc11c \uc81c\uc678\ud558\ub294 \uac83\uc774 \uc911\uc694\ud55c \ub610 \ub2e4\ub978 \uc77c\ubc18\uc801\uc778 \uc0ac\ub840(usecase)\ub294\n`\ubbf8\ub9ac \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ubbf8\uc138\uc870\uc815 <https://tutorials.pytorch.kr/beginner/finetuning_torchvision_models_tutorial.html>`__\n\ud558\ub294 \uacbd\uc6b0\uc785\ub2c8\ub2e4.\n\n\ubbf8\uc138\uc870\uc815(finetuning)\uc744 \ud558\ub294 \uacfc\uc815\uc5d0\uc11c, \uc0c8\ub85c\uc6b4 \uc815\ub2f5(label)\uc744 \uc608\uce21\ud560 \uc218 \uc788\ub3c4\ub85d \ubaa8\ub378\uc758 \ub300\ubd80\ubd84\uc744 \uace0\uc815\ud55c \ub4a4 \uc77c\ubc18\uc801\uc73c\ub85c \ubd84\ub958 \uacc4\uce35(classifier layer)\ub9cc \ubcc0\uacbd\ud569\ub2c8\ub2e4.\n\uc774\ub97c \uc124\uba85\ud558\uae30 \uc704\ud574 \uac04\ub2e8\ud55c \uc608\uc81c\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc774\uc804\uacfc \ub9c8\ucc2c\uac00\uc9c0\ub85c \uc774\ubbf8 \ud559\uc2b5\ub41c resnet18 \ubaa8\ub378\uc744 \ubd88\ub7ec\uc628 \ub4a4 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub97c \uace0\uc815\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n\nmodel = torchvision.models.resnet18(pretrained=True)\n\n# \uc2e0\uacbd\ub9dd\uc758 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub97c \uace0\uc815\ud569\ub2c8\ub2e4\nfor param in model.parameters():\n    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "10\uac1c\uc758 \uc815\ub2f5(label)\uc744 \uac16\ub294 \uc0c8\ub85c\uc6b4 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubaa8\ub378\uc744 \ubbf8\uc138\uc870\uc815\ud558\ub294 \uc0c1\ud669\uc744 \uac00\uc815\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\nresnet\uc5d0\uc11c \ubd84\ub958\uae30(classifier)\ub294 \ub9c8\uc9c0\ub9c9 \uc120\ud615 \uacc4\uce35(linear layer)\uc778 ``model.fc`` \uc785\ub2c8\ub2e4.\n\uc774\ub97c \uc0c8\ub85c\uc6b4 \ubd84\ub958\uae30\ub85c \ub3d9\uc791\ud560 (\uace0\uc815\ub418\uc9c0 \uc54a\uc740) \uc0c8\ub85c\uc6b4 \uc120\ud615 \uacc4\uce35\uc73c\ub85c \uac04\ub2e8\ud788 \ub300\uccb4\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(512, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c ``model.fc`` \ub97c \uc81c\uc678\ud55c \ubaa8\ub378\uc758 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc774 \uace0\uc815\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\ub294 \uc720\uc77c\ud55c \ub9e4\uac1c\ubcc0\uc218\ub294 ``model.fc`` \uc758 \uac00\uc911\uce58(weight)\uc640 \ud3b8\ud5a5(bias)\ubfd0\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ubd84\ub958\uae30\ub9cc \ucd5c\uc801\ud654\ud569\ub2c8\ub2e4.\noptimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc635\ud2f0\ub9c8\uc774\uc800(optimizer)\uc5d0 \ubaa8\ub4e0 \ub9e4\uac1c\ubcc0\uc218\ub97c \ub4f1\ub85d\ud558\ub354\ub77c\ub3c4,\n\ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0(\ud558\uace0 \uacbd\uc0ac\ud558\uac15\ubc95\uc73c\ub85c \uac31\uc2e0)\ud560 \uc218 \uc788\ub294 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc740 \ubd84\ub958\uae30\uc758 \uac00\uc911\uce58\uc640 \ud3b8\ud5a5\ubfd0\uc785\ub2c8\ub2e4.\n\n\ucee8\ud14d\uc2a4\ud2b8 \ub9e4\ub2c8\uc800(context manager)\uc5d0 `torch.no_grad() <https://pytorch.org/docs/stable/generated/torch.no_grad.html>`__\n\ub85c\ub3c4 \ub611\uac19\uc774 \uc81c\uc678\ud558\ub294 \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub354 \uc77d\uc5b4\ubcf4\uae30:\n~~~~~~~~~~~~~~~~~~~\n\n-  `In-place operations & Multithreaded Autograd <https://pytorch.org/docs/stable/notes/autograd.html>`__\n-  `Example implementation of reverse-mode autodiff <https://colab.research.google.com/drive/1VpeE6UvEPRz9HmsHh1KS0XxXjYu533EC>`__\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}