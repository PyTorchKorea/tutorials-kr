{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# wav2vec2\uc744 \uc774\uc6a9\ud55c \uac15\uc81c \uc815\ub82c\n\n**\uc800\uc790**: [Moto Hira](moto@meta.com)\n**\ubc88\uc5ed**: [\uae40\uaddc\uc9c4](http://github.com/kimgyujin/)\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 [CTC-Segmentation of Large Corpora for German End-to-end Speech Recognition](https://arxiv.org/abs/2007.09127)_ \uc5d0\uc11c \n\uc124\uba85\ud55c CTC \ubd84\ud560 \uc54c\uace0\ub9ac\uc998\uc744 \uc774\uc6a9\ud558\uc5ec torchaudio\ub97c \uac00\uc9c0\uace0 \uc815\ub2f5 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \uc74c\uc131\uc5d0 \ub9de\ucd94\ub294 \ubc29\ubc95\uc5d0 \ub300\ud574 \uc124\uba85\ud569\ub2c8\ub2e4.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 \uc6d0\ub798 Wav2Vec2\uc758 \uc0ac\uc6a9 \uc0ac\ub840\ub97c \uc124\uba85\ud558\uae30 \uc704\ud574 \uc791\uc131\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n   TorchAudio\uc5d0\ub294 \uac15\uc81c \uc815\ub82c\uc744 \uc704\ud574 \uc124\uacc4\ub41c API\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n   [CTC forced alignment API tutorial](./ctc_forced_alignment_api_tutorial.html)_ \uc740 \ud575\uc2ec API\uc778 \n   :py:func:`torchaudio.functional.forced_align` \uc758 \uc0ac\uc6a9\ubc95\uc5d0 \ub300\ud574 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n   \ub9cc\uc57d \ubcf8\uc778\ub9cc\uc758 \ucf54\ud37c\uc2a4\uc5d0 \ub300\ud574 \uac15\uc81c \uc815\ub82c\ud558\ub824\ub294 \uacbd\uc6b0, :py:class:`torchaudio.pipelines.Wav2Vec2FABundle` \ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc744 \ucd94\ucc9c\ud569\ub2c8\ub2e4.\n   \uc774\ub294 \uac15\uc81c \uc815\ub82c\uc744 \uc704\ud574 \ud2b9\ubcc4\ud788 \ud6c8\ub828\ub41c \uc0ac\uc804 \ud6c8\ub828 \ubaa8\ub378\uacfc \ud568\uaed8 :py:func:`~torchaudio.functional.forced_align` \ubc0f \uc5ec\ub7ec \ud568\uc218\ub97c \uacb0\ud569\ud558\uc5ec \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ud569\ub2c8\ub2e4. \n   \uc0ac\uc6a9\ubc95\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ub2e4\uad6d\uc5b4 \ub370\uc774\ud130\ub97c \uc704\ud55c \uac15\uc81c \uc815\ub82c\uc744 \uc124\uba85\ud558\ub294 [Forced alignment for multilingual data](forced_alignment_for_multilingual_data_tutorial.html)_ \ub97c \ucc38\uc870\ud558\uc138\uc694.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchaudio\n\nprint(torch.__version__)\nprint(torchaudio.__version__)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uac1c\uc694\n\n\uc815\ub82c \uacfc\uc815\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n1. \uc624\ub514\uc624 \ud30c\ud615\uc73c\ub85c\ubd80\ud130 \ud504\ub808\uc784\ubcc4 \ub77c\ubca8 \ud655\ub960\uc744 \ucd94\uc815\ud55c\ub2e4.\n2. \uac01 \uc2dc\uac04 \ubcc4\ub85c \uc815\ub82c\ub41c \ub77c\ubca8\uc758 \ud655\ub960\uc744 \ub098\ud0c0\ub0b4\ub294 trellis \ud589\ub82c\uc744 \uc0dd\uc131\ud55c\ub2e4.\n3. trellis \ud589\ub82c\ub85c\ubd80\ud130 \uac00\uc7a5 \uac00\ub2a5\uc131\uc774 \ub192\uc740 \uacbd\ub85c\ub97c \ucc3e\ub294\ub2e4.\n\n\uc774\ubc88 \uc608\uc2dc\uc5d0\ub294 \uc74c\uc131 \ud2b9\uc9d5 \ucd94\ucd9c\uc744 \uc704\ud574 torchaudio\uc758 wav2vec2 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc900\ube44\n\n\uba3c\uc800 \ud544\uc694\ud55c \ud328\ud0a4\uc9c0\ub97c \uc784\ud3ec\ud2b8\ud558\uace0, \uc791\uc5c5\ud560 \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n\nimport IPython\nimport matplotlib.pyplot as plt\n\ntorch.random.manual_seed(0)\n\nSPEECH_FILE = torchaudio.utils.download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud504\ub808\uc784 \ubcc4 \ub77c\ubca8 \ud655\ub960 \uc0dd\uc131 \n\n\uccab\ubc88\uc9f8 \uacfc\uc815\uc740 \uac01 \uc624\ub514\uc624 \ud504\ub808\uc784 \ubcc4 \ub77c\ubca8 \ud074\ub798\uc2a4 \ud655\ub960\uc744 \uc0dd\uc131\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\nASR(\uc74c\uc131 \uc778\uc2dd)\uc6a9\uc73c\ub85c \ud559\uc2b5\ub41c wav2vec2 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 :py:func:`torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H` \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n``torchaudio``\ub294 \uc5f0\uad00\ub41c \ub77c\ubca8\uacfc \ud568\uaed8 \ubbf8\ub9ac \ud559\uc2b5\ub41c \ubaa8\ub378\uc5d0 \uc27d\uac8c \uc811\uadfc\ud560 \uc218 \uc788\uac8c \ud569\ub2c8\ub2e4.\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\uc5ec\uae30\uc11c\ub294 \uc218\uce58\uc801\uc778 \ubd88\uc548\uc815\uc131\uc744 \ud53c\ud558\uace0\uc790 \ub85c\uadf8 \ub3c4\uba54\uc778\uc5d0\uc11c \ud655\ub960\uc744 \uacc4\uc0b0\ud560 \uac83\uc785\ub2c8\ub2e4. \n   \uc774\ub807\uac8c \ud558\uae30 \uc704\ud574 ``torch.log_softmax()`` \ub97c \uc0ac\uc6a9\ud558\uc5ec ``\ucd9c\ub825 \ud655\ub960`` \uc744 \uc815\uaddc\ud654\ud569\ub2c8\ub2e4.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\nmodel = bundle.get_model().to(device)\nlabels = bundle.get_labels()\nwith torch.inference_mode():\n    waveform, _ = torchaudio.load(SPEECH_FILE)\n    emissions, _ = model(waveform.to(device))\n    emissions = torch.log_softmax(emissions, dim=-1)\n\nemission = emissions[0].cpu().detach()\n\nprint(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uc2dc\uac01\ud654\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot():\n    fig, ax = plt.subplots()\n    img = ax.imshow(emission.T)\n    ax.set_title(\"Frame-wise class probability\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Labels\")\n    fig.colorbar(img, ax=ax, shrink=0.6, location=\"bottom\")\n    fig.tight_layout()\n\n\nplot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc815\ub82c \ud655\ub960 \uc0dd\uc131 (trellis)\n\n\ub2e4\uc74c, \ucd9c\ub825 \ud589\ub82c\ub85c\ubd80\ud130 \uac01 \ud504\ub808\uc784\uc5d0\uc11c \uc815\ub2f5 \uc2a4\ud06c\ub9bd\ud2b8\uc758 \ub77c\ubca8\ub4e4\uc774 \ub4f1\uc7a5\ud560 \uc218 \uc788\ub294 \ud655\ub960\uc744 \ub098\ud0c0\ub0b4\ub294 trellis\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\nTrellis\ub294 \uc2dc\uac04 \ucd95\uacfc \ub77c\ubca8 \ucd95\uc744 \uac00\uc9c0\uace0 \uc788\ub294 2D \ud589\ub82c\uc785\ub2c8\ub2e4. \ub77c\ubca8 \ucd95\uc740 \uc815\ub82c\ud558\ub824\ub294 \uc815\ub2f5 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \n$t$ \ub97c \uc2dc\uac04 \ucd95\uc5d0\uc11c\uc758 \uc778\ub371\uc2a4\ub85c \ub098\ud0c0\ub0b4\ub294 \ub370 \uc0ac\uc6a9\ud558\uace0, $j$ \ub97c \ub77c\ubca8 \ucd95\uc5d0\uc11c\uc758 \uc778\ub371\uc2a4\ub85c \ub098\ud0c0\ub0b4\ub294 \ub370 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \n$c_j$ \ub294 \ub77c\ubca8 \uc778\ub371\uc2a4 $j$ \uc5d0\uc11c\uc758 \ub77c\ubca8\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\n\n\n$t+1$ \uc2dc\uc810\uc5d0\uc11c\uc758 \ud655\ub960\uc744 \uc0dd\uc131\ud558\uae30 \uc704\ud574, $t$ \uc2dc\uc810\uc5d0\uc11c\uc758 trellis\uc640 $t+1$ \uc2dc\uc810\uc5d0\uc11c\uc758 \ucd9c\ub825\uc744 \ubd05\ub2c8\ub2e4. \n$t+1$ \uc2dc\uc810\uc5d0\uc11c $c_{j+1}$ \ub77c\ubca8\uc5d0 \ub3c4\ub2ec\ud560 \uc218 \uc788\ub294 2\uac1c\uc758 \uacbd\ub85c\uac00 \uc788\uc2b5\ub2c8\ub2e4. \n\uccab\ubc88\uc9f8\ub294 $t$ \uc2dc\uc810\uc5d0\uc11c \ub77c\ubca8\uc740 $c_{j+1}$ \uc600\uc73c\uba70 $t$ \uc5d0\uc11c ${t+1}$ \uc73c\ub85c \ubc14\ub014 \ub54c \ub77c\ubca8 \ubcc0\ud654\ub294 \uc5c6\ub294 \uacbd\uc6b0\uc785\ub2c8\ub2e4. \n\ub2e4\ub978 \uacbd\uc6b0\ub294 $t$ \uc2dc\uc810\uc5d0\uc11c \ub77c\ubca8\uc740 $c_j$ \uc600\uc73c\uba70 $t+1$ \uc2dc\uc810\uc5d0\uc11c\ub294 \ub2e4\uc74c \ub77c\ubca8 $c_{j+1}$ \ub85c \uc804\uc774\ub41c \uacbd\uc6b0\uc785\ub2c8\ub2e4.\n\n\uc544\ub798 \uadf8\ub9bc\uc740 2\uac00\uc9c0 \uc804\uc774\ub97c \ub098\ud0c0\ub0b4\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n<img src=\"https://download.pytorch.org/torchaudio/tutorial-assets/ctc-forward.png\">\n\n\uac00\uc7a5 \uac00\ub2a5\uc131 \uc788\ub294 \uc804\uc774\ub97c \ucc3e\uae30 \uc704\ud574, $k_{(t+1, j+1)}$ \uc758 \uac12\uc758 \uac00\uc7a5 \uac00\ub2a5\uc131 \uc788\ub294 \uacbd\ub85c\ub97c \ud0dd\ud569\ub2c8\ub2e4. \n\uc774\ub294 \uc544\ub798\uc5d0 \ub098\uc640 \uc788\ub294 \uc2dd\uc73c\ub85c \ub098\ud0c0\ub0bc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n$k_{(t+1, j+1)} = max( k_{(t, j)} p(t+1, c_{j+1}), k_{(t, j+1)} p(t+1, repeat) )$\n\n\n$k$ \ub294 trellis \ud589\ub82c\uc744 \ub098\ud0c0\ub0b4\uba70, $p(t, c_j)$ \ub294 $t$ \uc2dc\uc810\uc5d0\uc11c\uc758 \ub77c\ubca8 $c_j$ \uc758 \ud655\ub960\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \nrepeat\ub294 CTC \uc2dd\uc5d0\uc11c\uc758 \ube14\ub7ad\ud06c \ud1a0\ud070\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4. (CTC \uc54c\uace0\ub9ac\uc998\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc124\uba85\uc740 'Sequence Modeling with CTC'\ub97c \ucc38\uace0\ud558\uc138\uc694.) [[distill.pub](https://distill.pub/2017/ctc/)_])\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# SOS\uc640 EOS\ub97c \ub098\ud0c0\ub0b4\ub294 space \ud1a0\ud070\uc744 \uac00\uc9c0\uace0 \uc815\ub2f5 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \ub458\ub7ec\uc308.\ntranscript = \"|I|HAD|THAT|CURIOSITY|BESIDE|ME|AT|THIS|MOMENT|\"\ndictionary = {c: i for i, c in enumerate(labels)}\n\ntokens = [dictionary[c] for c in transcript]\nprint(list(zip(transcript, tokens)))\n\n\ndef get_trellis(emission, tokens, blank_id=0):\n    num_frame = emission.size(0)\n    num_tokens = len(tokens)\n\n    trellis = torch.zeros((num_frame, num_tokens))\n    trellis[1:, 0] = torch.cumsum(emission[1:, blank_id], 0)\n    trellis[0, 1:] = -float(\"inf\")\n    trellis[-num_tokens + 1 :, 0] = float(\"inf\")\n\n    for t in range(num_frame - 1):\n        trellis[t + 1, 1:] = torch.maximum(\n            # \uac19\uc740 \ud1a0\ud070\uc5d0 \uba38\ubb34\ub974\uace0 \uc788\ub294 \uacbd\uc6b0\uc758 \uc810\uc218\n            trellis[t, 1:] + emission[t, blank_id],\n            # \ub2e4\uc74c \ud1a0\ud070\uc73c\ub85c \ubc14\ub00c\ub294 \uacbd\uc6b0\uc5d0 \ub300\ud55c \uc810\uc218\n            trellis[t, :-1] + emission[t, tokens[1:]],\n        )\n    return trellis\n\n\ntrellis = get_trellis(emission, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uc2dc\uac01\ud654\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot():\n    fig, ax = plt.subplots()\n    img = ax.imshow(trellis.T, origin=\"lower\")\n    ax.annotate(\"- Inf\", (trellis.size(1) / 5, trellis.size(1) / 1.5))\n    ax.annotate(\"+ Inf\", (trellis.size(0) - trellis.size(1) / 5, trellis.size(1) / 3))\n    fig.colorbar(img, ax=ax, shrink=0.6, location=\"bottom\")\n    fig.tight_layout()\n\n\nplot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc704 \uc2dc\uac01\ud654\ub41c \uadf8\ub9bc\uc5d0\uc11c, \ud589\ub82c\uc744 \ub300\uac01\uc120\uc73c\ub85c \uac00\ub85c\uc9c0\ub974\ub294 \ub192\uc740 \ud655\ub960\uc758 \ucd94\uc801(trace)\ub97c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uac00\uc7a5 \uac00\ub2a5\uc131 \ub192\uc740 \uacbd\ub85c \ucc3e\uae30 (\ubc31\ud2b8\ub798\ud0b9)\n\ntrellis\uac00 \ud55c\ubc88 \uc0dd\uc131\ub418\uba74, \ub192\uc740 \ud655\ub960\uc744 \uac00\uc9c0\ub294 \uc694\uc18c\ub97c \ub530\ub77c \uc774\ub97c \ud0d0\uc0c9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uac00\uc7a5 \ub192\uc740 \ud655\ub960\uc744 \uac00\uc9c0\ub294 \uc2dc\uac04 \ub2e8\uacc4\uc5d0\uc11c \ub9c8\uc9c0\ub9c9 \ub77c\ubca8 \uc778\ub371\uc2a4\ub85c\ubd80\ud130 \uc2dc\uc791\ud569\ub2c8\ub2e4. \n\uadf8 \ud6c4\uc5d0, \uc774\uc804 \uc804\uc774 \ud655\ub960 $k_{t, j} p(t+1, c_{j+1})$ \ub610\ub294\n$k_{t, j+1} p(t+1, repeat)$\uc5d0 \uae30\ubc18\ud558\uc5ec \uba38\ubb34\ub97c\uc9c0 ($c_j \\rightarrow c_j$) \ub610\ub294 \uc804\uc774\ud560\uc9c0\n($c_j \\rightarrow c_{j+1}$)\ub97c \uc2dc\uac04 \uc5ed\uc21c\uc73c\ub85c \uc9c4\ud589\ud569\ub2c8\ub2e4.\n\n\ub77c\ubca8\uc774 \ud55c\ubc88 \uc2dc\uc791 \ubd80\ubd84\uc5d0 \ub3c4\ub2ec\ud558\uac8c \ub418\uba74, \uc804\uc774\uac00 \uc218\ud589\ub429\ub2c8\ub2e4.\n\ntrellis \ud589\ub82c\uc740 \uacbd\ub85c\ub97c \ucc3e\uae30 \uc704\ud574 \uc0ac\uc6a9\ub418\uc9c0\ub9cc, \uac01 \ubd84\ud560\uc758 \ucd5c\uc885 \ud655\ub960\uc5d0 \ub300\ud574\uc11c\ub294 \ucd9c\ub825 \ud589\ub82c\uc5d0\uc11c\uc758 \ud504\ub808\uc784\ubcc4 \ud655\ub960\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@dataclass\nclass Point:\n    token_index: int\n    time_index: int\n    score: float\n\n\ndef backtrack(trellis, emission, tokens, blank_id=0):\n    t, j = trellis.size(0) - 1, trellis.size(1) - 1\n\n    path = [Point(j, t, emission[t, blank_id].exp().item())]\n    while j > 0:\n        # \ubc1c\uc0dd\ud558\uc9c0 \uc54a\ub294 \uacbd\uc6b0\uc9c0\ub9cc, \ud639\uc2dc \ubab0\ub77c \uc608\uc678 \ucc98\ub9ac\ud568.\n        assert t > 0\n\n        # 1. \ud604\uc7ac \uc704\uce58\uac00 stay\uc778\uc9c0 \ub610\ub294 change\uc778\uc9c0\ub97c \ud310\ub2e8\ud568.\n        # stay \ub300 change\uc758 \ud504\ub808\uc784 \ubcc4 \uc810\uc218 \uacc4\uc0b0\n        p_stay = emission[t - 1, blank_id]\n        p_change = emission[t - 1, tokens[j]]\n\n        # stay \ub300 change\uc758 \ubb38\ub9e5\uc744 \uace0\ub824\ud55c \uc810\uc218 \uacc4\uc0b0\n        stayed = trellis[t - 1, j] + p_stay\n        changed = trellis[t - 1, j - 1] + p_change\n\n        # \uc704\uce58 \uac31\uc2e0\n        t -= 1\n        if changed > stayed:\n            j -= 1\n\n        # \ud504\ub808\uc784\ubcc4 \ud655\ub960\uc744 \uc774\uc6a9\ud558\uc5ec \uacbd\ub85c\ub97c \uc800\uc7a5\ud568.\n        prob = (p_change if changed > stayed else p_stay).exp().item()\n        path.append(Point(j, t, prob))\n\n    # \uc9c0\uae08 j == 0\uc774\ub77c\uba74 \uc774\ub294, SoS\ub97c \ub3c4\ub2ec\ud588\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud568.\n    # \uc2dc\uac01\ud654\ub97c \uc704\ud574 \ub098\uba38\uc9c0 \ubd80\ubd84\uc744 \ucc44\uc6c0.\n    while t > 0:\n        prob = emission[t - 1, blank_id].exp().item()\n        path.append(Point(j, t - 1, prob))\n        t -= 1\n\n    return path[::-1]\n\n\npath = backtrack(trellis, emission, tokens)\nfor p in path:\n    print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uc2dc\uac01\ud654\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_trellis_with_path(trellis, path):\n    # \uacbd\ub85c\uc640 \ud568\uaed8 trellis\ub97c \uadf8\ub9ac\uae30 \uc704\ud574, 'nan' \uac12\uc744 \uc774\uc6a9\ud569\ub2c8\ub2e4.\n    trellis_with_path = trellis.clone()\n    for _, p in enumerate(path):\n        trellis_with_path[p.time_index, p.token_index] = float(\"nan\")\n    plt.imshow(trellis_with_path.T, origin=\"lower\")\n    plt.title(\"The path found by backtracking\")\n    plt.tight_layout()\n\n\nplot_trellis_with_path(trellis, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc88b\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uacbd\ub85c \ubd84\ud560\n\uc9c0\uae08 \uc774 \uacbd\ub85c\ub294 \uac19\uc740 \ub77c\ubca8\uc758 \ubc18\ubcf5\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc774\ub97c \ubcd1\ud569\ud558\uc5ec \uc6d0\ubcf8 \uc815\ub2f5 \uc2a4\ud06c\ub9bd\ud2b8\uc640 \uac00\uae5d\uac8c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4.\n\n\ub2e4\uc218\uc758 \uacbd\ub85c \uc9c0\uc810\ub4e4\uc744 \ubcd1\ud569\ud560 \ub54c \ub2e8\uc21c\ud558\uac8c, \ubcd1\ud569\ub41c \ubd84\ud560\uc758 \ud3c9\uade0 \ud655\ub960\uc744 \ucde8\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ub77c\ubca8\uc744 \ubcd1\ud569\ud568\n@dataclass\nclass Segment:\n    label: str\n    start: int\n    end: int\n    score: float\n\n    def __repr__(self):\n        return f\"{self.label}\\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})\"\n\n    @property\n    def length(self):\n        return self.end - self.start\n\n\ndef merge_repeats(path):\n    i1, i2 = 0, 0\n    segments = []\n    while i1 < len(path):\n        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n            i2 += 1\n        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n        segments.append(\n            Segment(\n                transcript[path[i1].token_index],\n                path[i1].time_index,\n                path[i2 - 1].time_index + 1,\n                score,\n            )\n        )\n        i1 = i2\n    return segments\n\n\nsegments = merge_repeats(path)\nfor seg in segments:\n    print(seg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uc2dc\uac01\ud654\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_trellis_with_segments(trellis, segments, transcript):\n    # \uacbd\ub85c\uc640 \ud568\uaed8 trellis\ub97c \uadf8\ub9ac\uae30 \uc704\ud574, 'nan' \uac12\uc744 \uc774\uc6a9\ud569\ub2c8\ub2e4.\n    trellis_with_path = trellis.clone()\n    for i, seg in enumerate(segments):\n        if seg.label != \"|\":\n            trellis_with_path[seg.start : seg.end, i] = float(\"nan\")\n\n    fig, [ax1, ax2] = plt.subplots(2, 1, sharex=True)\n    ax1.set_title(\"Path, label and probability for each label\")\n    ax1.imshow(trellis_with_path.T, origin=\"lower\", aspect=\"auto\")\n\n    for i, seg in enumerate(segments):\n        if seg.label != \"|\":\n            ax1.annotate(seg.label, (seg.start, i - 0.7), size=\"small\")\n            ax1.annotate(f\"{seg.score:.2f}\", (seg.start, i + 3), size=\"small\")\n\n    ax2.set_title(\"Label probability with and without repetation\")\n    xs, hs, ws = [], [], []\n    for seg in segments:\n        if seg.label != \"|\":\n            xs.append((seg.end + seg.start) / 2 + 0.4)\n            hs.append(seg.score)\n            ws.append(seg.end - seg.start)\n            ax2.annotate(seg.label, (seg.start + 0.8, -0.07))\n    ax2.bar(xs, hs, width=ws, color=\"gray\", alpha=0.5, edgecolor=\"black\")\n\n    xs, hs = [], []\n    for p in path:\n        label = transcript[p.token_index]\n        if label != \"|\":\n            xs.append(p.time_index + 1)\n            hs.append(p.score)\n\n    ax2.bar(xs, hs, width=0.5, alpha=0.5)\n    ax2.axhline(0, color=\"black\")\n    ax2.grid(True, axis=\"y\")\n    ax2.set_ylim(-0.1, 1.1)\n    fig.tight_layout()\n\n\nplot_trellis_with_segments(trellis, segments, transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc88b\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc5ec\ub7ec \ubd84\ud560\uc744 \ub2e8\uc5b4\ub85c \ubcd1\ud569\n\uc9c0\uae08 \ub2e8\uc5b4\ub85c \ubcd1\ud569\ud574\ubd05\uc2dc\ub2e4. wav2vec2 \ubaa8\ub378\uc740 ``'|'`` \uc744 \ub2e8\uc5b4 \uacbd\uacc4\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \n\uadf8\ub798\uc11c ``'|'`` \uc774 \ub4f1\uc7a5\ud560 \ub54c\ub9c8\ub2e4 \ubd84\ud560\uc744 \ubcd1\ud569\ud569\ub2c8\ub2e4.\n\n\uadf8\ub7ec\uace0 \ub098\uc11c \ucd5c\uc885\uc801\uc73c\ub85c \uc6d0\ubcf8 \uc624\ub514\uc624\ub97c \ubd84\ud560\ub41c \uc624\ub514\uc624\ub85c \ubd84\ud560\ud558\uace0 \uc774\ub97c \ub4e4\uc5b4 \ubd84\ud560\uc774 \uc633\uac8c \ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ub2e8\uc5b4 \ubcd1\ud569\ndef merge_words(segments, separator=\"|\"):\n    words = []\n    i1, i2 = 0, 0\n    while i1 < len(segments):\n        if i2 >= len(segments) or segments[i2].label == separator:\n            if i1 != i2:\n                segs = segments[i1:i2]\n                word = \"\".join([seg.label for seg in segs])\n                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n                words.append(Segment(word, segments[i1].start, segments[i2 - 1].end, score))\n            i1 = i2 + 1\n            i2 = i1\n        else:\n            i2 += 1\n    return words\n\n\nword_segments = merge_words(segments)\nfor word in word_segments:\n    print(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \uc2dc\uac01\ud654\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_alignments(trellis, segments, word_segments, waveform, sample_rate=bundle.sample_rate):\n    trellis_with_path = trellis.clone()\n    for i, seg in enumerate(segments):\n        if seg.label != \"|\":\n            trellis_with_path[seg.start : seg.end, i] = float(\"nan\")\n\n    fig, [ax1, ax2] = plt.subplots(2, 1)\n\n    ax1.imshow(trellis_with_path.T, origin=\"lower\", aspect=\"auto\")\n    ax1.set_facecolor(\"lightgray\")\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n\n    for word in word_segments:\n        ax1.axvspan(word.start - 0.5, word.end - 0.5, edgecolor=\"white\", facecolor=\"none\")\n\n    for i, seg in enumerate(segments):\n        if seg.label != \"|\":\n            ax1.annotate(seg.label, (seg.start, i - 0.7), size=\"small\")\n            ax1.annotate(f\"{seg.score:.2f}\", (seg.start, i + 3), size=\"small\")\n\n    # \uc6d0\ubcf8 waveform\n    ratio = waveform.size(0) / sample_rate / trellis.size(0)\n    ax2.specgram(waveform, Fs=sample_rate)\n    for word in word_segments:\n        x0 = ratio * word.start\n        x1 = ratio * word.end\n        ax2.axvspan(x0, x1, facecolor=\"none\", edgecolor=\"white\", hatch=\"/\")\n        ax2.annotate(f\"{word.score:.2f}\", (x0, sample_rate * 0.51), annotation_clip=False)\n\n    for seg in segments:\n        if seg.label != \"|\":\n            ax2.annotate(seg.label, (seg.start * ratio, sample_rate * 0.55), annotation_clip=False)\n    ax2.set_xlabel(\"time [second]\")\n    ax2.set_yticks([])\n    fig.tight_layout()\n\n\nplot_alignments(\n    trellis,\n    segments,\n    word_segments,\n    waveform[0],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc624\ub514\uc624 \uc0d8\ud50c\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def display_segment(i):\n    ratio = waveform.size(1) / trellis.size(0)\n    word = word_segments[i]\n    x0 = int(ratio * word.start)\n    x1 = int(ratio * word.end)\n    print(f\"{word.label} ({word.score:.2f}): {x0 / bundle.sample_rate:.3f} - {x1 / bundle.sample_rate:.3f} sec\")\n    segment = waveform[:, x0:x1]\n    return IPython.display.Audio(segment.numpy(), rate=bundle.sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uac01 \ubd84\ud560\uc5d0 \ud574\ub2f9\ud558\ub294 \uc624\ub514\uc624 \uc0dd\uc131\nprint(transcript)\nIPython.display.Audio(SPEECH_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display_segment(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uacb0\ub860\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c, torchaudio\uc758 wav2vec2 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uac15\uc81c \uc815\ub82c\uc744 \uc704\ud55c CTC \ubd84\ud560\uc744 \uc218\ud589\ud558\ub294 \ubc29\ubc95\uc744 \uc0b4\ud3b4\ubcf4\uc558\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}