{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTensor\n=======\n\nPyTorch\uc5d0\uc11c\uc758 Tensor\ub294 Torch\uc5d0\uc11c\uc640 \uac70\uc758 \ub3d9\uc77c\ud558\uac8c \ub3d9\uc791\ud569\ub2c8\ub2e4.\n\n\ucd08\uae30\ud654\ub418\uc9c0 \uc54a\uc740 (5 x 7) \ud06c\uae30\uc758 Tensor\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\na = torch.empty(5, 7, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uade0 0, \ubd84\uc0b0 1\uc758 \uc815\uaddc\ubd84\ud3ec\ub97c \ub530\ub974\ub294 \ubb34\uc791\uc704 \uc22b\uc790\ub85c double Tensor\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = torch.randn(5, 7, dtype=torch.double)\nprint(a)\nprint(a.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` \ub294 \ud29c\ud50c(tuple)\uacfc \uac19\uc73c\uba70, \ubaa8\ub4e0 \ud29c\ud50c \uc5f0\uc0b0\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p></div>\n\n\ubc14\uafd4\uce58\uae30(In-place) / \ubc18\ud658\ud558\uae30(Out-of-place)\n---------------------------------------------\n\n\ubaa8\ub4e0 \ubc14\uafd4\uce58\uae30 \uc5f0\uc0b0\uc740 ``_`` \uc811\ubbf8\uc0ac\ub97c \uac16\uace0 \uc788\ub2e4\ub294 \uac83\uc774 \uccab\ubc88\uc9f8 \ucc28\uc774\uc810\uc785\ub2c8\ub2e4.\n\uc608\ub97c \ub4e4\uc5b4, ``add`` \ub294 \uc5f0\uc0b0 \uacb0\uacfc\ub97c \ub3cc\ub824\uc8fc\ub294 \ubc18\ud658\ud558\uae30 \ubc84\uc804\uc774\uace0, ``add_`` \ub294\n(\ud638\ucd9c\ud55c Tensor\uc758 \uac12\uc774 \ubc14\ub00c\ub294) \ubc14\uafd4\uce58\uae30 \ubc84\uc804\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a.fill_(3.5)\n# a\uc758 \uac12\uc774 3.5\ub85c \ubc14\uafd4\uce58\uae30 \ub429\ub2c8\ub2e4.\n\nb = a.add(4.0)\n# a\ub294 \uc5ec\uc804\ud788 3.5\uc785\ub2c8\ub2e4.\n# 3.5 + 4.0 = 7.5\uc758 \uac12\uc774 \ubc18\ud658\ub418\uc5b4 \uc0c8\ub85c\uc6b4 tensor b\uac00 \ub429\ub2c8\ub2e4.\n\nprint(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``narrow`` \uc640 \uac19\uc740 \uc77c\ubd80 \uc5f0\uc0b0\ub4e4\uc740 \ubc14\uafd4\uce58\uae30 \ubc84\uc804\uc744 \uac16\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 ``.narrow_`` \ub294\n\uc874\uc7ac\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \ub610\ud55c, ``fill_`` \uc740 \ubc18\ud658\ud558\uae30 \ubc84\uc804\uc744 \uac16\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \uc5ed\uc2dc\n``.fill`` \ub3c4 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n\n0-\uc778\ub371\uc2a4(Zero Indexing)\n-----------------------\n\n\ub610 \ub2e4\ub978 \ucc28\uc774\uc810\uc740 Tensor\uc758 \uc778\ub371\uc2a4\ub294 0\ubd80\ud130 \uc2dc\uc791(0-\uc778\ub371\uc2a4)\ud55c\ub2e4\ub294 \uc810\uc785\ub2c8\ub2e4.\n(Lua\uc5d0\uc11c tensor\ub294 1-\uc778\ub371\uc2a4\ub97c \uac16\uc2b5\ub2c8\ub2e4.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "b = a[0, 3]  # a\uc758 \uccab\ubc88\uc9f8 \ud589, 4\ubc88\uc9f8 \uc5f4\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Python\uc758 \uc2ac\ub77c\uc774\uc2f1\uc73c\ub85c\ub3c4 Tensor\ub97c \uc778\ub371\uc2a4 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "b = a[:, 3:5]  # a\uc758 \ubaa8\ub4e0 \ud589\uacfc 4\ubc88\uc9f8\uc640 5\ubc88\uc9f8 \uc5f4\uc744 \uc120\ud0dd\ud569\ub2c8\ub2e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uce74\uba5c\ud45c\uae30\ubc95(Camel case) \uc5c6\uc74c\n-----------------------------\n\n\uadf8 \uc678\uc5d0\ub3c4 \uce74\uba5c\ud45c\uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294 \uc0ac\uc18c\ud55c \ucc28\uc774\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\uc77c\ub840\ub85c ``indexAdd`` \ub294 ``index_add_`` \ub77c\uace0 \ud45c\uae30\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.ones(5, 5)\nprint(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = torch.empty(5, 2)\nz[:, 0] = 10\nz[:, 1] = 100\nprint(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x.index_add_(1, torch.tensor([4, 0], dtype=torch.long), z)\nprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NumPy \ubcc0\ud658(bridge)\n------------------\n\nTorch Tensor\ub97c NumPy \ubc30\uc5f4\ub85c \ubcc0\ud658\ud558\uac70\ub098, \uadf8 \ubc18\ub300\ub85c \ud558\ub294 \uac83\uc740 \ub9e4\uc6b0 \uc27d\uc2b5\ub2c8\ub2e4.\nTorch Tensor\uc640 NumPy \ubc30\uc5f4\uc740 \uc800\uc7a5 \uacf5\uac04\uc744 \uacf5\uc720\ud558\uae30 \ub54c\ubb38\uc5d0, \ud558\ub098\ub97c \ubcc0\uacbd\ud558\uba74 \ub2e4\ub978 \ud558\ub098\ub3c4\n\ubcc0\uacbd\ub429\ub2c8\ub2e4.\n\nTorch Tensor\ub97c NumPy \ubc30\uc5f4\ub85c \ubcc0\ud658\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = torch.ones(5)\nprint(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "b = a.numpy()\nprint(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a.add_(1)\nprint(a)\nprint(b) \t# NumPy \ubc30\uc5f4\uc758 \uac12\uc774 \uc5b4\ub5bb\uac8c \ubc14\ub00c\uc5c8\ub294\uc9c0 \ud655\uc778\ud558\uc138\uc694"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NumPy \ubc30\uc5f4\uc744 Torch Tensor\ub85c \ubcc0\ud658\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)  # NumPy \ubc30\uc5f4\uc774 Torch Tensor \uac12\uc744 \uc790\ub3d9\uc73c\ub85c \ubc14\uafbc \uac83\uc744 \ud655\uc778\ud558\uc138\uc694"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CharTensor\ub97c \uc81c\uc678\ud55c CPU \uc0c1\uc758 \ubaa8\ub4e0 Tensor\ub294 NumPy\ub85c\uc758 \ubcc0\ud658\uc744 \uc9c0\uc6d0\ud558\uba70,\n(NumPy\uc5d0\uc11c Tensor\ub85c\uc758) \ubc18\ub300 \ubcc0\ud658\ub3c4 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.\n\nCUDA Tensor\n------------\n\nPyTorch\uc5d0\uc11c CUDA Tensor\ub294 \uba4b\uc9c0\uace0 \uc27d\uc2b5\ub2c8\ub2e4. \uadf8\ub9ac\uace0 CUDA Tensor\ub97c CPU\uc5d0\uc11c GPU\ub85c \uc62e\uaca8\ub3c4\n\uae30\ubcf8 \ud615\uc2dd(underlying type)\uc740 \uc720\uc9c0\ub429\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc774 \ucf54\ub4dc\ub294 CUDA\uac00 \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ud658\uacbd\uc5d0\uc11c\ub9cc \uc2e4\ud589\ub429\ub2c8\ub2e4.\nif torch.cuda.is_available():\n\n    # LongTensor\ub97c \uc0dd\uc131\ud558\uace0 \uc774\ub97c GPU \uc0c1\uc758 torch.cuda.LongTensor\ub85c \uc62e\uae41\ub2c8\ub2e4.\n    a = torch.full((10,), 3, device=torch.device(\"cuda\"))\n    print(type(a))\n    b = a.to(torch.device(\"cpu\"))\n    # CPU\ub85c \ub2e4\uc2dc \uc804\uc1a1\uc744 \ud558\uba74, torch.LongTensor\ub85c \ub418\ub3cc\uc544\uc635\ub2c8\ub2e4."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}