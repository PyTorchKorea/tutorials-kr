{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\uba40\ud2f0-GPU \uc608\uc81c\n==================\n\n\ub370\uc774\ud130 \ubcd1\ub82c \ucc98\ub9ac(Data Parallelism)\ub294 \ubbf8\ub2c8\ubc30\uce58\ub97c \uc5ec\ub7ec \uac1c\uc758 \ub354 \uc791\uc740 \ubbf8\ub2c8\ubc30\uce58\ub85c\n\uc790\ub974\uace0 \uac01\uac01\uc758 \uc791\uc740 \ubbf8\ub2c8\ubc30\uce58\ub97c \ubcd1\ub82c\uc801\uc73c\ub85c \uc5f0\uc0b0\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\ub370\uc774\ud130 \ubcd1\ub82c \ucc98\ub9ac\ub294 ``torch.nn.DataParallel`` \uc744 \uc0ac\uc6a9\ud558\uc5ec \uad6c\ud604\ud569\ub2c8\ub2e4.\n``DataParallel`` \ub85c \uac10\uc300(wrap) \uc218 \uc788\ub294 \ubaa8\ub4c8\uc740 \ubc30\uce58 \ucc28\uc6d0(batch dimension)\uc5d0\uc11c\n\uc5ec\ub7ec GPU\uc5d0\uc11c \ubcd1\ub82c \ucc98\ub9ac\ub420 \uac83\uc785\ub2c8\ub2e4.\n\nDataParallel\n-------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\n\n\nclass DataParallelModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.block1 = nn.Linear(10, 20)\n\n        # wrap block2 in DataParallel\n        self.block2 = nn.Linear(20, 20)\n        self.block2 = nn.DataParallel(self.block2)\n\n        self.block3 = nn.Linear(20, 20)\n\n    def forward(self, x):\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucf54\ub4dc\ub294 CPU \ubaa8\ub4dc \ub54c\uc640 \ubc14\ub014 \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\n\nDataParallel\uc5d0 \ub300\ud55c \ubb38\uc11c\ub294 `\uc5ec\uae30 <http://pytorch.org/docs/nn.html#dataparallel>`_\n\uc5d0\uc11c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n**DataParallel\uc774 \uad6c\ud604\ub41c \uae30\ubcf8\ud615(Primitive):**\n\n\n\uc77c\ubc18\uc801\uc73c\ub85c, PyTorch\uc758 `nn.parallel` \uae30\ubcf8\ud615\uc740 \ub3c5\ub9bd\uc801\uc73c\ub85c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uac04\ub2e8\ud55c MPI\ub958\uc758 \uae30\ubcf8\ud615\uc744 \uad6c\ud604\ud588\uc2b5\ub2c8\ub2e4:\n\n- \ubcf5\uc81c(replicate): \uc5ec\ub7ec \uae30\uae30(Device)\uc5d0 \ubaa8\ub4c8\uc744 \ubcf5\uc81c\ud569\ub2c8\ub2e4.\n- \ubd84\uc0b0(scatter): \uccab\ubc88\uc9f8 \ucc28\uc6d0(First-dimension)\uc5d0\uc11c \uc785\ub825\uc744 \ubd84\uc0b0\ud569\ub2c8\ub2e4.\n- \uc218\uc9d1(gather): \uccab\ubc88\uc9f8 \ucc28\uc6d0\uc758 \uc785\ub825\uc744 \uc218\uc9d1\ud558\uace0 \uc5f0\uacb0(Concatenate)\ud569\ub2c8\ub2e4.\n- \ubcd1\ub82c\uc801\uc6a9(parallel\\_apply): \uc774\ubbf8 \ubd84\uc0b0\ub41c \uc785\ub825\uc758 \uc9d1\ud569\uc744 \uc774\ubbf8 \ubd84\uc0b0\ub41c \ubaa8\ub378\uc758\n  \uc9d1\ud569\uc5d0 \uc801\uc6a9\ud569\ub2c8\ub2e4.\n\n\ub354 \uba85\ud655\ud788 \uc54c\uc544\ubcf4\uae30 \uc704\ud574, \uc774\ub7ec\ud55c \uc694\uc18c\ub97c \uc0ac\uc6a9\ud558\uc5ec \uad6c\uc131\ud55c ``data_parallel``\n\ud568\uc218\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def data_parallel(module, input, device_ids, output_device=None):\n    if not device_ids:\n        return module(input)\n\n    if output_device is None:\n        output_device = device_ids[0]\n\n    replicas = nn.parallel.replicate(module, device_ids)\n    inputs = nn.parallel.scatter(input, device_ids)\n    replicas = replicas[:len(inputs)]\n    outputs = nn.parallel.parallel_apply(replicas, inputs)\n    return nn.parallel.gather(outputs, output_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378\uc758 \uc77c\ubd80\ub294 CPU, \uc77c\ubd80\ub294 GPU\uc5d0\uc11c\n----------------------------------\n\n\uc77c\ubd80\ub294 CPU\uc5d0\uc11c, \uc77c\ubd80\ub294 GPU\uc5d0\uc11c \uad6c\ud604\ud55c \uc791\uc740 \uc2e0\uacbd\ub9dd \uc608\uc81c\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\n\nclass DistributedModel(nn.Module):\n\n    def __init__(self):\n        super().__init__(\n            embedding=nn.Embedding(1000, 10),\n            rnn=nn.Linear(10, 10).to(device),\n        )\n\n    def forward(self, x):\n        # Compute embedding on CPU\n        x = self.embedding(x)\n\n        # Transfer to GPU\n        x = x.to(device)\n\n        # Compute RNN on GPU\n        x = self.rnn(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc9c0\uae08\uae4c\uc9c0 \uae30\uc874 Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c \uac04\ub2e8\ud55c PyTorch \uac1c\uc694\uc600\uc2b5\ub2c8\ub2e4.\n\ubc30\uc6b8 \uac83\uc740 \uc544\uc8fc \ub9ce\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\n``optim`` \ud328\ud0a4\uc9c0, \ub370\uc774\ud130 \ub85c\ub354 \ub4f1\uc744 \uc18c\uac1c\ud558\uace0 \uc788\ub294 \ub354 \ud3ec\uad04\uc801\uc778 \uc785\ubb38\uc6a9 \ud29c\ud1a0\ub9ac\uc5bc\uc744\n\ubcf4\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4: :doc:`/beginner/deep_learning_60min_blitz`.\n\n\ub610\ud55c, \ub2e4\uc74c\uc758 \ub0b4\uc6a9\ub4e4\ub3c4 \uc0b4\ud3b4\ubcf4\uc138\uc694.\n\n-  :doc:`Train neural nets to play video games </intermediate/reinforcement_q_learning>`\n-  `Train a state-of-the-art ResNet network on imagenet`_\n-  `Train an face generator using Generative Adversarial Networks`_\n-  `Train a word-level language model using Recurrent LSTM networks`_\n-  `\ub2e4\ub978 \uc608\uc81c\ub4e4 \ucc38\uace0\ud558\uae30`_\n-  `\ub354 \ub9ce\uc740 \ud29c\ud1a0\ub9ac\uc5bc \ubcf4\uae30`_\n-  `\ud3ec\ub7fc\uc5d0\uc11c PyTorch\uc5d0 \ub300\ud574 \uc598\uae30\ud558\uae30`_\n-  `Slack\uc5d0\uc11c \ub2e4\ub978 \uc0ac\uc6a9\uc790\uc640 \ub300\ud654\ud558\uae30`_\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}