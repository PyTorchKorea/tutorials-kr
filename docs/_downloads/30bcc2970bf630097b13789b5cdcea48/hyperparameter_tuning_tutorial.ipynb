{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Ray Tune\uc744 \uc0ac\uc6a9\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\n\n**\ubc88\uc5ed**: [\uc2ec\ud615\uc900](http://github.com/95hj)\n\n\ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\uc740 \ubcf4\ud1b5\uc758 \ubaa8\ub378\uacfc \ub9e4\uc6b0 \uc815\ud655\ud55c \ubaa8\ub378\uac04\uc758 \ucc28\uc774\ub97c \ub9cc\ub4e4\uc5b4 \ub0bc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc885\uc885 \ub2e4\ub978 \ud559\uc2b5\ub960(Learnig rate)\uc744 \uc120\ud0dd\ud558\uac70\ub098 layer size\ub97c \ubcc0\uacbd\ud558\ub294 \uac83\uacfc \uac19\uc740 \uac04\ub2e8\ud55c \uc791\uc5c5\ub9cc\uc73c\ub85c\ub3c4 \ubaa8\ub378 \uc131\ub2a5\uc5d0 \ud070 \uc601\ud5a5\uc744 \ubbf8\uce58\uae30\ub3c4 \ud569\ub2c8\ub2e4.\n\n\ub2e4\ud589\ud788, \ucd5c\uc801\uc758 \ub9e4\uac1c\ubcc0\uc218 \uc870\ud569\uc744 \ucc3e\ub294\ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \ub3c4\uad6c\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n[Ray Tune](https://docs.ray.io/en/latest/tune.html) \uc740 \ubd84\uc0b0 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\uc744 \uc704\ud55c \uc5c5\uacc4 \ud45c\uc900 \ub3c4\uad6c\uc785\ub2c8\ub2e4.\nRay Tune\uc740 \ucd5c\uc2e0 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uac80\uc0c9 \uc54c\uace0\ub9ac\uc998\uc744 \ud3ec\ud568\ud558\uace0 TensorBoard \ubc0f \uae30\ud0c0 \ubd84\uc11d \ub77c\uc774\ube0c\ub7ec\ub9ac\uc640 \ud1b5\ud569\ub418\uba70 \uae30\ubcf8\uc801\uc73c\ub85c\n[Ray \uc758 \ubd84\uc0b0 \uae30\uacc4 \ud559\uc2b5 \uc5d4\uc9c4](https://ray.io/) \uc744 \ud1b5\ud574 \ud559\uc2b5\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 Ray Tune\uc744 \ud30c\uc774\ud1a0\uce58 \ud559\uc2b5 workflow\uc5d0 \ud1b5\ud569\ud558\ub294 \ubc29\ubc95\uc744 \uc54c\ub824\uc90d\ub2c8\ub2e4.\nCIFAR10 \uc774\ubbf8\uc9c0 \ubd84\ub958\uae30\ub97c \ud6c8\ub828\ud558\uae30 \uc704\ud574 [\ud30c\uc774\ud1a0\uce58 \ubb38\uc11c\uc5d0\uc11c \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html) \ud655\uc7a5\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\uc544\ub798\uc640 \uac19\uc774 \uc57d\uac04\uc758 \uc218\uc815\ub9cc \ucd94\uac00\ud558\uba74 \ub429\ub2c8\ub2e4.\n\n1. \ud568\uc218\uc5d0\uc11c \ub370\uc774\ud130 \ub85c\ub529 \ubc0f \ud559\uc2b5 \ubd80\ubd84\uc744 \uac10\uc2f8\ub450\uace0,\n2. \uc77c\ubd80 \ub124\ud2b8\uc6cc\ud06c \ud30c\ub77c\ubbf8\ud130\ub97c \uad6c\uc131 \uac00\ub2a5\ud558\uac8c \ud558\uace0,\n3. \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \ucd94\uac00\ud558\uace0 (\uc120\ud0dd \uc0ac\ud56d),\n4. \ubaa8\ub378 \ud29c\ub2dd\uc744 \uc704\ud55c \uac80\uc0c9 \uacf5\uac04\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n\n|\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud574 \uc544\ub798\uc758 \ud328\ud0a4\uc9c0\uac00 \uc124\uce58\ub418\uc5b4 \uc788\ub294\uc9c0 \ud655\uc778\ud558\uc138\uc694:\n\n-  ``ray[tune]``: \ubc30\ud3ec\ub41c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd \ub77c\uc774\ube0c\ub7ec\ub9ac\n-  ``torchvision``: \ub370\uc774\ud130 \ubcc0\ud615\uc744 \uc704\ud574 \ud544\uc694\n\n## \uc124\uc815 / \ubd88\ub7ec\uc624\uae30\n\n\ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\ub4e4\uc744 \ubd88\ub7ec\uc624\ub294 \uac83(import)\uc73c\ub85c \uc2dc\uc791\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from functools import partial\nimport os\nimport tempfile\nfrom pathlib import Path\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import random_split\nimport torchvision\nimport torchvision.transforms as transforms\nfrom ray import tune\nfrom ray import train\nfrom ray.train import Checkpoint, get_checkpoint\nfrom ray.tune.schedulers import ASHAScheduler\nimport ray.cloudpickle as pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub300\ubd80\ubd84\uc758 import\ub4e4\uc740 \ud30c\uc774\ud1a0\uce58 \ubaa8\ub378\uc744 \ube4c\ub4dc\ud558\ub294\ub370 \ud544\uc694\ud569\ub2c8\ub2e4.\n\uac00\uc7a5 \ub9c8\uc9c0\ub9c9\uc758 import\ub9cc\uc774 Ray Tune\uc744 \uc0ac\uc6a9\ud558\uae30 \uc704\ud55c \uac83\uc785\ub2c8\ub2e4.\n\n## Data loaders\ndata loader\ub97c \uc790\uccb4 \ud568\uc218\ub85c \uac10\uc2f8\ub450\uace0 \uc804\uc5ed \ub370\uc774\ud130 \ub514\ub809\ud1a0\ub9ac\ub85c \uc804\ub2ec\ud569\ub2c8\ub2e4.\n\uc774\ub7f0 \uc2dd\uc73c\ub85c \uc11c\ub85c \ub2e4\ub978 \uc2e4\ud5d8\ub4e4 \uac04\uc5d0 \ub370\uc774\ud130 \ub514\ub809\ud1a0\ub9ac\ub97c \uacf5\uc720\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir=\"./data\"):\n    transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n    )\n\n    trainset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=True, download=True, transform=transform\n    )\n\n    testset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=False, download=True, transform=transform\n    )\n\n    return trainset, testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uad6c\uc131 \uac00\ub2a5\ud55c \uc2e0\uacbd\ub9dd\n\uad6c\uc131 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\ub9cc \ud29c\ub2dd\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.\n\uc774 \uc608\uc2dc\ub97c \ud1b5\ud574 fully connected layer \ud06c\uae30\ub97c \uc9c0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self, l1=120, l2=84):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n        self.fc2 = nn.Linear(l1, l2)\n        self.fc3 = nn.Linear(l2, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1)  # \ubc30\uce58(batch) \ucc28\uc6d0\uc744 \uc81c\uc678\ud55c \ubaa8\ub4e0 \ucc28\uc6d0\uc744 \ud3c9\ud0c4\ud654(flatten)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud559\uc2b5 \ud568\uc218\n\ud765\ubbf8\ub97c \ub354\ud574\ubcf4\uace0\uc790 [\ud30c\uc774\ud1a0\uce58 \ubb38\uc11c\uc758 \uc608\uc81c](https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html)\n\uc77c\ubd80\ub97c \ubcc0\uacbd\ud558\uc5ec \uc18c\uac1c\ud569\ub2c8\ub2e4.\n\n\ud559\uc2b5 \uc2a4\ud06c\ub9bd\ud2b8\ub97c ``train_cifar(config, data_dir=None)`` \ud568\uc218\ub85c \uac10\uc2f8\ub461\ub2c8\ub2e4.\n``config`` \ub9e4\uac1c\ubcc0\uc218\ub294 \ud559\uc2b5\ud560 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130(hyperparameter)\ub97c \ubc1b\uc2b5\ub2c8\ub2e4.\n``data_dir`` \uc740 \uc5ec\ub7ec \ubc88\uc758 \uc2e4\ud589(run) \uc2dc \ub3d9\uc77c\ud55c \ub370\uc774\ud130 \uc18c\uc2a4\ub97c \uacf5\uc720\ud560 \uc218 \uc788\ub3c4\ub85d\n\ub370\uc774\ud130\ub97c \uc77d\uace0 \uc800\uc7a5\ud558\ub294 \ub514\ub809\ud1a0\ub9ac\ub97c \uc9c0\uc815\ud569\ub2c8\ub2e4.\n\ub610\ud55c, checkpoint\uac00 \uc9c0\uc815\ub418\ub294 \uacbd\uc6b0\uc5d0\ub294 \uc2e4\ud589 \uc2dc\uc791 \uc2dc\uc810\uc758 \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800 \uc0c1\ud0dc(optimizer state)\ub97c\n\ubd88\ub7ec\uc62c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \uc544\ub798\ucabd\uc5d0\uc11c \uccb4\ud06c\ud3ec\uc778\ud2b8(checkpoint)\ub97c \uc9c0\uc815\ud558\ub294 \ubc29\ubc95\uacfc\n\uccb4\ud06c\ud3ec\uc778\ud2b8\uc758 \uc6a9\ub3c4\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```python\nnet = Net(config[\"l1\"], config[\"l2\"])\n\ncheckpoint = get_checkpoint()\nif checkpoint:\n    with checkpoint.as_directory() as checkpoint_dir:\n        data_path = Path(checkpoint_dir) / \"data.pkl\"\n        with open(data_path, \"rb\") as fp:\n            checkpoint_state = pickle.load(fp)\n        start_epoch = checkpoint_state[\"epoch\"]\n        net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\nelse:\n    start_epoch = 0\n```\n\ub610\ud55c, \uc635\ud2f0\ub9c8\uc774\uc800\uc758 \ud559\uc2b5\ub960(learning rate)\uc744 \uad6c\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```python\noptimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n```\n\ub610\ud55c \ud559\uc2b5 \ub370\uc774\ud130\ub97c \ud559\uc2b5 \ubc0f \uac80\uc99d \uc138\ud2b8\ub85c \ub098\ub215\ub2c8\ub2e4. \ub530\ub77c\uc11c \ub370\uc774\ud130\uc758 80%\ub294 \ubaa8\ub378 \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud558\uace0,\n\ub098\uba38\uc9c0 20%\uc5d0 \ub300\ud574 \uc720\ud6a8\uc131 \uac80\uc0ac \ubc0f \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8 \uc138\ud2b8\ub97c \ubc18\ubcf5\ud558\ub294 \ubc30\uce58 \ud06c\uae30\ub3c4 \uad6c\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n### DataParallel\uc744 \uc774\uc6a9\ud55c GPU(\ub2e4\uc911)\uc9c0\uc6d0 \ucd94\uac00\n\uc774\ubbf8\uc9c0 \ubd84\ub958\ub294 GPU\ub97c \uc0ac\uc6a9\ud560 \ub54c \uc774\uc810\uc774 \ub9ce\uc2b5\ub2c8\ub2e4. \uc6b4\uc88b\uac8c\ub3c4 Ray Tune\uc5d0\uc11c \ud30c\uc774\ud1a0\uce58\uc758 \ucd94\uc0c1\ud654\ub97c \uacc4\uc18d \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\ub530\ub77c\uc11c \uc5ec\ub7ec GPU\uc5d0\uc11c \ub370\uc774\ud130 \ubcd1\ub82c \ud6c8\ub828\uc744 \uc9c0\uc6d0\ud558\uae30 \uc704\ud574 \ubaa8\ub378\uc744 ``nn.DataParallel`` \uc73c\ub85c \uac10\uc300 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```python\ndevice = \"cpu\"\nif torch.cuda.is_available():\n    device = \"cuda:0\"\n    if torch.cuda.device_count() > 1:\n        net = nn.DataParallel(net)\nnet.to(device)\n```\n``device`` \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc6a9 \uac00\ub2a5\ud55c GPU\uac00 \uc5c6\uc744 \ub54c\ub3c4 \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\n\ud30c\uc774\ud1a0\uce58\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \ub370\uc774\ud130\ub97c GPU\uba54\ubaa8\ub9ac\uc5d0 \uba85\uc2dc\uc801\uc73c\ub85c \ubcf4\ub0b4\ub3c4\ub85d \uc694\uad6c\ud569\ub2c8\ub2e4.\n\n```python\nfor i, data in enumerate(trainloader, 0):\n    inputs, labels = data\n    inputs, labels = inputs.to(device), labels.to(device)\n```\n\uc774 \ucf54\ub4dc\ub294 \uc774\uc81c CPU\ub4e4, \ub2e8\uc77c GPU \ubc0f \ub2e4\uc911 GPU\uc5d0 \ub300\ud55c \ud559\uc2b5\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.\n\ud2b9\ud788 Ray\ub294 [fractional-GPU](https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus) \ub3c4 \uc9c0\uc6d0\ud558\ubbc0\ub85c\n\ubaa8\ub378\uc774 GPU \uba54\ubaa8\ub9ac\uc5d0 \uc801\ud569\ud55c \uc0c1\ud669\uc5d0\uc11c\ub294 \ud14c\uc2a4\ud2b8 \uac04\uc5d0 GPU\ub97c \uacf5\uc720\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ub098\uc911\uc5d0 \ub2e4\ub8f0 \uac83\uc785\ub2c8\ub2e4.\n\n### Ray Tune\uc73c\ub85c \ud1b5\uc2e0\ud558\uae30\n\n\uac00\uc7a5 \ud765\ubbf8\ub85c\uc6b4 \ubd80\ubd84\uc740 Ray Tune\uacfc\uc758 \ud1b5\uc2e0\uc785\ub2c8\ub2e4:\n\n```python\ncheckpoint_data = {\n    \"epoch\": epoch,\n    \"net_state_dict\": net.state_dict(),\n    \"optimizer_state_dict\": optimizer.state_dict(),\n}\nwith tempfile.TemporaryDirectory() as checkpoint_dir:\n    data_path = Path(checkpoint_dir) / \"data.pkl\"\n    with open(data_path, \"wb\") as fp:\n        pickle.dump(checkpoint_data, fp)\n\n    checkpoint = Checkpoint.from_directory(checkpoint_dir)\n    train.report(\n        {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n        checkpoint=checkpoint,\n    )\n```\n\uc5ec\uae30\uc11c \uba3c\uc800 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud55c \ub2e4\uc74c \uc77c\ubd80 \uba54\ud2b8\ub9ad\uc744 Ray Tune\uc5d0 \ub2e4\uc2dc \ubcf4\ub0c5\ub2c8\ub2e4. \ud2b9\ud788, validation loss\uc640 accuracy\ub97c\nRay Tune\uc73c\ub85c \ub2e4\uc2dc \ubcf4\ub0c5\ub2c8\ub2e4. \uadf8 \ud6c4 Ray Tune\uc740 \uc774\ub7ec\ud55c \uba54\ud2b8\ub9ad\uc744 \uc0ac\uc6a9\ud558\uc5ec \ucd5c\uc0c1\uc758 \uacb0\uacfc\ub97c \uc720\ub3c4\ud558\ub294 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uad6c\uc131\uc744\n\uacb0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uba54\ud2b8\ub9ad\ub4e4\uc740 \ub610\ud55c \ub9ac\uc18c\uc2a4 \ub0ad\ube44\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud574 \uc131\ub2a5\uc774 \uc88b\uc9c0 \uc54a\uc740 \uc2e4\ud5d8\uc744 \uc870\uae30\uc5d0 \uc911\uc9c0\ud558\ub294 \ub370 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uccb4\ud06c\ud3ec\uc778\ud2b8 \uc800\uc7a5\uc740 \uc120\ud0dd\uc0ac\ud56d\uc774\uc9c0\ub9cc,\n[Population Based Training](https://docs.ray.io/en/latest/tune/examples/pbt_guide.html) \uacfc \uac19\uc740 \uace0\uae09 \uc2a4\ucf00\uc904\ub7ec\ub97c\n\uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \ud544\uc694\ud569\ub2c8\ub2e4.\n\ub610\ud55c, \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud574\ub450\uba74 \ub098\uc911\uc5d0 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ub85c\ub4dc\ud558\uace0 \ud3c9\uac00 \uc138\ud2b8(test set)\uc5d0\uc11c \uac80\uc99d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n### \uc804\uccb4 \ud559\uc2b5 \ud568\uc218\n\n\uc804\uccb4 \uc608\uc81c \ucf54\ub4dc\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_cifar(config, data_dir=None):\n    net = Net(config[\"l1\"], config[\"l2\"])\n\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count() > 1:\n            net = nn.DataParallel(net)\n    net.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n\n    checkpoint = get_checkpoint()\n    if checkpoint:\n        with checkpoint.as_directory() as checkpoint_dir:\n            data_path = Path(checkpoint_dir) / \"data.pkl\"\n            with open(data_path, \"rb\") as fp:\n                checkpoint_state = pickle.load(fp)\n            start_epoch = checkpoint_state[\"epoch\"]\n            net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n    else:\n        start_epoch = 0\n\n    trainset, testset = load_data(data_dir)\n\n    test_abs = int(len(trainset) * 0.8)\n    train_subset, val_subset = random_split(\n        trainset, [test_abs, len(trainset) - test_abs]\n    )\n\n    trainloader = torch.utils.data.DataLoader(\n        train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8\n    )\n    valloader = torch.utils.data.DataLoader(\n        val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=8\n    )\n\n    for epoch in range(start_epoch, 10):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i % 2000 == 1999:  # print every 2000 mini-batches\n                print(\n                    \"[%d, %5d] loss: %.3f\"\n                    % (epoch + 1, i + 1, running_loss / epoch_steps)\n                )\n                running_loss = 0.0\n\n        # Validation loss\n        val_loss = 0.0\n        val_steps = 0\n        total = 0\n        correct = 0\n        for i, data in enumerate(valloader, 0):\n            with torch.no_grad():\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = net(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.cpu().numpy()\n                val_steps += 1\n\n        checkpoint_data = {\n            \"epoch\": epoch,\n            \"net_state_dict\": net.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n        }\n        with tempfile.TemporaryDirectory() as checkpoint_dir:\n            data_path = Path(checkpoint_dir) / \"data.pkl\"\n            with open(data_path, \"wb\") as fp:\n                pickle.dump(checkpoint_data, fp)\n\n            checkpoint = Checkpoint.from_directory(checkpoint_dir)\n            train.report(\n                {\"loss\": val_loss / val_steps, \"accuracy\": correct / total},\n                checkpoint=checkpoint,\n            )\n\n    print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubcf4\ub2e4\uc2dc\ud53c, \ub300\ubd80\ubd84\uc758 \ucf54\ub4dc\ub294 \uc6d0\ubcf8 \uc608\uc81c\uc5d0\uc11c \uc9c1\uc811 \uc801\uc6a9\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n## \ud14c\uc2a4\ud2b8\uc14b \uc815\ud655\ub3c4(Test set accuracy)\n\uc77c\ubc18\uc801\uc73c\ub85c \uba38\uc2e0\ub7ec\ub2dd \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 \ubaa8\ub378 \ud559\uc2b5 \uc2dc \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc740 \ub370\uc774\ud130\ub97c\n\ud14c\uc2a4\ud2b8\uc14b\uc73c\ub85c \ub530\ub85c \ub5bc\uc5b4\ub0b8 \ub4a4, \uc774\ub97c \uc0ac\uc6a9\ud558\uc5ec \ud14c\uc2a4\ud2b8\ud569\ub2c8\ub2e4.\n\uc774\ub7ec\ud55c \ud14c\uc2a4\ud2b8\uc14b \ub610\ud55c \ud568\uc218\ub85c \uac10\uc2f8\ub458 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\n    trainset, testset = load_data()\n\n    testloader = torch.utils.data.DataLoader(\n        testset, batch_size=4, shuffle=False, num_workers=2\n    )\n\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ud568\uc218\ub294 \ub610\ud55c ``device`` \ud30c\ub77c\ubbf8\ud130\ub97c \uc694\uad6c\ud558\ubbc0\ub85c, test set \ud3c9\uac00\ub97c GPU\uc5d0\uc11c \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n## \uac80\uc0c9 \uacf5\uac04 \uad6c\uc131\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c Ray Tune\uc758 \uac80\uc0c9 \uacf5\uac04\uc744 \uc815\uc758\ud574\uc57c \ud569\ub2c8\ub2e4. \uc608\uc2dc\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n```python\nconfig = {\n    \"l1\": tune.choice([2 ** i for i in range(9)]),\n    \"l2\": tune.choice([2 ** i for i in range(9)]),\n    \"lr\": tune.loguniform(1e-4, 1e-1),\n    \"batch_size\": tune.choice([2, 4, 8, 16])\n}\n```\n``tune.choice()`` \ud568\uc218\ub294 \uade0\uc77c\ud558\uac8c \uc0d8\ud50c\ub9c1\ub41c \uac12\ub4e4\uc758 \ubaa9\ub85d\uc744 \uc785\ub825\uc73c\ub85c \ubc1b\uc2b5\ub2c8\ub2e4.\n\uc704 \uc608\uc2dc\uc5d0\uc11c ``l1`` \ubc0f ``l2`` \ud30c\ub77c\ubbf8\ud130\ub294 4\uc640 256 \uc0ac\uc774\uc758 2\uc758 \uac70\ub4ed\uc81c\uacf1 \uac12\uc778 4, 8, 16, 32, 64, 128, 256 \uc785\ub2c8\ub2e4.\n``lr`` (\ud559\uc2b5\ub960)\uc740 0.0001\uacfc 0.1 \uc0ac\uc774\uc5d0\uc11c \uade0\uc77c\ud558\uac8c \uc0d8\ud50c\ub9c1 \ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \ubc30\uce58 \ud06c\uae30\ub294 2, 4, 8, 16\uc911\uc5d0\uc11c \uc120\ud0dd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uac01 \uc2e4\ud5d8\uc5d0\uc11c, Ray Tune\uc740 \uc774\uc81c \uc774\ub7ec\ud55c \uac80\uc0c9 \uacf5\uac04\uc5d0\uc11c \ub9e4\uac1c\ubcc0\uc218 \uc870\ud569\uc744 \ubb34\uc791\uc704\ub85c \uc0d8\ud50c\ub9c1\ud569\ub2c8\ub2e4.\n\uadf8\ub7f0 \ub2e4\uc74c \uc5ec\ub7ec \ubaa8\ub378\uc744 \ubcd1\ub82c\ub85c \ud6c8\ub828\ud558\uace0 \uc774 \uc911\uc5d0\uc11c \uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\uc744 \ucc3e\uc2b5\ub2c8\ub2e4. \ub610\ud55c \uc131\ub2a5\uc774 \uc88b\uc9c0 \uc54a\uc740 \uc2e4\ud5d8\uc744 \uc870\uae30\uc5d0 \uc885\ub8cc\ud558\ub294 ``ASHAScheduler`` \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\uc0c1\uc218 ``data_dir`` \ud30c\ub77c\ubbf8\ud130\ub97c \uc124\uc815\ud558\uae30 \uc704\ud574 ``functools.partial`` \ub85c ``train_cifar`` \ud568\uc218\ub97c \uac10\uc2f8\ub461\ub2c8\ub2e4. \ub610\ud55c \uac01 \uc2e4\ud5d8\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \uc790\uc6d0\ub4e4(resources)\uc744 Ray Tune\uc5d0 \uc54c\ub9b4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```python\ngpus_per_trial = 2\n# ...\nresult = tune.run(\n    partial(train_cifar, data_dir=data_dir),\n    resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n    config=config,\n    num_samples=num_samples,\n    scheduler=scheduler,\n    checkpoint_at_end=True)\n```\n\ud30c\uc774\ud1a0\uce58 ``DataLoader`` \uc778\uc2a4\ud134\uc2a4\uc758 ``num_workers`` \uc744 \ub298\ub9ac\uae30 \uc704\ud574 CPU \uc218\ub97c \uc9c0\uc815\ud558\uace0 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uac01 \uc2e4\ud5d8\uc5d0\uc11c \uc120\ud0dd\ud55c \uc218\uc758 GPU\ub4e4\uc740 \ud30c\uc774\ud1a0\uce58\uc5d0 \ud45c\uc2dc\ub429\ub2c8\ub2e4. \uc2e4\ud5d8\ub4e4\uc740 \uc694\uccad\ub418\uc9c0 \uc54a\uc740 GPU\uc5d0 \uc561\uc138\uc2a4\ud560 \uc218 \uc5c6\uc73c\ubbc0\ub85c \uac19\uc740 \uc790\uc6d0\ub4e4\uc744 \uc0ac\uc6a9\ud558\ub294 \uc911\ubcf5\ub41c \uc2e4\ud5d8\uc5d0 \ub300\ud574 \uc2e0\uacbd\uc4f0\uc9c0 \uc54a\uc544\ub3c4 \ub429\ub2c8\ub2e4.\n\n\ubd80\ubd84 GPUs\ub97c \uc9c0\uc815\ud560 \uc218\ub3c4 \uc788\uc73c\ubbc0\ub85c, ``gpus_per_trial=0.5`` \uc640 \uac19\uc740 \uac83 \ub610\ud55c \uac00\ub2a5\ud569\ub2c8\ub2e4. \uc774\ud6c4 \uac01 \uc2e4\ud5d8\uc740 GPU\ub97c \uacf5\uc720\ud569\ub2c8\ub2e4. \uc0ac\uc6a9\uc790\ub294 \ubaa8\ub378\uc774 \uc5ec\uc804\ud788 GPU\uba54\ubaa8\ub9ac\uc5d0 \uc801\ud569\ud55c\uc9c0\ub9cc \ud655\uc778\ud558\uba74 \ub429\ub2c8\ub2e4.\n\n\ubaa8\ub378\uc744 \ud6c8\ub828\uc2dc\ud0a8 \ud6c4, \uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\uc744 \ucc3e\uace0 \uccb4\ud06c\ud3ec\uc778\ud2b8 \ud30c\uc77c\uc5d0\uc11c \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ub85c\ub4dc\ud569\ub2c8\ub2e4. \uc774\ud6c4 test set \uc815\ud655\ub3c4(accuracy)\ub97c \uc5bb\uace0 \ubaa8\ub4e0 \uac83\ub4e4\uc744 \ucd9c\ub825\ud558\uc5ec \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc804\uccb4 \uc8fc\uc694 \uae30\ub2a5\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n    data_dir = os.path.abspath(\"./data\")\n    load_data(data_dir)\n    config = {\n        \"l1\": tune.choice([2**i for i in range(9)]),\n        \"l2\": tune.choice([2**i for i in range(9)]),\n        \"lr\": tune.loguniform(1e-4, 1e-1),\n        \"batch_size\": tune.choice([2, 4, 8, 16]),\n    }\n    scheduler = ASHAScheduler(\n        metric=\"loss\",\n        mode=\"min\",\n        max_t=max_num_epochs,\n        grace_period=1,\n        reduction_factor=2,\n    )\n    result = tune.run(\n        partial(train_cifar, data_dir=data_dir),\n        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n        config=config,\n        num_samples=num_samples,\n        scheduler=scheduler,\n    )\n\n    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n    print(f\"Best trial config: {best_trial.config}\")\n    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n    print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n\n    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if gpus_per_trial > 1:\n            best_trained_model = nn.DataParallel(best_trained_model)\n    best_trained_model.to(device)\n\n    best_checkpoint = result.get_best_checkpoint(trial=best_trial, metric=\"accuracy\", mode=\"max\")\n    with best_checkpoint.as_directory() as checkpoint_dir:\n        data_path = Path(checkpoint_dir) / \"data.pkl\"\n        with open(data_path, \"rb\") as fp:\n            best_checkpoint_data = pickle.load(fp)\n\n        best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n        test_acc = test_accuracy(best_trained_model, device)\n        print(\"Best trial test set accuracy: {}\".format(test_acc))\n\n\nif __name__ == \"__main__\":\n    # \ub9e4 \uc2e4\ud5d8\ub2f9 \uc0ac\uc6a9\ud560 GPU \uc218\ub97c \uc5ec\uae30\uc5d0\uc11c \ubcc0\uacbd\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucf54\ub4dc\ub97c \uc2e4\ud589\ud558\uba74 \uacb0\uacfc\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \ub098\uc62c \uac83\uc785\ub2c8\ub2e4:\n\n```sh\nNumber of trials: 10/10 (10 TERMINATED)\n+-----+--------------+------+------+-------------+--------+---------+------------+\n| ... |   batch_size |   l1 |   l2 |          lr |   iter |    loss |   accuracy |\n|-----+--------------+------+------+-------------+--------+---------+------------|\n| ... |            2 |    1 |  256 | 0.000668163 |      1 | 2.31479 |     0.0977 |\n| ... |            4 |   64 |    8 | 0.0331514   |      1 | 2.31605 |     0.0983 |\n| ... |            4 |    2 |    1 | 0.000150295 |      1 | 2.30755 |     0.1023 |\n| ... |           16 |   32 |   32 | 0.0128248   |     10 | 1.66912 |     0.4391 |\n| ... |            4 |    8 |  128 | 0.00464561  |      2 | 1.7316  |     0.3463 |\n| ... |            8 |  256 |    8 | 0.00031556  |      1 | 2.19409 |     0.1736 |\n| ... |            4 |   16 |  256 | 0.00574329  |      2 | 1.85679 |     0.3368 |\n| ... |            8 |    2 |    2 | 0.00325652  |      1 | 2.30272 |     0.0984 |\n| ... |            2 |    2 |    2 | 0.000342987 |      2 | 1.76044 |     0.292  |\n| ... |            4 |   64 |   32 | 0.003734    |      8 | 1.53101 |     0.4761 |\n+-----+--------------+------+------+-------------+--------+---------+------------+\n\nBest trial config: {'l1': 64, 'l2': 32, 'lr': 0.0037339984519545164, 'batch_size': 4}\nBest trial final validation loss: 1.5310075663924216\nBest trial final validation accuracy: 0.4761\nBest trial test set accuracy: 0.4737\n```\n\ub300\ubd80\ubd84\uc758 \uc2e4\ud5d8\uc740 \uc790\uc6d0 \ub0ad\ube44\ub97c \ub9c9\uae30 \uc704\ud574 \uc77c\ucc0d \uc911\ub2e8\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\uac00\uc7a5 \uc88b\uc740 \uacb0\uacfc\ub97c \uc5bb\uc740 \uc2e4\ud5d8\uc740 47%\uc758 \uc815\ud655\ub3c4\ub97c \ub2ec\uc131\ud588\uc73c\uba70,\n\uc774\ub294 \ud14c\uc2a4\ud2b8\uc14b\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774\uac83\uc774 \uc804\ubd80\uc785\ub2c8\ub2e4! \uc774\uc81c \ud30c\uc774\ud1a0\uce58 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc870\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}