{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\uae30\ucd08\ubd80\ud130 \uc2dc\uc791\ud558\ub294 NLP: \ubb38\uc790-\ub2e8\uc704 RNN\uc73c\ub85c \uc774\ub984 \ubd84\ub958\ud558\uae30\n********************************************************************************\n**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n  **\ubc88\uc5ed**: `\ud669\uc131\uc218 <https://github.com/adonisues>`_\n\n\n\ub2e8\uc5b4\ub97c \ubd84\ub958\ud558\uae30 \uc704\ud574 \uae30\ucd08\uc801\uc778 \ubb38\uc790-\ub2e8\uc704 RNN\uc744 \uad6c\ucd95\ud558\uace0 \ud559\uc2b5 \ud560 \uc608\uc815\uc785\ub2c8\ub2e4.\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 (\uc774\ud6c4 2\uac1c \ud29c\ud1a0\ub9ac\uc5bc\uacfc \ud568\uaed8) NLP \ubaa8\ub378\ub9c1\uc744 \uc704\ud55c \ub370\uc774\ud130 \uc804\ucc98\ub9ac\ub97c\n`torchtext` \uc758 \ud3b8\ub9ac\ud55c \ub9ce\uc740 \uae30\ub2a5\ub4e4\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0 \uc5b4\ub5bb\uac8c \ud558\ub294\uc9c0 \"\uae30\ucd08\ubd80\ud130(from scratch)\"\n\ubcf4\uc5ec\uc8fc\uae30 \ub54c\ubb38\uc5d0  NLP \ubaa8\ub378\ub9c1\uc744 \uc704\ud55c \uc804\ucc98\ub9ac\uac00 \uc800\uc218\uc900\uc5d0\uc11c \uc5b4\ub5bb\uac8c \uc9c4\ud589\ub418\ub294\uc9c0\ub97c \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\ubb38\uc790-\ub2e8\uc704 RNN\uc740 \ub2e8\uc5b4\ub97c \ubb38\uc790\uc758 \uc5f0\uc18d\uc73c\ub85c \uc77d\uc5b4 \ub4e4\uc5ec\uc11c \uac01 \ub2e8\uacc4\uc758 \uc608\uce21\uacfc\n\"\uc740\ub2c9 \uc0c1\ud0dc(Hidden State)\" \ucd9c\ub825\ud558\uace0, \ub2e4\uc74c \ub2e8\uacc4\uc5d0 \uc774\uc804 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc804\ub2ec\ud569\ub2c8\ub2e4.\n\ub2e8\uc5b4\uac00 \uc18d\ud55c \ud074\ub798\uc2a4\ub85c \ucd9c\ub825\uc774 \ub418\ub3c4\ub85d \ucd5c\uc885 \uc608\uce21\uc73c\ub85c \uc120\ud0dd\ud569\ub2c8\ub2e4.\n\n\uad6c\uccb4\uc801\uc73c\ub85c, 18\uac1c \uc5b8\uc5b4\ub85c \ub41c \uc218\ucc9c \uac1c\uc758 \uc131(\u59d3)\uc744 \ud6c8\ub828\uc2dc\ud0a4\uace0,\n\ucca0\uc790\uc5d0 \ub530\ub77c \uc774\ub984\uc774 \uc5b4\ub5a4 \uc5b8\uc5b4\uc778\uc9c0 \uc608\uce21\ud569\ub2c8\ub2e4:\n\n::\n\n    $ python predict.py Hinton\n    (-0.47) Scottish\n    (-1.52) English\n    (-3.57) Irish\n\n    $ python predict.py Schmidhuber\n    (-0.19) German\n    (-2.48) Czech\n    (-2.68) Dutch\n\n\n**\ucd94\ucc9c \uc790\ub8cc:**\n\nPytorch\ub97c \uc124\uce58\ud588\uace0, Python\uc744 \uc54c\uace0, Tensor\ub97c \uc774\ud574\ud55c\ub2e4\uace0 \uac00\uc815\ud569\ub2c8\ub2e4:\n\n-  https://pytorch.org/ \uc124\uce58 \uc548\ub0b4\n-  :doc:`/beginner/deep_learning_60min_blitz` PyTorch \uc2dc\uc791\ud558\uae30\n-  :doc:`/beginner/pytorch_with_examples` \ub113\uace0 \uae4a\uc740 \ud1b5\ucc30\uc744 \uc704\ud55c \uc790\ub8cc\n-  :doc:`/beginner/former_torchies_tutorial` \uc774\uc804 Lua Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c \uc790\ub8cc\n\nRNN\uacfc \uc791\ub3d9 \ubc29\uc2dd\uc744 \uc544\ub294 \uac83 \ub610\ud55c \uc720\uc6a9\ud569\ub2c8\ub2e4:\n\n-  `The Unreasonable Effectiveness of Recurrent Neural\n   Networks <https://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n   \uc2e4\uc0dd\ud65c \uc608\uc81c\ub97c \ubcf4\uc5ec \uc90d\ub2c8\ub2e4.\n-  `Understanding LSTM\n   Networks <https://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n   LSTM\uc5d0 \uad00\ud55c \uac83\uc774\uc9c0\ub9cc RNN\uc5d0 \uad00\ud574\uc11c\ub3c4 \uc720\uc775\ud569\ub2c8\ub2e4.\n\n\ub370\uc774\ud130 \uc900\ube44\n==================\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>`\uc5ec\uae30 <https://download.pytorch.org/tutorial/data.zip>`__ \uc5d0\uc11c \ub370\uc774\ud130\ub97c \ub2e4\uc6b4 \ubc1b\uace0,\n   \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624.</p></div>\n\n``data/names`` \ub514\ub809\ud1a0\ub9ac\uc5d0\ub294 \"[Language].txt\" \ub77c\ub294 18 \uac1c\uc758 \ud14d\uc2a4\ud2b8 \ud30c\uc77c\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\uac01 \ud30c\uc77c\uc5d0\ub294 \ud55c \uc904\uc5d0 \ud558\ub098\uc758 \uc774\ub984\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uc73c\uba70 \ub300\ubd80\ubd84 \ub85c\ub9c8\uc790\ub85c \ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4\n(\uadf8\ub7ec\ub098, \uc720\ub2c8\ucf54\ub4dc\uc5d0\uc11c ASCII\ub85c \ubcc0\ud658\ud574\uc57c \ud568).\n\n\uac01 \uc5b8\uc5b4 \ubcc4\ub85c \uc774\ub984 \ubaa9\ub85d \uc0ac\uc804 ``{language: [names ...]}`` \uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n\uc77c\ubc18 \ubcc0\uc218 \"category\" \uc640 \"line\" (\uc6b0\ub9ac\uc758 \uacbd\uc6b0 \uc5b8\uc5b4\uc640 \uc774\ub984)\uc740 \uc774\ud6c4\uc758 \ud655\uc7a5\uc131\uc744 \uc704\ud574 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\uc5ed\uc790 \uc8fc:  \"line\" \uc5d0 \uc785\ub825\uc744 \"category\"\uc5d0 \ud074\ub798\uc2a4\ub97c \uc801\uc6a9\ud558\uc5ec \ub2e4\ub978 \ubb38\uc81c\uc5d0\ub3c4 \ud65c\uc6a9 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n   \uc5ec\uae30\uc11c\ub294 \"line\"\uc5d0 \uc774\ub984(ex. Robert )\ub97c \uc785\ub825\uc73c\ub85c \"category\"\uc5d0 \ud074\ub798\uc2a4(ex. english)\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport glob\nimport os\n\ndef findFiles(path): return glob.glob(path)\n\nprint(findFiles('data/names/*.txt'))\n\nimport unicodedata\nimport string\n\nall_letters = string.ascii_letters + \" .,;'\"\nn_letters = len(all_letters)\n\n# \uc720\ub2c8\ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 ASCII\ub85c \ubcc0\ud658, https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in all_letters\n    )\n\nprint(unicodeToAscii('\u015alus\u00e0rski'))\n\n# \uac01 \uc5b8\uc5b4\uc758 \uc774\ub984 \ubaa9\ub85d\uc778 category_lines \uc0ac\uc804 \uc0dd\uc131\ncategory_lines = {}\nall_categories = []\n\n# \ud30c\uc77c\uc744 \uc77d\uace0 \uc904 \ub2e8\uc704\ub85c \ubd84\ub9ac\ndef readLines(filename):\n    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n    return [unicodeToAscii(line) for line in lines]\n\nfor filename in findFiles('data/names/*.txt'):\n    category = os.path.splitext(os.path.basename(filename))[0]\n    all_categories.append(category)\n    lines = readLines(filename)\n    category_lines[category] = lines\n\nn_categories = len(all_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \uac01 ``category`` (\uc5b8\uc5b4)\ub97c ``line`` (\uc774\ub984)\uc5d0 \ub9e4\ud551\ud558\ub294 \uc0ac\uc804\uc778\n``category_lines`` \ub97c \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4. \ub098\uc911\uc5d0 \ucc38\uc870 \ud560 \uc218 \uc788\ub3c4\ub85d\n``all_categories`` (\uc5b8\uc5b4 \ubaa9\ub85d)\uc640 ``n_categories`` \ub3c4 \ucd94\uc801\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(category_lines['Italian'][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\ub984\uc744 Tensor\ub85c \ubcc0\uacbd\n--------------------------\n\n\uc774\uc81c \ubaa8\ub4e0 \uc774\ub984\uc744 \uccb4\uacc4\ud654 \ud588\uc73c\ubbc0\ub85c, \uc774\ub97c \ud65c\uc6a9\ud558\uae30 \uc704\ud574 Tensor\ub85c\n\uc804\ud658\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n\ud558\ub098\uc758 \ubb38\uc790\ub97c \ud45c\ud604\ud558\uae30 \uc704\ud574, \ud06c\uae30\uac00 ``<1 x n_letters>`` \uc778\n\"One-Hot \ubca1\ud130\" \ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. One-Hot \ubca1\ud130\ub294 \ud604\uc7ac \ubb38\uc790\uc758\n\uc8fc\uc18c\uc5d0\ub9cc 1\uc744 \uac12\uc73c\ub85c \uac00\uc9c0\uace0 \uadf8\uc678\uc5d0 \ub098\uba38\uc9c0\ub294 0\uc73c\ub85c \ucc44\uc6cc\uc9c4\ub2e4.\n\uc608\uc2dc ``\"b\" = <0 1 0 0 0 ...>`` .\n\n\ub2e8\uc5b4\ub97c \ub9cc\ub4e4\uae30 \uc704\ud574 One-Hot \ubca1\ud130\ub4e4\uc744 2 \ucc28\uc6d0 \ud589\ub82c\n``<line_length x 1 x n_letters>`` \uc5d0 \uacb0\ud569\uc2dc\ud0b5\ub2c8\ub2e4.\n\n\uc704\uc5d0\uc11c \ubcf4\uc774\ub294 \ucd94\uac00\uc801\uc778 1\ucc28\uc6d0\uc740 PyTorch\uc5d0\uc11c \ubaa8\ub4e0 \uac83\uc774 \ubc30\uce58(batch)\uc5d0 \uc788\ub2e4\uace0 \uac00\uc815\ud558\uae30\n\ub54c\ubb38\uc5d0 \ubc1c\uc0dd\ud569\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \ubc30\uce58 \ud06c\uae30 1\uc744 \uc0ac\uc6a9\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "'''\n.. NOTE::\n\uc5ed\uc790 \uc8fc:  One-Hot \ubca1\ud130\ub294 \uc5b8\uc5b4\ub97c \ub2e4\ub8f0 \ub54c \uc790\uc8fc \uc774\uc6a9\ub418\uba70,\n\ub2e8\uc5b4,\uae00\uc790 \ub4f1\uc744 \ubca1\ud130\ub85c \ud45c\ud604 \ud560 \ub54c \ub2e8\uc5b4,\uae00\uc790 \uc0ac\uc774\uc758 \uc0c1\uad00 \uad00\uacc4\ub97c \ubbf8\ub9ac \uc54c \uc218 \uc5c6\uc744 \uacbd\uc6b0,\nOne-Hot\uc73c\ub85c \ud45c\ud604\ud558\uc5ec \uc11c\ub85c \uc9c1\uad50\ud55c\ub2e4\uace0 \uac00\uc815\ud558\uace0 \ud559\uc2b5\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4.\n\ub3d9\uc77c\ud558\uac8c \uc0c1\uad00 \uad00\uacc4\ub97c \uc54c \uc218 \uc5c6\ub294 \ub2e4\ub978 \ub370\uc774\ud130\uc758 \uacbd\uc6b0\uc5d0\ub3c4 One-Hot \ubca1\ud130\ub97c \ud65c\uc6a9 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n'''\n\nimport torch\n\n# all_letters \ub85c \ubb38\uc790\uc758 \uc8fc\uc18c \ucc3e\uae30, \uc608\uc2dc \"a\" = 0\ndef letterToIndex(letter):\n    return all_letters.find(letter)\n\n# \uac80\uc99d\uc744 \uc704\ud574\uc11c \ud55c\uac1c\uc758 \ubb38\uc790\ub97c <1 x n_letters> Tensor\ub85c \ubcc0\ud658\ndef letterToTensor(letter):\n    tensor = torch.zeros(1, n_letters)\n    tensor[0][letterToIndex(letter)] = 1\n    return tensor\n\n# \ud55c \uc904(\uc774\ub984)\uc744  <line_length x 1 x n_letters>,\n# \ub610\ub294 One-Hot \ubb38\uc790 \ubca1\ud130\uc758 Array\ub85c \ubcc0\uacbd\ndef lineToTensor(line):\n    tensor = torch.zeros(len(line), 1, n_letters)\n    for li, letter in enumerate(line):\n        tensor[li][0][letterToIndex(letter)] = 1\n    return tensor\n\nprint(letterToTensor('J'))\n\nprint(lineToTensor('Jones').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub124\ud2b8\uc6cc\ud06c \uc0dd\uc131\n====================\n\nAutograd \uc804\uc5d0, Torch\uc5d0\uc11c RNN(recurrent neural network) \uc0dd\uc131\uc740\n\uc5ec\ub7ec \uc2dc\uac04 \ub2e8\uacc4 \uac78\ucc98\uc11c \uacc4\uce35\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \ubcf5\uc81c\ud558\ub294 \uc791\uc5c5\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.\n\uacc4\uce35\uc740 \uc740\ub2c9 \uc0c1\ud0dc\uc640 \ubcc0\ud654\ub3c4(Gradient)\ub97c \uac00\uc9c0\uba70, \uc774\uc81c \uc774\uac83\ub4e4\uc740 \uadf8\ub798\ud504 \uc790\uccb4\uc5d0\uc11c\n\uc644\uc804\ud788 \ucc98\ub9ac\ub429\ub2c8\ub2e4. \uc774\ub294 feed-forward \uacc4\uce35\uacfc\n\uac19\uc740 \ub9e4\uc6b0 \"\uc21c\uc218\ud55c\" \ubc29\ubc95\uc73c\ub85c RNN\uc744 \uad6c\ud604\ud560 \uc218 \uc788\ub2e4\ub294 \uac83\uc744 \uc758\ubbf8\ud569\ub2c8\ub2e4.\n\n\uc5ed\uc790 \uc8fc : \uc5ec\uae30\uc11c\ub294 \uad50\uc721\ubaa9\uc801\uc73c\ub85c nn.RNN \ub300\uc2e0 \uc9c1\uc811 RNN\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\uc774 RNN \ubaa8\ub4c8(\ub300\ubd80\ubd84 `Torch \uc0ac\uc6a9\uc790\ub97c \uc704\ud55c PyTorch \ud29c\ud1a0\ub9ac\uc5bc\n<https://tutorials.pytorch.kr/beginner/former_torchies/\nnnft_tutorial.html#example-2-recurrent-net>`__ \uc5d0\uc11c \ubcf5\uc0ac\ud568)\n\uc740 \uc785\ub825 \ubc0f \uc740\ub2c9 \uc0c1\ud0dc\ub85c \uc791\ub3d9\ud558\ub294 2\uac1c\uc758 \uc120\ud615 \uacc4\uce35\uc774\uba70,\n\ucd9c\ub825 \ub2e4\uc74c\uc5d0 LogSoftmax \uacc4\uce35\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\n.. figure:: https://i.imgur.com/Z2xbySO.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, hidden):\n        combined = torch.cat((input, hidden), 1)\n        hidden = self.i2h(combined)\n        output = self.i2o(combined)\n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)\n\nn_hidden = 128\nrnn = RNN(n_letters, n_hidden, n_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ub124\ud2b8\uc6cc\ud06c\uc758 \ud55c \ub2e8\uacc4\ub97c \uc2e4\ud589\ud558\ub824\uba74 \uc785\ub825(\ud604\uc7ac \ubb38\uc790 Tensor)\uacfc\n\uc774\uc804\uc758 \uc740\ub2c9 \uc0c1\ud0dc (\ucc98\uc74c\uc5d0\ub294 0\uc73c\ub85c \ucd08\uae30\ud654)\ub97c \uc804\ub2ec\ud574\uc57c \ud569\ub2c8\ub2e4.\n\ucd9c\ub825(\uac01 \uc5b8\uc5b4\uc758 \ud655\ub960)\uacfc \ub2e4\uc74c \uc740\ub2c9 \uc0c1\ud0dc (\ub2e4\uc74c \ub2e8\uacc4\ub97c \uc704\ud574 \uc720\uc9c0)\ub97c\n\ub3cc\ub824 \ubc1b\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input = letterToTensor('A')\nhidden = torch.zeros(1, n_hidden)\n\noutput, next_hidden = rnn(input, hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud6a8\uc728\uc131\uc744 \uc704\ud574\uc11c \ub9e4 \ub2e8\uacc4\ub9c8\ub2e4 \uc0c8\ub85c\uc6b4 Tensor\ub97c \ub9cc\ub4e4\uace0 \uc2f6\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0\n``letterToTensor`` \ub300\uc2e0 ``lineToTensor`` \ub97c \uc798\ub77c\uc11c \uc0ac\uc6a9\ud560\n\uac83\uc785\ub2c8\ub2e4. \uc774\uac83\uc740 Tensor\uc758 \uc0ac\uc804 \uc5f0\uc0b0(pre-computing) \ubc30\uce58\uc5d0 \uc758\ud574\n\ub354\uc6b1 \ucd5c\uc801\ud654 \ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input = lineToTensor('Albert')\nhidden = torch.zeros(1, n_hidden)\n\noutput, next_hidden = rnn(input[0], hidden)\nprint(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubcf4\uc2dc\ub2e4\uc2dc\ud53c \ucd9c\ub825\uc740 ``<1 x n_categories>`` Tensor\uc774\uace0, \ubaa8\ub4e0 \ud56d\ubaa9\uc740\n\ud574\ub2f9 \uce74\ud14c\uace0\ub9ac\uc758 \uc6b0\ub3c4(likelihood) \uc785\ub2c8\ub2e4 (\ub354 \ub192\uc740 \uac83\uc774 \ub354 \ud655\ub960 \ub192\uc74c).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5\n========\n\ud559\uc2b5 \uc900\ube44\n----------------------\n\n\ud559\uc2b5\uc73c\ub85c \ub4e4\uc5b4\uac00\uae30 \uc804\uc5d0 \uba87\uba87 \ub3c4\uc6c0\ub418\ub294 \ud568\uc218\ub97c \ub9cc\ub4e4\uc5b4\uc57c\ud569\ub2c8\ub2e4.\n\uccab\uc9f8\ub294 \uc6b0\ub9ac\uac00 \uc54c\uc544\ub0b8 \uac01 \uce74\ud14c\uace0\ub9ac\uc758 \uc6b0\ub3c4\uc778 \ub124\ud2b8\uc6cc\ud06c \ucd9c\ub825\uc744 \ud574\uc11d\ud558\ub294 \uac83 \uc785\ub2c8\ub2e4.\n\uac00\uc7a5 \ud070 \uac12\uc758 \uc8fc\uc18c\ub97c \uc54c\uae30 \uc704\ud574\uc11c ``Tensor.topk`` \ub97c \uc0ac\uc6a9 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc5ed\uc790 \uc8fc: \ub124\ud2b8\uc6cc\ud06c \ucd9c\ub825(\uac01 \uce74\ud14c\uace0\ub9ac\uc758 \uc6b0\ub3c4)\uc73c\ub85c\n\uac00\uc7a5 \ud655\ub960\uc774 \ub192\uc740 \uce74\ud14c\uace0\ub9ac \uc774\ub984(\uc5b8\uc5b4)\uacfc \uce74\ud14c\uace0\ub9ac \ubc88\ud638 \ubc18\ud658\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def categoryFromOutput(output):\n    top_n, top_i = output.topk(1) # \ud150\uc11c\uc758 \uac00\uc7a5 \ud070 \uac12 \ubc0f \uc8fc\uc18c\n    category_i = top_i[0].item()     # \ud150\uc11c\uc5d0\uc11c \uc815\uc218 \uac12\uc73c\ub85c \ubcc0\uacbd\n    return all_categories[category_i], category_i\n\nprint(categoryFromOutput(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \uc608\uc2dc(\ud558\ub098\uc758 \uc774\ub984\uacfc \uadf8 \uc5b8\uc5b4)\ub97c \uc5bb\ub294 \ube60\ub978 \ubc29\ubc95\ub3c4 \ud544\uc694\ud569\ub2c8\ub2e4.:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\ndef randomChoice(l):\n    return l[random.randint(0, len(l) - 1)]\n\ndef randomTrainingExample():\n    category = randomChoice(all_categories)\n    line = randomChoice(category_lines[category])\n    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n    line_tensor = lineToTensor(line)\n    return category, line, category_tensor, line_tensor\n\nfor i in range(10):\n    category, line, category_tensor, line_tensor = randomTrainingExample()\n    print('category =', category, '/ line =', line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub124\ud2b8\uc6cc\ud06c \ud559\uc2b5\n--------------------\n\n\uc774\uc81c \uc774 \ub124\ud2b8\uc6cc\ud06c\ub97c \ud559\uc2b5\ud558\ub294\ub370 \ud544\uc694\ud55c \uc608\uc2dc(\ud559\uc2b5 \ub370\uc774\ud130)\ub4e4\uc744 \ubcf4\uc5ec\uc8fc\uace0 \ucd94\uc815\ud569\ub2c8\ub2e4.\n\ub9cc\uc77c \ud2c0\ub838\ub2e4\uba74 \uc54c\ub824 \uc90d\ub2c8\ub2e4.\n\nRNN\uc758 \ub9c8\uc9c0\ub9c9 \uacc4\uce35\uc774 ``nn.LogSoftmax`` \uc774\ubbc0\ub85c \uc190\uc2e4 \ud568\uc218\ub85c\n``nn.NLLLoss`` \uac00 \uc801\ud569\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uac01 \ud559\uc2b5 \ub8e8\ud504\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n-  \uc785\ub825\uacfc \ubaa9\ud45c Tensor \uc0dd\uc131\n-  0 \ub85c \ucd08\uae30\ud654\ub41c \uc740\ub2c9 \uc0c1\ud0dc \uc0dd\uc131\n-  \uac01 \ubb38\uc790\ub97c \uc77d\uae30\n\n   -  \ub2e4\uc74c \ubb38\uc790\ub97c \uc704\ud55c \uc740\ub2c9 \uc0c1\ud0dc \uc720\uc9c0\n\n-  \ubaa9\ud45c\uc640 \ucd5c\uc885 \ucd9c\ub825 \ube44\uad50\n-  \uc5ed\uc804\ud30c\n-  \ucd9c\ub825\uacfc \uc190\uc2e4 \ubc18\ud658\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.005 # \uc774\uac83\uc744 \ub108\ubb34 \ub192\uac8c \uc124\uc815\ud558\uba74 \ubc1c\uc0b0\ud560 \uc218 \uc788\uace0, \ub108\ubb34 \ub0ae\uc73c\uba74 \ud559\uc2b5\uc774 \ub418\uc9c0 \uc54a\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\ndef train(category_tensor, line_tensor):\n    hidden = rnn.initHidden()\n\n    rnn.zero_grad()\n\n    for i in range(line_tensor.size()[0]):\n        output, hidden = rnn(line_tensor[i], hidden)\n\n    loss = criterion(output, category_tensor)\n    loss.backward()\n\n    # \ub9e4\uac1c\ubcc0\uc218\uc758 \uacbd\uc0ac\ub3c4\uc5d0 \ud559\uc2b5\ub960\uc744 \uacf1\ud574\uc11c \uadf8 \ub9e4\uac1c\ubcc0\uc218\uc758 \uac12\uc5d0 \ub354\ud569\ub2c8\ub2e4.\n    for p in rnn.parameters():\n        p.data.add_(p.grad.data, alpha=-learning_rate)\n\n    return output, loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \uc608\uc2dc \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc2e4\ud589\ud574\uc57c\ud569\ub2c8\ub2e4. ``train`` \ud568\uc218\uac00 \ucd9c\ub825\uacfc \uc190\uc2e4\uc744\n\ubc18\ud658\ud558\uae30 \ub54c\ubb38\uc5d0 \ucd94\uce21\uc744 \ud654\uba74\uc5d0 \ucd9c\ub825\ud558\uace0 \ub3c4\uc2dd\ud654\ub97c \uc704\ud55c \uc190\uc2e4\uc744 \ucd94\uc801 \ud560 \uc218\n\uc788\uc2b5\ub2c8\ub2e4. 1000\uac1c\uc758 \uc608\uc2dc \ub370\uc774\ud130\uac00 \uc788\uae30 \ub54c\ubb38\uc5d0 ``print_every`` \uc608\uc81c\ub9cc\n\ucd9c\ub825\ud558\uace0, \uc190\uc2e4\uc758 \ud3c9\uade0\uc744 \uc5bb\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\nn_iters = 100000\nprint_every = 5000\nplot_every = 1000\n\n\n\n# \ub3c4\uc2dd\ud654\ub97c \uc704\ud55c \uc190\uc2e4 \ucd94\uc801\ncurrent_loss = 0\nall_losses = []\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\nstart = time.time()\n\nfor iter in range(1, n_iters + 1):\n    category, line, category_tensor, line_tensor = randomTrainingExample()\n    output, loss = train(category_tensor, line_tensor)\n    current_loss += loss\n\n    # iter \uc22b\uc790, \uc190\uc2e4, \uc774\ub984, \ucd94\uce21 \ud654\uba74 \ucd9c\ub825\n    if iter % print_every == 0:\n        guess, guess_i = categoryFromOutput(output)\n        correct = '\u2713' if guess == category else '\u2717 (%s)' % category\n        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n\n    # \ud604\uc7ac \ud3c9\uade0 \uc190\uc2e4\uc744 \uc804\uccb4 \uc190\uc2e4 \ub9ac\uc2a4\ud2b8\uc5d0 \ucd94\uac00\n    if iter % plot_every == 0:\n        all_losses.append(current_loss / plot_every)\n        current_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacb0\uacfc \ub3c4\uc2dd\ud654\n--------------------\n\n``all_losses`` \ub97c \uc774\uc6a9\ud55c \uc190\uc2e4 \ub3c4\uc2dd\ud654\ub294\n\ub124\ud2b8\uc6cc\ud06c\uc758 \ud559\uc2b5\uc744 \ubcf4\uc5ec\uc900\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nplt.figure()\nplt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uacb0\uacfc \ud3c9\uac00\n======================\n\n\ub124\ud2b8\uc6cc\ud06c\uac00 \ub2e4\ub978 \uce74\ud14c\uace0\ub9ac\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uc798 \uc791\ub3d9\ud558\ub294\uc9c0 \ubcf4\uae30\uc704\ud574\n\ubaa8\ub4e0 \uc2e4\uc81c \uc5b8\uc5b4(\ud589)\uac00 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c \uc5b4\ub5a4 \uc5b8\uc5b4\ub85c \ucd94\uce21(\uc5f4)\ub418\ub294\uc9c0\ub97c \ub098\ud0c0\ub0b4\ub294\n\ud63c\ub780 \ud589\ub82c(confusion matrix)\uc744 \ub9cc\ub4ed\ub2c8\ub2e4. \ud63c\ub780 \ud589\ub82c\uc744 \uacc4\uc0b0\ud558\uae30 \uc704\ud574\n``evaluate()`` \ub85c \ub9ce\uc740 \uc218\uc758 \uc0d8\ud50c\uc744 \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc2e4\ud589\ud569\ub2c8\ub2e4.\n``evaluate()`` \uc740 ``train ()`` \uacfc \uc5ed\uc804\ud30c\ub97c \ube7c\uba74 \ub3d9\uc77c\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud63c\ub780 \ud589\ub82c\uc5d0\uc11c \uc815\ud655\ud55c \ucd94\uce21\uc744 \ucd94\uc801\nconfusion = torch.zeros(n_categories, n_categories)\nn_confusion = 10000\n\n# \uc8fc\uc5b4\uc9c4 \ub77c\uc778\uc758 \ucd9c\ub825 \ubc18\ud658\ndef evaluate(line_tensor):\n    hidden = rnn.initHidden()\n\n    for i in range(line_tensor.size()[0]):\n        output, hidden = rnn(line_tensor[i], hidden)\n\n    return output\n\n# \uc608\uc2dc\ub4e4 \uc911\uc5d0 \uc5b4\ub5a4 \uac83\uc774 \uc815\ud655\ud558\uac8c \uc608\uce21\ub418\uc5c8\ub294\uc9c0 \uae30\ub85d\nfor i in range(n_confusion):\n    category, line, category_tensor, line_tensor = randomTrainingExample()\n    output = evaluate(line_tensor)\n    guess, guess_i = categoryFromOutput(output)\n    category_i = all_categories.index(category)\n    confusion[category_i][guess_i] += 1\n\n# \ubaa8\ub4e0 \ud589\uc744 \ud569\uacc4\ub85c \ub098\ub204\uc5b4 \uc815\uaddc\ud654\nfor i in range(n_categories):\n    confusion[i] = confusion[i] / confusion[i].sum()\n\n# \ub3c4\uc2dd \uc124\uc815\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(confusion.numpy())\nfig.colorbar(cax)\n\n# \ucd95 \uc124\uc815\nax.set_xticklabels([''] + all_categories, rotation=90)\nax.set_yticklabels([''] + all_categories)\n\n# \ubaa8\ub4e0 tick\uc5d0\uc11c \ub808\uc774\ube14 \uc9c0\uc815\nax.xaxis.set_major_locator(ticker.MultipleLocator(1))\nax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n# sphinx_gallery_thumbnail_number = 2\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc8fc\ucd95\uc5d0\uc11c \ubc97\uc5b4\ub09c \ubc1d\uc740 \uc810\uc744 \uc120\ud0dd\ud558\uc5ec \uc798\ubabb \ucd94\uce21\ud55c \uc5b8\uc5b4\ub97c \ud45c\uc2dc\n\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 \ud55c\uad6d\uc5b4\ub294 \uc911\uad6d\uc5b4\ub85c \uc774\ud0c8\ub9ac\uc544\uc5b4\ub85c \uc2a4\ud398\uc778\uc5b4\ub85c.\n\uadf8\ub9ac\uc2a4\uc5b4\ub294 \ub9e4\uc6b0 \uc798\ub418\ub294 \uac83\uc73c\ub85c \uc601\uc5b4\ub294 \ub9e4\uc6b0 \ub098\uc05c\uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4.\n(\ub2e4\ub978 \uc5b8\uc5b4\ub4e4\uacfc \uc911\ucca9 \ub54c\ubb38\uc73c\ub85c \ucd94\uc815)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc0ac\uc6a9\uc790 \uc785\ub825\uc73c\ub85c \uc2e4\ud589\n---------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def predict(input_line, n_predictions=3):\n    print('\\n> %s' % input_line)\n    with torch.no_grad():\n        output = evaluate(lineToTensor(input_line))\n\n        # Get top N categories\n        topv, topi = output.topk(n_predictions, 1, True)\n        predictions = []\n\n        for i in range(n_predictions):\n            value = topv[0][i].item()\n            category_index = topi[0][i].item()\n            print('(%.2f) %s' % (value, all_categories[category_index]))\n            predictions.append([value, all_categories[category_index]])\n\npredict('Dovesky')\npredict('Jackson')\npredict('Satoshi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`\uc2e4\uc6a9 PyTorch \uc800\uc7a5\uc18c\n<https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification>`__\n\uc758 \ucd5c\uc885 \ubc84\uc804 \uc2a4\ud06c\ub9bd\ud2b8\ub294 \uc704 \ucf54\ub4dc\ub97c \uba87\uac1c\uc758 \ud30c\uc77c\ub85c \ubd84\ud560\ud588\uc2b5\ub2c8\ub2e4.:\n\n-  ``data.py`` (\ud30c\uc77c \uc77d\uae30)\n-  ``model.py`` (RNN \uc815\uc758)\n-  ``train.py`` (\ud559\uc2b5 \uc2e4\ud589)\n-  ``predict.py`` (\ucee4\uba58\ub4dc \ub77c\uc778 \uc778\uc790\ub85c ``predict()`` \uc2e4\ud589)\n-  ``server.py`` (bottle.py\ub97c \uc0ac\uc6a9\ud558\uc5ec JSON API\ub85c \uc608\uce21 \uc81c\uacf5)\n\n\ud559\uc2b5\uacfc \ub124\ud2b8\uc6cc\ud06c \uc800\uc7a5\uc744 \uc704\ud574 ``train.py`` \uc2e4\ud589.\n\n\uc774\ub984\uc73c\ub85c \uc608\uce21\uc744 \ubcf4\uae30 \uc704\ud574 ``predict.py`` \uc2e4\ud589:\n\n::\n\n    $ python predict.py Hazaki\n    (-0.42) Japanese\n    (-1.39) Polish\n    (-3.51) Czech\n\n``server.py`` \ub97c \uc2e4\ud589\ud558\uace0 \uc608\uce21\uc758 JSON \ucd9c\ub825\uc744 \uc5bb\uae30 \uc704\ud574\nhttp://localhost:5533/Yourname \ubc29\ubb38.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc5f0\uc2b5\n=========\n\n-  \"line -> category\" \uc758 \ub2e4\ub978 \ub370\uc774\ud130 \uc9d1\ud569\uc73c\ub85c \uc2dc\ub3c4\ud574\ubcf4\uc2ed\uc2dc\uc624, \uc608\ub97c \ub4e4\uc5b4:\n\n   -  \ub2e8\uc5b4 -> \uc5b8\uc5b4\n   -  \uc774\ub984 -> \uc131\ubcc4\n   -  \uce90\ub9ad\ud130 \uc774\ub984 -> \uc791\uac00\n   -  \ud398\uc774\uc9c0 \uc81c\ubaa9 -> \ube14\ub85c\uadf8 \ub610\ub294 \uc11c\ube0c\ub808\ub527\n\n-  \ub354 \ud06c\uace0 \ub354 \ub098\uc740 \ubaa8\uc591\uc758 \ub124\ud2b8\uc6cc\ud06c\ub85c \ub354 \ub098\uc740 \uacb0\uacfc\ub97c \uc5bb\uc73c\uc2ed\uc2dc\uc624.\n\n   -  \ub354\ub9ce\uc740 \uc120\ud615 \uacc4\uce35\uc744 \ucd94\uac00\ud574 \ubcf4\uc2ed\uc2dc\uc624\n   -  ``nn.LSTM`` \uacfc ``nn.GRU`` \uacc4\uce35\uc744 \ucd94\uac00\ud574 \ubcf4\uc2ed\uc2dc\uc624\n   -  \uc5ec\ub7ec \uac1c\uc758 \uc774\ub7f0 RNN\uc744 \uc0c1\uc704 \uc218\uc900 \ub124\ud2b8\uc6cc\ud06c\ub85c \uacb0\ud569\ud574 \ubcf4\uc2ed\uc2dc\uc624\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}