{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nPyTorch\uc5d0\uc11c state_dict\ub780 \ubb34\uc5c7\uc778\uac00\uc694?\n======================================\nPyTorch\uc5d0\uc11c ``torch.nn.Module`` \ubaa8\ub378\uc758 \ud559\uc2b5 \uac00\ub2a5\ud55c\n\ub9e4\uac1c\ubcc0\uc218(\uc608. \uac00\uc911\uce58\uc640 \ud3b8\ud5a5)\ub4e4\uc740 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n(model.parameters()\ub85c \uc811\uadfc\ud569\ub2c8\ub2e4)\n``state_dict`` \ub294 \uac04\ub2e8\ud788 \ub9d0\ud574 \uac01 \uacc4\uce35\uc744 \ub9e4\uac1c\ubcc0\uc218 \ud150\uc11c\ub85c \ub9e4\ud551\ub418\ub294\nPython \uc0ac\uc804(dict) \uac1d\uccb4\uc785\ub2c8\ub2e4.\n\n\uac1c\uc694\n------------\n``state_dict`` \ub294 PyTorch\uc5d0\uc11c \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\uac70\ub098 \ubd88\ub7ec\uc624\ub294 \ub370 \uad00\uc2ec\uc774\n\uc788\ub2e4\uba74 \ud544\uc218\uc801\uc778 \ud56d\ubaa9\uc785\ub2c8\ub2e4.\n``state_dict`` \uac1d\uccb4\ub294 Python \uc0ac\uc804\uc774\uae30 \ub54c\ubb38\uc5d0 \uc27d\uac8c \uc800\uc7a5, \uc5c5\ub370\uc774\ud2b8,\n\ubcc0\uacbd \ubc0f \ubcf5\uc6d0\ud560 \uc218 \uc788\uc73c\uba70, \uc774\ub294 PyTorch \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\uc5d0 \uc5c4\uccad\ub09c\n\ubaa8\ub4c8\uc131(modularity)\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\uc774 \ub54c, \ud559\uc2b5 \uac00\ub2a5\ud55c \ub9e4\uac1c\ubcc0\uc218\ub97c \uac16\ub294 \uacc4\uce35(\ud569\uc131\uacf1 \uacc4\uce35, \uc120\ud615 \uacc4\uce35 \ub4f1)\n\ubc0f \ub4f1\ub85d\ub41c \ubc84\ud37c\ub4e4(batchnorm\uc758 running_mean)\ub9cc \ubaa8\ub378\uc758 ``state_dict``\n \ud56d\ubaa9\uc744 \uac00\uc9c4\ub2e4\ub294 \uc810\uc5d0 \uc720\uc758\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4. \uc635\ud2f0\ub9c8\uc774\uc800 \uac1d\uccb4\n( ``torch.optim`` ) \ub610\ud55c \uc635\ud2f0\ub9c8\uc774\uc800\uc758 \uc0c1\ud0dc \ubfd0\ub9cc \uc544\ub2c8\ub77c \uc0ac\uc6a9\ub41c\n\ud558\uc774\ud37c \ub9e4\uac1c\ubcc0\uc218 (Hyperparameter) \uc815\ubcf4\uac00 \ud3ec\ud568\ub41c ``state_dict`` \uc744\n\uac16\uc2b5\ub2c8\ub2e4.\n\ub808\uc2dc\ud53c\uc5d0\uc11c ``state_dict`` \uc774 \uac04\ub2e8\ud55c \ubaa8\ub378\uc5d0\uc11c \uc5b4\ub5bb\uac8c \uc0ac\uc6a9\ub418\ub294\uc9c0\n\uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc124\uc815\n----------\n\uc2dc\uc791\ud558\uae30 \uc804\uc5d0 ``torch`` \uac00 \uc5c6\ub2e4\uba74 \uc124\uce58\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n::\n\n   pip install torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e8\uacc4(Steps)\n--------------\n\n1. \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc62c \ub54c \ud544\uc694\ud55c \ubaa8\ub4e0 \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30\n2. \uc2e0\uacbd\ub9dd\uc744 \uad6c\uc131\ud558\uace0 \ucd08\uae30\ud654\ud558\uae30\n3. \uc635\ud2f0\ub9c8\uc774\uc800 \ucd08\uae30\ud654\ud558\uae30\n4. \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\uc758 ``state_dict`` \uc811\uadfc\ud558\uae30\n\n1. \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc62c \ub54c \ud544\uc694\ud55c \ubaa8\ub4e0 \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uc774 \ub808\uc2dc\ud53c\uc5d0\uc11c\ub294 ``torch`` \uc640 \ud558\uc704 \ud328\ud0a4\uc9c0\uc778 ``torch.nn`` \uacfc ``torch.optim`` \uc744\n\uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. \uc2e0\uacbd\ub9dd\uc744 \uad6c\uc131\ud558\uace0 \ucd08\uae30\ud654\ud558\uae30\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uc608\uc2dc\ub97c \ubcf4\uc774\uae30 \uc704\ud574, \uc774\ubbf8\uc9c0\ub97c \ud559\uc2b5\ud558\ub294 \uc2e0\uacbd\ub9dd\uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc2e0\uacbd\ub9dd \uad6c\uc131\ud558\uae30 \ub808\uc2dc\ud53c\ub97c \ucc38\uace0\ud574\uc8fc\uc138\uc694.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nprint(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. \uc635\ud2f0\ub9c8\uc774\uc800 \ucd08\uae30\ud654\ud558\uae30\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\ubaa8\uba58\ud140(momentum)\uc744 \uac16\ub294 SGD\ub97c \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\uc758 ``state_dict`` \uc811\uadfc\ud558\uae30\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\uc774\uc81c \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uad6c\uc131\ud588\uc73c\ubbc0\ub85c \uac01\uac01\uc758 ``state_dict`` \uc18d\uc131\uc5d0\n\uc800\uc7a5\ub418\uc5b4 \uc788\ub294 \ud56d\ubaa9\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ubaa8\ub378\uc758 state_dict \ucd9c\ub825\nprint(\"Model's state_dict:\")\nfor param_tensor in net.state_dict():\n    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n\nprint()\n\n# \uc635\ud2f0\ub9c8\uc774\uc800\uc758 state_dict \ucd9c\ub825\nprint(\"Optimizer's state_dict:\")\nfor var_name in optimizer.state_dict():\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \uc815\ubcf4\ub294 \ud5a5\ud6c4 \ubaa8\ub378 \ubc0f \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uc800\uc7a5\ud558\uace0\n\ubd88\ub7ec\uc624\ub294 \uac83\uacfc \uad00\ub828\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ucd95\ud558\ud569\ub2c8\ub2e4! PyTorch\uc5d0\uc11c ``state_dict`` \uc744 \uc131\uacf5\uc801\uc73c\ub85c \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n\ub354 \uc54c\uc544\ubcf4\uae30\n-------------\n\n\ub2e4\ub978 \ub808\uc2dc\ud53c\ub97c \ub458\ub7ec\ubcf4\uace0 \uacc4\uc18d \ubc30\uc6cc\ubcf4\uc138\uc694:\n\n- :doc:`/recipes/recipes/saving_and_loading_models_for_inference`\n- :doc:`/recipes/recipes/saving_and_loading_a_general_checkpoint`\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}