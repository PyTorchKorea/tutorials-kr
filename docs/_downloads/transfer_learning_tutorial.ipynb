{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\uc804\uc774\ud559\uc2b5(Transfer Learning) \ud29c\ud1a0\ub9ac\uc5bc\n====================================\n**Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`_\n  **\ubc88\uc5ed**: `\ubc15\uc815\ud658 <http://github.com/9bow>`_\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \uc804\uc774\ud559\uc2b5(Transfer Learning)\uc744 \uc774\uc6a9\ud558\uc5ec \uc2e0\uacbd\ub9dd\uc744 \uc5b4\ub5bb\uac8c \ud559\uc2b5\uc2dc\ud0a4\ub294\uc9c0\n\ubc30\uc6cc\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc804\uc774\ud559\uc2b5\uc5d0 \ub300\ud574\uc11c \ub354 \uc54c\uc544\ubcf4\uc2dc\ub824\uba74\n`CS231n \ub178\ud2b8 <http://cs231n.github.io/transfer-learning/>`__ \ub97c \uc77d\uc5b4\ubcf4\uc2dc\uba74 \uc88b\uc2b5\ub2c8\ub2e4.\n\n\uc704 \ub178\ud2b8\ub97c \uc778\uc6a9\ud574\ubcf4\uba74,\n\n    \uc2e4\uc81c\ub85c \ucda9\ubd84\ud55c \ud06c\uae30\uc758 \ub370\uc774\ud130\uc14b\uc744 \uac16\ucd94\uae30\ub294 \uc0c1\ub300\uc801\uc73c\ub85c \ub4dc\ubb3c\uae30 \ub54c\ubb38\uc5d0,\n    (\ubb34\uc791\uc704 \ucd08\uae30\ud654\ub97c \ud1b5\ud574) \ubc14\ub2e5\ubd80\ud130(from scratch) \uc804\uccb4 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd(Convolutional\n    Network)\ub97c \ud559\uc2b5\ud558\ub294 \uc0ac\ub78c\uc740 \uac70\uc758 \uc5c6\uc2b5\ub2c8\ub2e4. \ub300\uc2e0, \ub9e4\uc6b0 \ud070 \ub370\uc774\ud130\uc14b(\uc608.\n    100\uac00\uc9c0 \ubd84\ub958(Category)\uc5d0 \ub300\ud574 120\ub9cc\uac1c\uc758 \uc774\ubbf8\uc9c0\uac00 \ud3ec\ud568\ub41c ImageNet)\uc5d0\uc11c \ud569\uc131\uacf1\n    \uc2e0\uacbd\ub9dd(ConvNet)\uc744 \ubbf8\ub9ac \ud559\uc2b5(Pretrain)\ud55c \ud6c4, \uc774 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\uc744 \uad00\uc2ec\uc788\ub294 \uc791\uc5c5\n    (task of interest)\uc744 \uc704\ud55c \ucd08\uae30\ud654(initialization) \ub610\ub294 \uace0\uc815 \ud2b9\uc9d5 \ucd94\ucd9c\uae30(fixed\n    feature extractor)\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\uc774\ub7ec\ud55c 2\uac00\uc9c0\uc758 \uc8fc\uc694\ud55c \uc804\uc774\ud559\uc2b5 \uc2dc\ub098\ub9ac\uc624\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n\n-  **\ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\uc758 \ubbf8\uc138\uc870\uc815(Finetuning)**: \ubb34\uc791\uc704 \ucd08\uae30\ud654 \ub300\uc2e0, \uc2e0\uacbd\ub9dd\uc744\n   ImageNet 1000 \ub370\uc774\ud130\uc14b \ub4f1\uc73c\ub85c \ubbf8\ub9ac \ud559\uc2b5\ud55c \uc2e0\uacbd\ub9dd\uc73c\ub85c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4. \ud559\uc2b5\uc758 \ub098\uba38\uc9c0\n   \uacfc\uc815\ub4e4\uc740 \ud3c9\uc0c1\uc2dc\uc640 \uac19\uc2b5\ub2c8\ub2e4.\n-  **\uace0\uc815 \ud2b9\uc815 \ucd94\ucd9c\uae30\ub85c\uc368\uc758 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd**: \uc5ec\uae30\uc11c\ub294 \ub9c8\uc9c0\ub9c9\uc758 \uc644\uc804\ud788 \uc5f0\uacb0\n   (Fully-connected)\ub41c \uacc4\uce35\uc744 \uc81c\uc678\ud55c \ubaa8\ub4e0 \uc2e0\uacbd\ub9dd\uc758 \uac00\uc911\uce58\ub97c \uace0\uc815\ud569\ub2c8\ub2e4. \uc774\n   \ub9c8\uc9c0\ub9c9\uc758 \uc644\uc804\ud788 \uc5f0\uacb0\ub41c \uacc4\uce35\uc740 \uc0c8\ub85c\uc6b4 \ubb34\uc791\uc704\uc758 \uac00\uc911\uce58\ub97c \uac16\ub294 \uacc4\uce35\uc73c\ub85c \ub300\uccb4\ub418\uc5b4\n   \uc774 \uacc4\uce35\ub9cc \ud559\uc2b5\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\n---------------\n\n\ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc624\uae30 \uc704\ud574 torchvision\uacfc torch.utils.data \ud328\ud0a4\uc9c0\ub97c \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\uc624\ub298 \ud480\uace0\uc790 \ud558\ub294 \ubb38\uc81c\ub294 **\uac1c\ubbf8** \uc640 **\ubc8c** \uc744 \ubd84\ub958\ud558\ub294 \ubaa8\ub378\uc744 \ud559\uc2b5\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\uac01\uac01\uc758 \ubd84\ub958\uc5d0\ub294 75\uac1c\uc758 \uac80\uc99d\uc6a9 \uc774\ubbf8\uc9c0(validation image)\uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c,\n\ub9cc\uc57d \ubc14\ub2e5\ubd80\ud130 \ud559\uc2b5\uc744 \ud55c\ub2e4\uba74, \uc774\ub294 \uc77c\ubc18\ud654\ud558\uae30\uc5d0\ub294 \uc544\uc8fc \uc791\uc740 \ub370\uc774\ud130\uc14b\uc785\ub2c8\ub2e4.\n\ud558\uc9c0\ub9cc \uc804\uc774\ud559\uc2b5\uc744 \uc0ac\uc6a9\ud560 \uac83\uc774\ubbc0\ub85c, \ud569\ub9ac\uc801\uc73c\ub85c \uc798 \uc77c\ubc18\ud654\ud574 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ub370\uc774\ud130\uc14b\uc740 ImageNet\uc758 \uc544\uc8fc \uc791\uc740 \ubd80\ubd84(Subset)\uc785\ub2c8\ub2e4.\n\n.. Note ::\n   \ub370\uc774\ud130\ub97c `\uc5ec\uae30 <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_\n   \uc5d0\uc11c \ub2e4\uc6b4\ub85c\ub4dc \ubc1b\uc544 \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc555\ucd95\uc744 \ud478\uc2ed\uc2dc\uc624.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud559\uc2b5\uc744 \uc704\ud55c \ub370\uc774\ud130 \uc99d\uac00(Augmentation)\uc640 \uc77c\ubc18\ud654\ud558\uae30\n# \ub2e8\uc9c0 \uac80\uc99d\uc744 \uc704\ud55c \uc77c\ubc18\ud654\ud558\uae30\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'hymenoptera_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc77c\ubd80 \uc774\ubbf8\uc9c0 \uc2dc\uac01\ud654\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\ub370\uc774\ud130 \uc99d\uac00\ub97c \uc774\ud574\ud558\uae30 \uc704\ud574 \uc77c\ubd80 \ud559\uc2b5\uc6a9 \uc774\ubbf8\uc9c0\ub97c \uc2dc\uac01\ud654\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \ud559\uc2b5\ud558\uae30\n--------------\n\n\uc774\uc81c \ubaa8\ub378\uc744 \ud559\uc2b5\ud558\uae30 \uc704\ud55c \uc77c\ubc18 \ud568\uc218\ub97c \uc791\uc131\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uc11c\ub294 \ub2e4\uc74c \ub0b4\uc6a9\ub4e4\uc744\n\uc124\uba85\ud569\ub2c8\ub2e4:\n\n-  Learning Rate \uad00\ub9ac(Scheduling)\n-  \ucd5c\uc801\uc758 \ubaa8\ub378 \uad6c\ud558\uae30\n\n\uc544\ub798\uc5d0\uc11c ``scheduler`` \ub9e4\uac1c\ubcc0\uc218\ub294 ``torch.optim.lr_scheduler`` \uc758 LR Scheduler\n\uac1d\uccb4(Object)\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc608\uce21\uac12 \uc2dc\uac01\ud654\ud558\uae30\n^^^^^^^^^^^^^^^^^^^^^^^\n\n\uc77c\ubd80 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud55c \uc608\uce21\uac12\uc744 \ubcf4\uc5ec\uc8fc\ub294 \uc77c\ubc18\ud654\ub41c(Generic) \ud568\uc218\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd \ubbf8\uc138\uc870\uc815(Finetuning)\n----------------------------------\n\n\ubbf8\ub9ac \ud559\uc2b5\ud55c \ubaa8\ub378\uc744 \ubd88\ub7ec\uc628 \ud6c4 \ub9c8\uc9c0\ub9c9\uc758 \uc644\uc804\ud788 \uc5f0\uacb0\ub41c \uacc4\uce35\uc744 \uc7ac\uc124\uc815(reset)\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ubc0f \ud3c9\uac00\ud558\uae30\n^^^^^^^^^^^^^^^^^^\n\nCPU\uc5d0\uc11c 15-25\ubd84 \uac00\ub7c9 \uc18c\uc694\ub420 \uac83\uc785\ub2c8\ub2e4. \uadf8\ub798\ub3c4 GPU\uc5d0\uc11c\ub294 1\ubd84\ub3c4 \uac78\ub9ac\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uace0\uc815 \ud2b9\uc815 \ucd94\ucd9c\uae30\ub85c\uc368\uc758 \ud569\uc131\uacf1 \uc2e0\uacbd\ub9dd\n-------------------------------------\n\n\uc774\uc81c, \ub9c8\uc9c0\ub9c9 \uacc4\uce35\uc744 \uc81c\uc678\ud55c \ubaa8\ub4e0 \uc2e0\uacbd\ub9dd\uc744 \uace0\uc815(freeze)\ud560 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n``requires_grad == False`` \ub97c \uc124\uc815\ud558\uc5ec \ub9e4\uac1c\ubcc0\uc218\ub97c \uace0\uc815\ud558\uc5ec ``backward()`` \uc5d0\uc11c\n\uacbd\uc0ac\ub3c4(gradient)\uac00 \uacc4\uc0b0\ub418\uc9c0 \uc54a\ub3c4\ub85d \ud574\uc57c\ud569\ub2c8\ub2e4.\n\n\uc774 \ubd80\ubd84\uc5d0 \ub300\ud55c \ubb38\uc11c\ub294\n`\uc5ec\uae30 <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__\n\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opoosed to before.\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ubc0f \ud3c9\uac00\ud558\uae30\n^^^^^^^^^^^^^^^^^\n\nCPU\uc5d0\uc11c \uc2e4\ud589\ud558\ub294 \uacbd\uc6b0 \uc774\uc804 \uc2dc\ub098\ub9ac\uc624\uc640 \ube44\uad50\ud588\uc744 \ub54c \uc57d \uc808\ubc18 \uac00\ub7c9\uc758 \uc2dc\uac04\uc774 \uc18c\uc694\ub429\ub2c8\ub2e4.\n\uc774\ub294 \ub300\ubd80\ubd84\uc758 \uc2e0\uacbd\ub9dd\uc5d0\uc11c \uacbd\uc0ac\ub3c4\ub97c \uacc4\uc0b0\ud560 \ud544\uc694\uac00 \uc5c6\uc744 \uac83\uc73c\ub85c \uae30\ub300\ud569\ub2c8\ub2e4. \ud558\uc9c0\ub9cc,\n\uc21c\uc804\ud30c(forward)\ub294 \uacc4\uc0b0\ud574\uc57c \ud560 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_conv)\n\nplt.ioff()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}