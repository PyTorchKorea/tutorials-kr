{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n[\ud30c\uc774\ud1a0\uce58(PyTorch) \uae30\ubcf8 \uc775\ud788\uae30](intro.html) ||\n[\ube60\ub978 \uc2dc\uc791](quickstart_tutorial.html) ||\n[\ud150\uc11c(Tensor)](tensorqs_tutorial.html) ||\n[Dataset\uacfc Dataloader](data_tutorial.html) ||\n[\ubcc0\ud615(Transform)](transforms_tutorial.html) ||\n[\uc2e0\uacbd\ub9dd \ubaa8\ub378 \uad6c\uc131\ud558\uae30](buildmodel_tutorial.html) ||\n**Autograd** ||\n[\ucd5c\uc801\ud654(Optimization)](optimization_tutorial.html) ||\n[\ubaa8\ub378 \uc800\uc7a5\ud558\uace0 \ubd88\ub7ec\uc624\uae30](saveloadrun_tutorial.html)\n\n# ``torch.autograd``\\ \ub97c \uc0ac\uc6a9\ud55c \uc790\ub3d9 \ubbf8\ubd84\n\n\uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\ud560 \ub54c \uac00\uc7a5 \uc790\uc8fc \uc0ac\uc6a9\ub418\ub294 \uc54c\uace0\ub9ac\uc998\uc740 **\uc5ed\uc804\ud30c**\\ \uc785\ub2c8\ub2e4. \uc774 \uc54c\uace0\ub9ac\uc998\uc5d0\uc11c,\n\ub9e4\uac1c\ubcc0\uc218(\ubaa8\ub378 \uac00\uc911\uce58)\ub294 \uc8fc\uc5b4\uc9c4 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub300\ud55c \uc190\uc2e4 \ud568\uc218\uc758 **\ubcc0\ud654\ub3c4(gradient)**\\ \uc5d0\n\ub530\ub77c \uc870\uc815\ub429\ub2c8\ub2e4.\n\n\uc774\ub7ec\ud55c \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574 PyTorch\uc5d0\ub294 ``torch.autograd``\\ \ub77c\uace0 \ubd88\ub9ac\ub294 \uc790\ub3d9 \ubbf8\ubd84 \uc5d4\uc9c4\uc774\n\ub0b4\uc7a5\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubaa8\ub4e0 \uacc4\uc0b0 \uadf8\ub798\ud504\uc5d0 \ub300\ud55c \ubcc0\ud654\ub3c4\uc758 \uc790\ub3d9 \uacc4\uc0b0\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.\n\n\uc785\ub825 ``x``, \ub9e4\uac1c\ubcc0\uc218 ``w``\\ \uc640 ``b`` , \uadf8\ub9ac\uace0 \uc77c\ubd80 \uc190\uc2e4 \ud568\uc218\uac00 \uc788\ub294 \uac00\uc7a5 \uac04\ub2e8\ud55c \ub2e8\uc77c \uacc4\uce35\n\uc2e0\uacbd\ub9dd\uc744 \uac00\uc815\ud558\uaca0\uc2b5\ub2c8\ub2e4. PyTorch\uc5d0\uc11c\ub294 \ub2e4\uc74c\uacfc \uac19\uc774 \uc815\uc758\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nx = torch.ones(5)  # input tensor\ny = torch.zeros(3)  # expected output\nw = torch.randn(5, 3, requires_grad=True)\nb = torch.randn(3, requires_grad=True)\nz = torch.matmul(x, w)+b\nloss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensor, Function\uacfc \uc5f0\uc0b0\uadf8\ub798\ud504(Computational graph)\n\n\uc774 \ucf54\ub4dc\ub294 \ub2e4\uc74c\uc758 **\uc5f0\uc0b0 \uadf8\ub798\ud504** \ub97c \uc815\uc758\ud569\ub2c8\ub2e4:\n\n.. figure:: /_static/img/basics/comp-graph.png\n   :alt:\n\n\uc774 \uc2e0\uacbd\ub9dd\uc5d0\uc11c, ``w``\\ \uc640 ``b``\\ \ub294 \ucd5c\uc801\ud654\ub97c \ud574\uc57c \ud558\ub294 **\ub9e4\uac1c\ubcc0\uc218**\\ \uc785\ub2c8\ub2e4. \ub530\ub77c\uc11c\n\uc774\ub7ec\ud55c \ubcc0\uc218\ub4e4\uc5d0 \ub300\ud55c \uc190\uc2e4 \ud568\uc218\uc758 \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud560 \uc218 \uc788\uc5b4\uc57c \ud569\ub2c8\ub2e4. \uc774\ub97c \uc704\ud574\uc11c \ud574\ub2f9 \ud150\uc11c\uc5d0\n``requires_grad`` \uc18d\uc131\uc744 \uc124\uc815\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``requires_grad``\\ \uc758 \uac12\uc740 \ud150\uc11c\ub97c \uc0dd\uc131\ud560 \ub54c \uc124\uc815\ud558\uac70\ub098, \ub098\uc911\uc5d0\n          ``x.requires_grad_(True)`` \uba54\uc18c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub098\uc911\uc5d0 \uc124\uc815\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc5f0\uc0b0 \uadf8\ub798\ud504\ub97c \uad6c\uc131\ud558\uae30 \uc704\ud574 \ud150\uc11c\uc5d0 \uc801\uc6a9\ud558\ub294 \ud568\uc218\ub294 \uc0ac\uc2e4 ``Function`` \ud074\ub798\uc2a4\uc758 \uac1d\uccb4\uc785\ub2c8\ub2e4.\n\uc774 \uac1d\uccb4\ub294 *\uc21c\uc804\ud30c* \ubc29\ud5a5\uc73c\ub85c \ud568\uc218\ub97c \uacc4\uc0b0\ud558\ub294 \ubc29\ubc95\uacfc, *\uc5ed\ubc29\ud5a5 \uc804\ud30c* \ub2e8\uacc4\uc5d0\uc11c \ub3c4\ud568\uc218(derivative)\ub97c\n\uacc4\uc0b0\ud558\ub294 \ubc29\ubc95\uc744 \uc54c\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc5ed\ubc29\ud5a5 \uc804\ud30c \ud568\uc218\uc5d0 \ub300\ud55c \ucc38\uc870(reference)\ub294 \ud150\uc11c\uc758 ``grad_fn``\n\uc18d\uc131\uc5d0 \uc800\uc7a5\ub429\ub2c8\ub2e4. ``Function``\\ \uc5d0 \ub300\ud55c \uc790\uc138\ud55c \uc815\ubcf4\ub294\n[\uc774 \ubb38\uc11c](https://pytorch.org/docs/stable/autograd.html#function)_\n\uc5d0\uc11c \ucc3e\uc544\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\nprint(f\"Gradient function for loss = {loss.grad_fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ubcc0\ud654\ub3c4(Gradient) \uacc4\uc0b0\ud558\uae30\n\n\uc2e0\uacbd\ub9dd\uc5d0\uc11c \ub9e4\uac1c\ubcc0\uc218\uc758 \uac00\uc911\uce58\ub97c \ucd5c\uc801\ud654\ud558\ub824\uba74 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ub300\ud55c \uc190\uc2e4\ud568\uc218\uc758 \ub3c4\ud568\uc218(derivative)\ub97c\n\uacc4\uc0b0\ud574\uc57c \ud569\ub2c8\ub2e4. \uc989, ``x``\\ \uc640 ``y``\\ \uc758 \uc77c\ubd80 \uace0\uc815\uac12\uc5d0\uc11c $\\frac{\\partial loss}{\\partial w}$\\ \uc640\n$\\frac{\\partial loss}{\\partial b}$ \uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n\uc774\ub7ec\ud55c \ub3c4\ud568\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574, ``loss.backward()`` \ub97c \ud638\ucd9c\ud55c \ub2e4\uc74c ``w.grad``\\ \uc640\n``b.grad``\\ \uc5d0\uc11c \uac12\uc744 \uac00\uc838\uc635\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss.backward()\nprint(w.grad)\nprint(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>- \uc5f0\uc0b0 \uadf8\ub798\ud504\uc758 \uc78e(leaf) \ub178\ub4dc\ub4e4 \uc911 ``requires_grad`` \uc18d\uc131\uc774 ``True``\\ \ub85c \uc124\uc815\ub41c\n    \ub178\ub4dc\ub4e4\uc758 ``grad`` \uc18d\uc131\ub9cc \uad6c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub798\ud504\uc758 \ub2e4\ub978 \ubaa8\ub4e0 \ub178\ub4dc\uc5d0\uc11c\ub294 \ubcc0\ud654\ub3c4\uac00\n    \uc720\ud6a8\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n  - \uc131\ub2a5 \uc0c1\uc758 \uc774\uc720\ub85c, \uc8fc\uc5b4\uc9c4 \uadf8\ub798\ud504\uc5d0\uc11c\uc758 ``backward``\\ \ub97c \uc0ac\uc6a9\ud55c \ubcc0\ud654\ub3c4 \uacc4\uc0b0\uc740 \ud55c \ubc88\ub9cc\n    \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub9cc\uc57d \ub3d9\uc77c\ud55c \uadf8\ub798\ud504\uc5d0\uc11c \uc5ec\ub7ec\ubc88\uc758 ``backward`` \ud638\ucd9c\uc774 \ud544\uc694\ud558\uba74,\n    ``backward`` \ud638\ucd9c \uc2dc\uc5d0 ``retrain_graph=True``\\ \ub97c \uc804\ub2ec\ud574\uc57c \ud569\ub2c8\ub2e4.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ubcc0\ud654\ub3c4 \ucd94\uc801 \uba48\ucd94\uae30\n\n\uae30\ubcf8\uc801\uc73c\ub85c, ``requires_grad=True``\\ \uc778 \ubaa8\ub4e0 \ud150\uc11c\ub4e4\uc740 \uc5f0\uc0b0 \uae30\ub85d\uc744 \ucd94\uc801\ud558\uace0 \ubcc0\ud654\ub3c4 \uacc4\uc0b0\uc744\n\uc9c0\uc6d0\ud569\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \ubaa8\ub378\uc744 \ud559\uc2b5\ud55c \ub4a4 \uc785\ub825 \ub370\uc774\ud130\ub97c \ub2e8\uc21c\ud788 \uc801\uc6a9\ud558\uae30\ub9cc \ud558\ub294 \uacbd\uc6b0\uc640 \uac19\uc774 *\uc21c\uc804\ud30c*\n\uc5f0\uc0b0\ub9cc \ud544\uc694\ud55c \uacbd\uc6b0\uc5d0\ub294, \uc774\ub7ec\ud55c \ucd94\uc801\uc774\ub098 \uc9c0\uc6d0\uc774 \ud544\uc694 \uc5c6\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\uc5f0\uc0b0 \ucf54\ub4dc\ub97c ``torch.no_grad()`` \ube14\ub85d\uc73c\ub85c \ub458\ub7ec\uc2f8\uc11c \uc5f0\uc0b0 \ucd94\uc801\uc744 \uba48\ucd9c \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = torch.matmul(x, w)+b\nprint(z.requires_grad)\n\nwith torch.no_grad():\n    z = torch.matmul(x, w)+b\nprint(z.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub3d9\uc77c\ud55c \uacb0\uacfc\ub97c \uc5bb\ub294 \ub2e4\ub978 \ubc29\ubc95\uc740 \ud150\uc11c\uc5d0 ``detach()`` \uba54\uc18c\ub4dc\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc785\ub2c8\ub2e4:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = torch.matmul(x, w)+b\nz_det = z.detach()\nprint(z_det.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubcc0\ud654\ub3c4 \ucd94\uc801\uc744 \uba48\ucdb0\uc57c \ud558\ub294 \uc774\uc720\ub4e4\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n  - \uc2e0\uacbd\ub9dd\uc758 \uc77c\ubd80 \ub9e4\uac1c\ubcc0\uc218\ub97c **\uace0\uc815\ub41c \ub9e4\uac1c\ubcc0\uc218(frozen parameter)**\\ \ub85c \ud45c\uc2dc\ud569\ub2c8\ub2e4.\n  - \ubcc0\ud654\ub3c4\ub97c \ucd94\uc801\ud558\uc9c0 \uc54a\ub294 \ud150\uc11c\uc758 \uc5f0\uc0b0\uc774 \ub354 \ud6a8\uc728\uc801\uc774\uae30 \ub54c\ubb38\uc5d0, \uc21c\uc804\ud30c \ub2e8\uacc4\ub9cc \uc218\ud589\ud560 \ub54c\n    **\uc5f0\uc0b0 \uc18d\ub3c4\uac00 \ud5a5\uc0c1\ub429\ub2c8\ub2e4.**\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc5f0\uc0b0 \uadf8\ub798\ud504\uc5d0 \ub300\ud55c \ucd94\uac00 \uc815\ubcf4\n\n\uac1c\ub150\uc801\uc73c\ub85c, autograd\ub294 \ub370\uc774\ud130(\ud150\uc11c)\uc758 \ubc0f \uc2e4\ud589\ub41c \ubaa8\ub4e0 \uc5f0\uc0b0\ub4e4(\ubc0f \uc5f0\uc0b0 \uacb0\uacfc\uac00 \uc0c8\ub85c\uc6b4 \ud150\uc11c\uc778 \uacbd\uc6b0\ub3c4 \ud3ec\ud568\ud558\uc5ec)\uc758\n\uae30\ub85d\uc744 [Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)_ \uac1d\uccb4\ub85c\n\uad6c\uc131\ub41c \ubc29\ud5a5\uc131 \ube44\uc21c\ud658 \uadf8\ub798\ud504(DAG; Directed Acyclic Graph)\uc5d0 \uc800\uc7a5(keep)\ud569\ub2c8\ub2e4.\n\uc774 \ubc29\ud5a5\uc131 \ube44\uc21c\ud658 \uadf8\ub798\ud504(DAG)\uc758 \uc78e(leave)\uc740 \uc785\ub825 \ud150\uc11c\uc774\uace0, \ubfcc\ub9ac(root)\ub294 \uacb0\uacfc \ud150\uc11c\uc785\ub2c8\ub2e4.\n\uc774 \uadf8\ub798\ud504\ub97c \ubfcc\ub9ac\uc5d0\uc11c\ubd80\ud130 \uc78e\uae4c\uc9c0 \ucd94\uc801\ud558\uba74 \uc5f0\uc1c4 \ubc95\uce59(chain rule)\uc5d0 \ub530\ub77c \ubcc0\ud654\ub3c4\ub97c \uc790\ub3d9\uc73c\ub85c \uacc4\uc0b0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc21c\uc804\ud30c \ub2e8\uacc4\uc5d0\uc11c, autograd\ub294 \ub2e4\uc74c \ub450 \uac00\uc9c0 \uc791\uc5c5\uc744 \ub3d9\uc2dc\uc5d0 \uc218\ud589\ud569\ub2c8\ub2e4:\n\n- \uc694\uccad\ub41c \uc5f0\uc0b0\uc744 \uc218\ud589\ud558\uc5ec \uacb0\uacfc \ud150\uc11c\ub97c \uacc4\uc0b0\ud558\uace0,\n- DAG\uc5d0 \uc5f0\uc0b0\uc758 *\ubcc0\ud654\ub3c4 \uae30\ub2a5(gradient function)* \ub97c \uc720\uc9c0(maintain)\ud569\ub2c8\ub2e4.\n\n\uc5ed\uc804\ud30c \ub2e8\uacc4\ub294 DAG \ubfcc\ub9ac(root)\uc5d0\uc11c ``.backward()`` \uac00 \ud638\ucd9c\ub420 \ub54c \uc2dc\uc791\ub429\ub2c8\ub2e4. ``autograd``\\ \ub294 \uc774 \ub54c:\n\n- \uac01 ``.grad_fn`` \uc73c\ub85c\ubd80\ud130 \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\uace0,\n- \uac01 \ud150\uc11c\uc758 ``.grad`` \uc18d\uc131\uc5d0 \uacc4\uc0b0 \uacb0\uacfc\ub97c \uc313\uace0(accumulate),\n- \uc5f0\uc1c4 \ubc95\uce59\uc744 \uc0ac\uc6a9\ud558\uc5ec, \ubaa8\ub4e0 \uc78e(leaf) \ud150\uc11c\ub4e4\uae4c\uc9c0 \uc804\ud30c(propagate)\ud569\ub2c8\ub2e4.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>**PyTorch\uc5d0\uc11c DAG\ub4e4\uc740 \ub3d9\uc801(dynamic)\uc785\ub2c8\ub2e4.**\n  \uc8fc\ubaa9\ud574\uc57c \ud560 \uc911\uc694\ud55c \uc810\uc740 \uadf8\ub798\ud504\uac00 \ucc98\uc74c\ubd80\ud130(from scratch) \ub2e4\uc2dc \uc0dd\uc131\ub41c\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4; \ub9e4\ubc88 ``.bachward()`` \uac00\n  \ud638\ucd9c\ub418\uace0 \ub098\uba74, autograd\ub294 \uc0c8\ub85c\uc6b4 \uadf8\ub798\ud504\ub97c \ucc44\uc6b0\uae30(populate) \uc2dc\uc791\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc810 \ub355\ubd84\uc5d0 \ubaa8\ub378\uc5d0\uc11c\n  \ud750\ub984 \uc81c\uc5b4(control flow) \uad6c\ubb38\ub4e4\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ub418\ub294 \uac83\uc785\ub2c8\ub2e4; \ub9e4\ubc88 \ubc18\ubcf5(iteration)\ud560 \ub54c\ub9c8\ub2e4 \ud544\uc694\ud558\uba74\n  \ubaa8\uc591(shape)\uc774\ub098 \ud06c\uae30(size), \uc5f0\uc0b0(operation)\uc744 \ubc14\uafc0 \uc218 \uc788\uc2b5\ub2c8\ub2e4.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \uc120\ud0dd\uc801\uc73c\ub85c \uc77d\uae30(Optional Reading): \ud150\uc11c \ubcc0\ud654\ub3c4\uc640 \uc57c\ucf54\ube44\uc548 \uacf1 (Jacobian Product)\n\n\ub300\ubd80\ubd84\uc758 \uacbd\uc6b0, \uc2a4\uce7c\ub77c \uc190\uc2e4 \ud568\uc218\ub97c \uac00\uc9c0\uace0 \uc77c\ubd80 \ub9e4\uac1c\ubcc0\uc218\uc640 \uad00\ub828\ud55c \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud574\uc57c \ud569\ub2c8\ub2e4.\n\uadf8\ub7ec\ub098 \ucd9c\ub825 \ud568\uc218\uac00 \uc784\uc758\uc758 \ud150\uc11c\uc778 \uacbd\uc6b0\uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7f4 \ub54c, PyTorch\ub294 \uc2e4\uc81c \ubcc0\ud654\ub3c4\uac00 \uc544\ub2cc\n**\uc57c\ucf54\ube44\uc548 \uacf1(Jacobian product)**\\ \uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\n$\\vec{x}=\\langle x_1,\\dots,x_n\\rangle$\\ \uc774\uace0,\n$\\vec{y}=\\langle y_1,\\dots,y_m\\rangle$\\ \uc77c \ub54c\n\ubca1\ud130 \ud568\uc218 $\\vec{y}=f(\\vec{x})$\\ \uc5d0\uc11c $\\vec{x}$\\ \uc5d0 \ub300\ud55c\n$\\vec{y}$ \uc758 \ubcc0\ud654\ub3c4\ub294 **\uc57c\ucf54\ube44\uc548 \ud589\ub82c(Jacobian matrix)**\\ \ub85c \uc8fc\uc5b4\uc9d1\ub2c8\ub2e4:\n\n\\begin{align}J=\\left(\\begin{array}{ccc}\n      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n      \\vdots & \\ddots & \\vdots\\\\\n      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n      \\end{array}\\right)\\end{align}\n\n\uc57c\ucf54\ube44\uc548 \ud589\ub82c \uc790\uccb4\ub97c \uacc4\uc0b0\ud558\ub294 \ub300\uc2e0, PyTorch\ub294 \uc8fc\uc5b4\uc9c4 \uc785\ub825 \ubca1\ud130 $v=(v_1 \\dots v_m)$\\ \uc5d0 \ub300\ud55c\n**\uc57c\ucf54\ube44\uc548 \uacf1(Jacobian Product)**  $v^T\\cdot J$\\ \uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\uc774 \uacfc\uc815\uc740 $v$\\ \ub97c \uc778\uc790\ub85c ``backward``\\ \ub97c \ud638\ucd9c\ud558\uba74 \uc774\ub904\uc9d1\ub2c8\ub2e4. $v$\\ \uc758 \ud06c\uae30\ub294\n\uacf1(product)\uc744 \uacc4\uc0b0\ud558\ub824\uace0 \ud558\ub294 \uc6d0\ub798 \ud150\uc11c\uc758 \ud06c\uae30\uc640 \uac19\uc544\uc57c \ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inp = torch.eye(4, 5, requires_grad=True)\nout = (inp+1).pow(2).t()\nout.backward(torch.ones_like(out), retain_graph=True)\nprint(f\"First call\\n{inp.grad}\")\nout.backward(torch.ones_like(out), retain_graph=True)\nprint(f\"\\nSecond call\\n{inp.grad}\")\ninp.grad.zero_()\nout.backward(torch.ones_like(out), retain_graph=True)\nprint(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub3d9\uc77c\ud55c \uc778\uc790\ub85c ``backward``\\ \ub97c \ub450\ucc28\ub840 \ud638\ucd9c\ud558\uba74 \ubcc0\ud654\ub3c4 \uac12\uc774 \ub2ec\ub77c\uc9d1\ub2c8\ub2e4.\n\uc774\ub294 ``\uc5ed\ubc29\ud5a5`` \uc804\ud30c\ub97c \uc218\ud589\ud560 \ub54c, PyTorch\uac00 **\ubcc0\ud654\ub3c4\ub97c \ub204\uc801(accumulate)\ud574\uc8fc\uae30 \ub54c\ubb38**\\\n\uc785\ub2c8\ub2e4. \uc989, \uacc4\uc0b0\ub41c \ubcc0\ud654\ub3c4\uc758 \uac12\uc774 \uc5f0\uc0b0 \uadf8\ub798\ud504\uc758 \ubaa8\ub4e0 \uc78e(leaf) \ub178\ub4dc\uc758 ``grad`` \uc18d\uc131\uc5d0\n\ucd94\uac00\ub429\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc81c\ub300\ub85c \ub41c \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574\uc11c\ub294 ``grad`` \uc18d\uc131\uc744 \uba3c\uc800 0\uc73c\ub85c \ub9cc\ub4e4\uc5b4\uc57c\n\ud569\ub2c8\ub2e4. \uc2e4\uc81c \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c\ub294 *\uc635\ud2f0\ub9c8\uc774\uc800(optimizer)*\\ \uac00 \uc774 \uacfc\uc815\uc744 \ub3c4\uc640\uc90d\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\uc774\uc804\uc5d0\ub294 \ub9e4\uac1c\ubcc0\uc218 \uc5c6\uc774 ``backward()`` \ud568\uc218\ub97c \ud638\ucd9c\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ubcf8\uc9c8\uc801\uc73c\ub85c\n          ``backward(torch.tensor(1.0))`` \uc744 \ud638\ucd9c\ud558\ub294 \uac83\uacfc \ub3d9\uc77c\ud558\uba70,\n          \uc2e0\uacbd\ub9dd \ud6c8\ub828 \uc911\uc758 \uc190\uc2e4\uacfc \uac19\uc740 \uc2a4\uce7c\ub77c-\uac12 \ud568\uc218\uc758 \ubcc0\ud654\ub3c4\ub97c \uacc4\uc0b0\ud558\ub294 \uc720\uc6a9\ud55c \ubc29\ubc95\uc785\ub2c8\ub2e4.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ub354 \uc77d\uc5b4\ubcf4\uae30\n- [Autograd Mechanics](https://pytorch.org/docs/stable/notes/autograd.html)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}