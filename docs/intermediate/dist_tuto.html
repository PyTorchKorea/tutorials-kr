


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Pytorch로 분산 어플리케이션 개발하기 &mdash; PyTorch Tutorials 0.4.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="공간 변형기 네트워크(Spatial Transformer Networks) 튜토리얼" href="spatial_transformer_tutorial.html" />
    <link rel="prev" title="강화 학습 (DQN) 튜토리얼" href="reinforcement_q_learning.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   
  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.4.1
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Beginner Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">PyTorch로 딥러닝하기: 60분만에 끝장내기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/former_torchies_tutorial.html">Torch 사용자를 위한 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">예제로 배우는 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">전이학습(Transfer Learning) 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/data_loading_tutorial.html">Data Loading and Processing Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a></li>
</ul>
<p class="caption"><span class="caption-text">Intermediate Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="char_rnn_classification_tutorial.html">문자-단위 RNN으로 이름 분류하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="char_rnn_generation_tutorial.html">문자-단위 RNN으로 이름 생성하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="seq2seq_translation_tutorial.html">Sequence to Sequence 네트워크와 Attention을 이용한 번역</a></li>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_q_learning.html">강화 학습 (DQN) 튜토리얼</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Pytorch로 분산 어플리케이션 개발하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="spatial_transformer_tutorial.html">공간 변형기 네트워크(Spatial Transformer Networks) 튜토리얼</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/neural_style_tutorial.html">PyTorch를 이용한 신경망-변환(Neural-Transfer)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html">Creating extensions using numpy and scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html">Transfering a model from PyTorch to Caffe2 and Mobile using ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
      <li>Pytorch로 분산 어플리케이션 개발하기</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/intermediate/dist_tuto.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <div class="section" id="pytorch">
<h1>Pytorch로 분산 어플리케이션 개발하기<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h1>
<dl class="docutils">
<dt><strong>Author</strong>: <a class="reference external" href="http://seba1511.com">Séb Arnold</a></dt>
<dd><strong>번역</strong>: <a class="reference external" href="https://github.com/adonisues">황성수</a></dd>
</dl>
<p>이 짧은 튜토리얼에서 Pytorch의 분산 패키지를 둘러봅니다. 분산 설정 방법을 살펴보고,
다른 통신 전략을 사용하고, 몇몇 내부 패키지를 확인해 봅니다.</p>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h2>
<!--
* Processes & machines
* variables and init_process_group
--><p>Pytorch에 포함된 분산 패키지 (i.e., <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code>)는 연구자와 개발자가
여러개의 프로세서와 머신 클러스터에서 계산을 쉽게 병렬화하게 해준다.
그렇게 하기 위해서, messaging passing semantics 가 각 프로세스가 다른 프로세스들과
데이터를 통신하도록 해준다. 다중 처리(<code class="docutils literal notranslate"><span class="pre">torch.multiprocessing</span></code>) 패키지와 달리
프로세스는 다른 통신 백엔드를 사용할 수 있으며 동일한 기계에서 실행되는 것으로
제한됩니다.</p>
<p>시작하려면 여러 프로세스를 동시에 실행할 수 있어야합니다. 컴퓨트 클러스터에
접속할 경우 local sysadmin 으로 점검하거나 또는 선호하는 coordination tool을
사용하십시오.
(e.g.,
<a class="reference external" href="https://linux.die.net/man/1/pdsh">pdsh</a> ,
<a class="reference external" href="http://cea-hpc.github.io/clustershell/">clustershell</a> 또는
<a class="reference external" href="https://slurm.schedmd.com/">others</a> ) 이 튜토리얼에서는 다음 템플릿을 사용하여
단일 기기를 사용하고 여러 프로세스를 포크합니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;run.py:&quot;&quot;&quot;</span>
<span class="c1">#!/usr/bin/env python</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">from</span> <span class="nn">torch.multiprocessing</span> <span class="k">import</span> <span class="n">Process</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Distributed function to be implemented later. &quot;&quot;&quot;</span>
    <span class="k">pass</span>

<span class="k">def</span> <span class="nf">init_processes</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;tcp&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Initialize the distributed environment. &quot;&quot;&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;127.0.0.1&#39;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">size</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">processes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">init_processes</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">run</span><span class="p">))</span>
        <span class="n">p</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="n">processes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">processes</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</pre></div>
</div>
<p>위 스크립트는 각각 분산 환경을 설정하는 두개의 프로세스를 생성하고,
프로세스 그룹(<code class="docutils literal notranslate"><span class="pre">dist.init_process_group</span></code>)을 초기화하고, 마지막으로 주어진
<code class="docutils literal notranslate"><span class="pre">run</span></code> 함수를 실행합니다.</p>
<p><code class="docutils literal notranslate"><span class="pre">init_processes</span></code> 함수는 동일한 IP 주소와 포트를 사용해서 모든 프로세스가 마스터를
통해서 조직 되게 한다. 우리는 TCP 백헨드를 사용했지만 대신
<a class="reference external" href="https://en.wikipedia.org/wiki/Message_Passing_Interface">MPI</a> 또는
<a class="reference external" href="http://github.com/facebookincubator/gloo">Gloo</a> 를 사용할 수 있습니다.
(c.f. <a class="reference external" href="#communication-backends">Section 5.1</a>) 이 튜토리얼의 마지막에 있는
<code class="docutils literal notranslate"><span class="pre">dist.init_process_group</span></code> 에서 일어나는 마법을 살펴봅니다. 그러나 기본적으로
프로세스는 자신의 위치를 공유하여 서로 통신할 수 있습니다.</p>
</div>
<div class="section" id="point-to-point-communication">
<h2>지점간 통신(Point-to-Point Communication)<a class="headerlink" href="#point-to-point-communication" title="Permalink to this headline">¶</a></h2>
<div class="figure align-center" id="id4">
<a class="reference internal image-reference" href="../_images/send_recv.png"><img alt="Send and Recv" src="../_images/send_recv.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">전송과 수신</span></p>
</div>
<p>하나의 프로세스에서 다른 프로세스로 데이터를 전송하는 것을 지점간 통신이라고합니다.
이것은 <code class="docutils literal notranslate"><span class="pre">send</span></code> 와 <code class="docutils literal notranslate"><span class="pre">recv</span></code> 함수 또는 직접 대응부인 (<em>immediate</em> counter-parts)
<code class="docutils literal notranslate"><span class="pre">isend</span></code> 와 <code class="docutils literal notranslate"><span class="pre">irecv</span></code> 를 통해 이루어집니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Blocking point-to-point communication.&quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Send the tensor to process 1</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Receive tensor from process 0</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>위의 예제에서 두 프로세스는 모두 값이 0인 Tensor 로 시작하고, 0번 프로세스는
Tensor를 증가시키고 프로세스 1로 보내서 양쪽 모두 1.0으로 끝납니다. 프로세스 1은
수신 할 데이터를 저장하기 위해 메모리를 할당해야합니다.</p>
<p>또한 <code class="docutils literal notranslate"><span class="pre">send</span></code> / <code class="docutils literal notranslate"><span class="pre">recv</span></code> 는 <strong>blocking</strong> 으로 동작합니다. : 통신이 완료될 때까지
두 프로세스 모두 멈춥니다. 반면에 Immediates ( <code class="docutils literal notranslate"><span class="pre">isend</span></code> 와 <code class="docutils literal notranslate"><span class="pre">irecv</span></code> )는
<strong>non-blocking</strong> 으로 동작 합니다; 스크립트는 실행을 계속하고 메서드는 <code class="docutils literal notranslate"><span class="pre">wait()</span></code>
를 선택할 수 있는 <code class="docutils literal notranslate"><span class="pre">DistributedRequest</span></code> 객체를 반환합니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Non-blocking point-to-point communication.&quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">req</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Send the tensor to process 1</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank 0 started sending&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Receive tensor from process 0</span>
        <span class="n">req</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">irecv</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank 1 started receiving&#39;</span><span class="p">)</span>
    <span class="n">req</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>Immediates 를 사용할 때 보내고 받는 Tensor에 대한 사용법에 주의해야 합니다.
언제 데이터가 다른 프로세스와 통신 될지 알지 못하기 때문에, <code class="docutils literal notranslate"><span class="pre">req.wait</span> <span class="pre">()</span></code> 가
완료되기 전에 전송된 Tensor를 수정하거나 수신된 Tensor에 접근해서는 안됩니다.</p>
<p>다시 말하면,</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">dist.isend</span> <span class="pre">()</span></code> 다음에 <code class="docutils literal notranslate"><span class="pre">tensor</span></code> 에 쓰면 정의되지 않은 동작이 발생합니다.</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.irecv</span> <span class="pre">()</span></code> 다음에 <code class="docutils literal notranslate"><span class="pre">tensor</span></code> 를 읽으면 정의되지 않은 동작이 발생합니다.</li>
</ul>
<p>그러나 <code class="docutils literal notranslate"><span class="pre">req.wait</span> <span class="pre">()</span></code> 가 실행 된 후에 통신이 이루어진 것과, <code class="docutils literal notranslate"><span class="pre">tensor[0]</span></code> 에
저장된 값이 1.0이라는 것이 보장됩니다.</p>
<p>지점 간 통신은 프로세스 통신에 대한 세분화 된 제어를 원할 때 유용합니다. 그것들은
<a class="reference external" href="https://github.com/baidu-research/baidu-allreduce">Baidu’s DeepSpeech</a> 또는
<a class="reference external" href="https://research.fb.com/publications/imagenet1kin1h/">Facebook’s large-scale experiments</a>
(c.f. <a class="reference external" href="#our-own-ring-allreduce">Section 4.1</a>) 와 같은 고급 알고리즘을 구현하는데
사용됩니다.</p>
</div>
<div class="section" id="collective-communication">
<h2>집단 통신 (Collective Communication)<a class="headerlink" href="#collective-communication" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first last figure align-center" id="id5">
<a class="reference internal image-reference" href="../_images/scatter.png"><img alt="Scatter" src="../_images/scatter.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Scatter</span></p>
</div>
</td>
<td><div class="first last figure align-center" id="id6">
<a class="reference internal image-reference" href="../_images/gather.png"><img alt="Gather" src="../_images/gather.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Gather</span></p>
</div>
</td>
</tr>
<tr class="row-even"><td><div class="first last figure align-center" id="id7">
<a class="reference internal image-reference" href="../_images/reduce.png"><img alt="Reduce" src="../_images/reduce.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Reduce</span></p>
</div>
</td>
<td><div class="first last figure align-center" id="id8">
<a class="reference internal image-reference" href="../_images/all_reduce.png"><img alt="All-Reduce" src="../_images/all_reduce.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">All-Reduce</span></p>
</div>
</td>
</tr>
<tr class="row-odd"><td><div class="first last figure align-center" id="id9">
<a class="reference internal image-reference" href="../_images/broadcast.png"><img alt="Broadcast" src="../_images/broadcast.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Broadcast</span></p>
</div>
</td>
<td><div class="first last figure align-center" id="id10">
<a class="reference internal image-reference" href="../_images/all_gather.png"><img alt="All-Gather" src="../_images/all_gather.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">All-Gather</span></p>
</div>
</td>
</tr>
</tbody>
</table>
<p>지점간 통신과는 달리 집단 통신은 <strong>그룹(Group)</strong> 의 모든 프로세스에서 통신 패턴을
허용합니다. 그룹은 모든 프로세스의 하위 집합입니다.
그룹을 만들려면, <code class="docutils literal notranslate"><span class="pre">dist.new_group</span> <span class="pre">(group)</span></code> 에 순위 목록을 전달하면 됩니다.
기본적으로 집단 통신은 <strong>월드(World)</strong> 라고도하는 모든 프로세스에서 실행됩니다.
예를 들어, 모든 프로세스에서 모든 Tensor의 합을 얻으려면,
<code class="docutils literal notranslate"><span class="pre">dist.all_reduce</span> <span class="pre">(tensor,</span> <span class="pre">op,</span> <span class="pre">group)</span></code> 를 사용할 수 있습니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; All-Reduce example.&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Simple point-to-point communication. &quot;&quot;&quot;</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">new_group</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">reduce_op</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="s1">&#39; has data &#39;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>그룹의 모든 Tensor의 합이 필요하기 때문에 Reduce 연산자로 <code class="docutils literal notranslate"><span class="pre">dist.reduce_op.SUM</span></code> 을
사용합니다. 일반적으로 교환 법칙이 성립하는 수학 연산은 연산자로 사용할 수 있습니다.</p>
<p>특별히, PyTorch는 4개의 연산자를 제공하고 모두 요소 별로(element-wise) 작동합니다.:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">dist.reduce_op.SUM</span></code>,</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.reduce_op.PRODUCT</span></code>,</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.reduce_op.MAX</span></code>,</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.reduce_op.MIN</span></code>.</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">dist.all_reduce</span> <span class="pre">(tensor,</span> <span class="pre">op,</span> <span class="pre">group)</span></code> 외에 현재 PyTorch에서 구현된 총 6개의
집단 통신이 있습니다.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">dist.broadcast(tensor,</span> <span class="pre">src,</span> <span class="pre">group)</span></code>: <code class="docutils literal notranslate"><span class="pre">src</span></code> 에서 다른 모든 프로세스로
<code class="docutils literal notranslate"><span class="pre">tensor</span></code> 를 복사합니다.</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.reduce(tensor,</span> <span class="pre">dst,</span> <span class="pre">op,</span> <span class="pre">group)</span></code>: 모든 <code class="docutils literal notranslate"><span class="pre">tensor</span></code> 에 <code class="docutils literal notranslate"><span class="pre">op</span></code> 를 적용하고
그 결과를 <code class="docutils literal notranslate"><span class="pre">dst</span></code> 에 저장합니다.</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.all_reduce(tensor,</span> <span class="pre">op,</span> <span class="pre">group)</span></code>: reduce와 같지만 결과는 모든 프로세스에
저장됩니다.</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.scatter(tensor,</span> <span class="pre">src,</span> <span class="pre">scatter_list,</span> <span class="pre">group)</span></code>: <code class="docutils literal notranslate"><span class="pre">i번째</span> <span class="pre">tensor</span></code>
<code class="docutils literal notranslate"><span class="pre">scatter_list[i]</span></code> 를 <code class="docutils literal notranslate"><span class="pre">i번째</span></code> 프로세스에 복사합니다.</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.gather(tensor,</span> <span class="pre">dst,</span> <span class="pre">gather_list,</span> <span class="pre">group)</span></code>: <code class="docutils literal notranslate"><span class="pre">dst</span></code> 의 모든 프로세스에서
<code class="docutils literal notranslate"><span class="pre">tensor</span></code> 를 복사합니다</li>
<li><code class="docutils literal notranslate"><span class="pre">dist.all_gather(tensor_list,</span> <span class="pre">tensor,</span> <span class="pre">group)</span></code>:  모든 프로세스에서 <code class="docutils literal notranslate"><span class="pre">tensor</span></code> 를
모든 프로세스의 <code class="docutils literal notranslate"><span class="pre">tensor_list</span></code> 에 복사합니다.</li>
</ul>
</div>
<div class="section" id="distributed-training">
<h2>분산 학습(Distributed Training)<a class="headerlink" href="#distributed-training" title="Permalink to this headline">¶</a></h2>
<!--
* Gloo Backend
* Simple all_reduce on the gradients
* Point to optimized DistributedDataParallel

TODO: Custom ring-allreduce
--><p><strong>알림:</strong> 이 섹션의 예제 스크립트를
<a class="reference external" href="https://github.com/seba-1511/dist_tuto.pth/">GitHub repository</a> 에서 찾으실
수 있습니다.</p>
<p>이제 분산 모듈이 어떻게 작동하는지 이해 했으므로 유용한 모듈을 작성해 보겠습니다.
우리의 목표는 <a class="reference external" href="http://pytorch.org/docs/master/nn.html#torch.nn.parallel.DistributedDataParallel">DistributedDataParallel</a> 의
기능을 복제하는 것입니다. 물론, 이것은 교훈적인 예가 되지만, 실제 상황에서 위에
링크된 잘 검증되고 최적화 된 공식 버전을 사용해야합니다.</p>
<p>매우 간단하게 확률적 경사 하강법의 분산 버전을 구현하고자 합니다. 스크립트는 모든
프로세스가 데이터 배치에서 모델의 변화도를 계산한 다음 변화도를 평균합니다.
프로세스 수를 변경할 때 유사한 수렴 결과를 보장하기 위해 우선 데이터 세트를 분할해야
합니다. (아래 단편 코드 대신에
<a class="reference external" href="https://github.com/pytorch/tnt/blob/master/torchnet/dataset/splitdataset.py#L4">tnt.dataset.SplitDataset</a>
를 이용할 수 있습니다.)</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; Dataset partitioning helper &quot;&quot;&quot;</span>
<span class="k">class</span> <span class="nc">Partition</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">index</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">data_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">data_idx</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">DataPartitioner</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">sizes</span><span class="o">=</span><span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1234</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">partitions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">Random</span><span class="p">()</span>
        <span class="n">rng</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">data_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">data_len</span><span class="p">)]</span>
        <span class="n">rng</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">frac</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">:</span>
            <span class="n">part_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">frac</span> <span class="o">*</span> <span class="n">data_len</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">partitions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">indexes</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">part_len</span><span class="p">])</span>
            <span class="n">indexes</span> <span class="o">=</span> <span class="n">indexes</span><span class="p">[</span><span class="n">part_len</span><span class="p">:]</span>

    <span class="k">def</span> <span class="nf">use</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">partition</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Partition</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">partitions</span><span class="p">[</span><span class="n">partition</span><span class="p">])</span>
</pre></div>
</div>
<p>위의 단편 코드로 다음 몇 줄을 이용해 모든 데이터 세트를 간단하게 분할할 수 있습니다:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; Partitioning MNIST &quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">partition_dataset</span><span class="p">():</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                             <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                                 <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                 <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                             <span class="p">]))</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
    <span class="n">bsz</span> <span class="o">=</span> <span class="mi">128</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="n">partition_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">size</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)]</span>
    <span class="n">partition</span> <span class="o">=</span> <span class="n">DataPartitioner</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">partition_sizes</span><span class="p">)</span>
    <span class="n">partition</span> <span class="o">=</span> <span class="n">partition</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">())</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">partition</span><span class="p">,</span>
                                         <span class="n">batch_size</span><span class="o">=</span><span class="n">bsz</span><span class="p">,</span>
                                         <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">bsz</span>
</pre></div>
</div>
<p>2개의 복제본이 있다고 가정하면, 각 프로세스는 60000 / 2 = 30000 샘플의
<code class="docutils literal notranslate"><span class="pre">train_set</span></code> 을 가질 것입니다. 또한 <strong>전체</strong> 배치 크기 128을 유지하기 위해 배치
크기를 복제본 수로 나눕니다.</p>
<p>이제는 일반적인 forward-backward-optimize 학습 코드를 작성하고, 모델의 변화도를
평균하는 함수 호출을 추가 할 수 있습니다. (다음은 공식
<a class="reference external" href="https://github.com/pytorch/examples/blob/master/mnist/main.py">PyTorch MNIST 예제</a>
에서 영감을 얻었습니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; Distributed Synchronous SGD Example &quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
    <span class="n">train_set</span><span class="p">,</span> <span class="n">bsz</span> <span class="o">=</span> <span class="n">partition_dataset</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                          <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">bsz</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">train_set</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">average_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank &#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(),</span> <span class="s1">&#39;, epoch &#39;</span><span class="p">,</span>
              <span class="n">epoch</span><span class="p">,</span> <span class="s1">&#39;: &#39;</span><span class="p">,</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="n">num_batches</span><span class="p">)</span>
</pre></div>
</div>
<p>단순히 모델을 취하여 world의 변화도를 평균하는 <code class="docutils literal notranslate"><span class="pre">average_gradients</span> <span class="pre">(model)</span></code> 함수를
구현하는 것이 남았습니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; Gradient averaging. &quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">average_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">reduce_op</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
        <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">/=</span> <span class="n">size</span>
</pre></div>
</div>
<p><em>완성</em>! 우리는 분산 동기식 SGD를 성공적으로 구현했으며 대형 컴퓨터 클러스터에서
모든 모델을 학습 할 수 있었습니다.</p>
<p><strong>주의:</strong> 마지막 문장은 <em>기술적으로</em> 사실이지만 동기식 SGD의 상용 수준 구현하는데
필요한 더 많은 트릭이 있습니다. 다시말하면
<a class="reference external" href="http://pytorch.org/docs/master/nn.html#torch.nn.parallel.DistributedDataParallel">검증되고 최적화된 함수</a> 를
사용하십시오.</p>
<div class="section" id="our-own-ring-allreduce">
<h3>Our Own Ring-Allreduce<a class="headerlink" href="#our-own-ring-allreduce" title="Permalink to this headline">¶</a></h3>
<p>추가 과제로서 DeepSpeech의 효율적인 ring allreduce 를 구현하고 싶다고 상상해보십시오.
이것은 지점간 집단 통신 (point-to-point collectives)을 사용하여 쉽게 구현됩니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; Implementation of a ring-reduce with addition. &quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">allreduce</span><span class="p">(</span><span class="n">send</span><span class="p">,</span> <span class="n">recv</span><span class="p">):</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
    <span class="n">send_buff</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">send</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="n">recv_buff</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">send</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="n">accum</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">send</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="n">accum</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">send</span><span class="p">[:]</span>

    <span class="n">left</span> <span class="o">=</span> <span class="p">((</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">size</span><span class="p">)</span> <span class="o">%</span> <span class="n">size</span>
    <span class="n">right</span> <span class="o">=</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">size</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Send send_buff</span>
            <span class="n">send_req</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">send_buff</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
            <span class="n">dist</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">recv_buff</span><span class="p">,</span> <span class="n">left</span><span class="p">)</span>
            <span class="n">accum</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">recv</span><span class="p">[:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Send recv_buff</span>
            <span class="n">send_req</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">isend</span><span class="p">(</span><span class="n">recv_buff</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
            <span class="n">dist</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">send_buff</span><span class="p">,</span> <span class="n">left</span><span class="p">)</span>
            <span class="n">accum</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">send</span><span class="p">[:]</span>
        <span class="n">send_req</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="n">recv</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">accum</span><span class="p">[:]</span>
</pre></div>
</div>
<p>위의 스크립트에서, <code class="docutils literal notranslate"><span class="pre">allreduce</span> <span class="pre">(send,</span> <span class="pre">recv)</span></code> 함수는 PyTorch에 있는 것과 약간 다른
특징을 가지고 있습니다.
그것은 <code class="docutils literal notranslate"><span class="pre">recv</span></code> tensor를 취해서 모든 <code class="docutils literal notranslate"><span class="pre">send</span></code> tensor의 합을 저장합니다. 독자에게
남겨진 실습으로, 우리의 버전과 DeepSpeech의 차이점은 여전히 한가지가 있습니다:
그들의 구현은 통신 대역폭을 최적으로 활용하기 위해 경사도 tensor를 <em>chunks</em> 로
나눕니다. (힌트:
<a class="reference external" href="http://pytorch.org/docs/master/torch.html#torch.chunk">toch.chunk</a>)</p>
</div>
</div>
<div class="section" id="advanced-topics">
<h2>Advanced Topics<a class="headerlink" href="#advanced-topics" title="Permalink to this headline">¶</a></h2>
<p>이제 <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> 보다 진보된 기능들을 발견 할 준비가 되었습니다. 커버할
부분이 많으므로 이 섹션은 두 개의 하위 섹션으로 구분됩니다:</p>
<ol class="arabic simple">
<li>통신 백엔드 : GPU-GPU 통신을 위해 MPI 및 Gloo를 사용하는 방법을 배웁니다.</li>
<li>초기화 방법 : <code class="docutils literal notranslate"><span class="pre">dist.init_process_group()</span></code> 에서 초기 구성 단계를 가장 잘
설정하는 방법을 이해합니다.</li>
</ol>
<div class="section" id="id2">
<h3>통신 백엔드<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> 의 가장 우아한 면 중 하나는 다른 백엔드 위에서 추상화하고
빌드 할 수 있는 능력입니다. 앞서 언급했듯이 현재 PyTorch에는 TCP, MPI 및 Gloo의
세 가지 백엔드가 구현되어 있습니다. 그것들은 원하는 사용 사례에 따라 서로 다른
특징과 trade-off 를 가지고 있습니다. 지원되는 기능의 비교표는
<a class="reference external" href="http://pytorch.org/docs/master/distributed.html#module-torch.distributed">여기</a>
에서 찾을 수 있습니다.</p>
<p><strong>TCP 백엔드</strong></p>
<p>지금까지 우리는 TCP 백엔드를 광범위하게 사용 해왔다. 그것은 대부분의 기계 및
운영체제에서 작동하도록 보장하기 때문에 개발 플랫폼으로 매우 편리합니다.
또한 CPU에서 모든 지점간 및 집단 통신 기능을 지원합니다. 그러나 GPU에 대한 지원은
없으며 통신 루틴이 MPI만큼 최적화되지 않았습니다.</p>
<p><strong>Gloo 백엔드</strong></p>
<p><a class="reference external" href="https://github.com/facebookincubator/gloo">Gloo 백엔드</a> 는 CPU와 GPU 모두를
위한 <em>집단 통신</em> 절차의 최적화된 구현을 제공합니다.
<a class="reference external" href="https://developer.nvidia.com/gpudirect">GPUDirect</a> 를 사용하여 CPU 메모리로
데이터를 전송하지 않고 통신을 수행 할 수 있기 때문에 GPU에서 특히 빛납니다.
또한 <a class="reference external" href="https://github.com/NVIDIA/nccl">NCCL</a> 을 사용하여 빠른 노드-내부
(intra-node) 통신을 수행 할 수 있으며 노드들-간(inter-node) 루틴을 위한
<a class="reference external" href="https://github.com/facebookincubator/gloo/blob/master/docs/algorithms.md">자체 알고리즘</a> 을
구현합니다.</p>
<p>버전 0.2.0부터, Gloo 백엔드는 PyTorch의 미리 컴파일 된 바이너리에 자동으로
포함됩니다. GPU에 <code class="docutils literal notranslate"><span class="pre">모델</span></code> 을 넣으면 배포된 SGD 예제가 제대로 작동하지 않습니다.
<code class="docutils literal notranslate"><span class="pre">init_processes</span> <span class="pre">(rank,</span> <span class="pre">size,</span> <span class="pre">fn,</span> <span class="pre">backend</span> <span class="pre">=</span> <span class="pre">'tcp')</span></code> 에서``backend = ‘gloo’`` 를
먼저 바꾸어서 고쳐 보겠습니다. 이 시점에서 스크립트는 여전히 CPU에서 실행되지만
백그라운드에서 Gloo 백엔드를 사용합니다. 여러 GPU를 사용하려면 다음과 같이
수정하십시오.</p>
<ol class="arabic simple" start="0">
<li><code class="docutils literal notranslate"><span class="pre">init_processes(rank,</span> <span class="pre">size,</span> <span class="pre">fn,</span> <span class="pre">backend='tcp')</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span>
<code class="docutils literal notranslate"><span class="pre">init_processes(rank,</span> <span class="pre">size,</span> <span class="pre">fn,</span> <span class="pre">backend='gloo')</span></code></li>
</ol>
<p>1.  Use <code class="docutils literal notranslate"><span class="pre">device</span> <span class="pre">=</span> <span class="pre">torch.device(&quot;cuda:{}&quot;.format(rank))</span></code>
1. <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">=</span> <span class="pre">Net()</span></code> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">=</span> <span class="pre">Net().to(device)</span></code>
2.  Use <code class="docutils literal notranslate"><span class="pre">data,</span> <span class="pre">target</span> <span class="pre">=</span> <span class="pre">data.to(device),</span> <span class="pre">target.to(device)</span></code></p>
<p>위의 수정으로 우리 모델은 이제 2개의 GPU에서 학습하고, <code class="docutils literal notranslate"><span class="pre">watch</span> <span class="pre">nvidia-smi</span></code> 로
사용률을 모니터링 할 수 있습니다.</p>
<p><strong>MPI 백엔드</strong></p>
<p>MPI (Message Passing Interface)는 고성능 컴퓨팅 분야의 표준 도구입니다. 그것은
지점간과 집단 통신을 가능하게하고 <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> 의 API에 대한 주요
영감이었습니다. 다양한 목적으로 최적화된 여러 가지 MPI 구현 (예 :
<a class="reference external" href="https://www.open-mpi.org/">Open-MPI</a> , <a class="reference external" href="http://mvapich.cse.ohio-state.edu/">MVAPICH2</a> ,
<a class="reference external" href="https://software.intel.com/en-us/intel-mpi-library">Intel MPI</a> )이 있습니다.
MPI 백엔드를 사용하면 큰 컴퓨터 클러스터에서 MPI의 광범위한 가용성과 높은 수준의
최적화가 가능하다는 장점이 있습니다. <a class="reference external" href="https://developer.nvidia.com/mvapich">일부</a>
<a class="reference external" href="https://developer.nvidia.com/ibm-spectrum-mpi">최신</a>
<a class="reference external" href="http://www.open-mpi.org/">구현</a> 들은 CPU를 통한 메모리 복사를 피하기 위해서
CUDA IPC와 GPU 다이렉트 기술를 활용하고 있습니다.</p>
<p>불행하게도 PyTorch의 바이너리는 MPI 구현을 포함 할 수 없으므로 수동으로 다시
컴파일해야합니다. 다행히도, 이 컴파일 과정은 매우 간단합니다. PyTorch는 사용 가능한
MPI 구현을 자동으로 살펴볼 것입니다.
다음 단계는 PyTorch를 <a class="reference external" href="https://github.com/pytorch/pytorch#from-source">소스</a> 로
설치하여 MPI 백엔드를 설치합니다.</p>
<ol class="arabic simple">
<li>아나콘다 환경을 만들고 활성화하고, `
가이드 &lt;<a class="reference external" href="https://github.com/pytorch/pytorch#from-source">https://github.com/pytorch/pytorch#from-source</a>&gt;`__ 에 따라 모든 필수
조건을 설치하십시오. 그러나 아직 <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">install</span></code> 을 실행하지
마십시오.</li>
<li>원하는 MPI 구현을 선택하고 설치하십시오. CUDA 인식하는 MPI를 활성화하려면
몇 가지 추가 단계가 필요할 수 있습니다. GPU <em>없이</em>  Open-MPI를 사용 할 것입니다:
<code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">-c</span> <span class="pre">conda-forge</span> <span class="pre">openmpi</span></code></li>
<li>이제 복제 된 PyTorch repo 로 이동하여 <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">install</span></code> 을 실행하십시오.</li>
</ol>
<p>새로 설치된 백엔드를 테스트하려면 몇 가지 수정이 필요합니다.</p>
<ol class="arabic simple">
<li><code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">'__main__':</span></code> 아래 내용을 <code class="docutils literal notranslate"><span class="pre">init_processes(0,</span> <span class="pre">0,</span> <span class="pre">run,</span> <span class="pre">backend='mpi')</span></code> 로
변경하십시오.</li>
<li><code class="docutils literal notranslate"><span class="pre">mpirun</span> <span class="pre">-n</span> <span class="pre">4</span> <span class="pre">python</span> <span class="pre">myscript.py</span></code> 를 실행하십시오.</li>
</ol>
<p>이러한 변경의 이유는 MPI가 프로세스를 생성하기 전에 자체 환경을 만들어야하기 때문입니다.
MPI는 또한 자신의 프로세스를 생성하고 <code class="docutils literal notranslate"><span class="pre">init_process_group</span></code> 의 <code class="docutils literal notranslate"><span class="pre">rank</span></code> 와 <code class="docutils literal notranslate"><span class="pre">size</span></code> 인자를
불필요하게 만드는 <a class="reference external" href="#initialization-methods">초기화 방법</a> 에서 설명한 handshake 를
수행합니다. 각 프로세스의 계산 리소스를 맞추기 위해``mpirun``에 추가 인자를 전달할
수 있기 때문에 이것이 실제로 강력합니다.
(프로세스 당 코어 수, 특정 순위의 머신에 수동 할당,
<a class="reference external" href="https://www.open-mpi.org/faq/?category=running#mpirun-hostfile">기타 추가</a>
할 것들)
이렇게하면 다른 통신 백엔드와 같고 익숙한 출력을 얻어야합니다.</p>
</div>
<div class="section" id="id3">
<h3>초기화 방법<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>이 튜토리얼을 끝내기 위해, 호출한 첫 번째 함수인
<code class="docutils literal notranslate"><span class="pre">dist.init_process_group(backend,</span> <span class="pre">init_method)</span></code> 에 대해 이야기 해봅시다. 특히
각 프로세스 간의 초기 구성 단계를 담당하는 다양한 초기화 메소드를 살펴보겠습니다.
이러한 메서드를 사용하면 이 구성이 수행되는 방법을 정의 할 수 있습니다.
하드웨어 설정에 따라, 이러한 방법 중 하나는 자연스럽게 다른 것보다 더 적합해야
합니다. 다음 섹션들에 덧붙여
<a class="reference external" href="http://pytorch.org/docs/master/distributed.html#initialization">공식 문서</a> 를
살펴 봐야합니다.</p>
<p>초기화 메소드에 대해 배우기 전에, C/C++ 관점에서 <code class="docutils literal notranslate"><span class="pre">init_process_group</span></code> 뒤에
일어나는 것을 간단히 살펴 보겠습니다.</p>
<ol class="arabic simple">
<li>먼저, 인자가 구문 분석되고 유효성 검사가 수행됩니다.</li>
<li>백엔드는 <code class="docutils literal notranslate"><span class="pre">name2channel.at</span> <span class="pre">()</span></code> 함수를 통해 해결됩니다. <code class="docutils literal notranslate"><span class="pre">Channel</span></code> 클래스가
반환되고, 데이터 전송을 수행하는 데 사용됩니다.</li>
<li>GIL이 삭제되고, <code class="docutils literal notranslate"><span class="pre">THDProcessGroupInit</span> <span class="pre">()</span></code> 가 호출됩니다. 이것은 채널을
instantiates 하고 마스터 노드의 주소를 추가합니다.</li>
<li>순위 0의 프로세스는 <code class="docutils literal notranslate"><span class="pre">마스터</span></code> 단계를 실행하지만 다른 모든 순위는 <code class="docutils literal notranslate"><span class="pre">워커</span></code> 가
됩니다.</li>
<li>마스터<ol class="loweralpha">
<li>모든 워커를 위한 소켓을 생성합니다.</li>
<li>모든 워커가 연결되기를 기다립니다.</li>
<li>다른 프로세스의 위치에 대한 정보를 보냅니다.</li>
</ol>
</li>
<li>워커<ol class="loweralpha">
<li>마스터에 소켓을 생성합니다.</li>
<li>자신의 위치 정보를 보냅니다.</li>
<li>다른 워커에 대한 정보를 받습니다.</li>
<li>다른 모든 워커와 소켓을 열고 handshake를 합니다.</li>
</ol>
</li>
<li>초기화가 완료되고 모두가 모두와 연결됩니다.</li>
</ol>
<p><strong>환경 변수</strong></p>
<p>이 튜토리얼에서는 환경 변수 초기화 메소드를 사용해 왔습니다. 모든 머신에서 다음
네가지 환경 변수를 설정해서 모든 프로세스들이 마스터와 적합하게 연결될 수 있고
다른 프로세스의 정보를 얻고, 최종적으로 그들과 handshake 할 수 있습니다.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">MASTER_PORT</span></code>: 순위 0의 프로세스를 호스트 할 머신의 자유 포트.</li>
<li><code class="docutils literal notranslate"><span class="pre">MASTER_ADDR</span></code>: 순위 0의 프로세스를 호스트 할 머신의 IP 주소.</li>
<li><code class="docutils literal notranslate"><span class="pre">WORLD_SIZE</span></code>: 기다려야하는 워커 숫자를 마스터가 알 수 있게하는 총 프로세스 수.</li>
<li><code class="docutils literal notranslate"><span class="pre">RANK</span></code>: 워커의 마스터 인지 아닌지를 알 수 있게 하는 각 프로세스의 순위.</li>
</ul>
<p><strong>공유 파일 시스템(Shared File System)</strong></p>
<p>공유 파일 시스템은 모든 프로세스가 공유 파일 시스템에 접속하는 것을 요구하며 공유
파일을 통해 이를 구성합니다. 이것은 각 프로세스가 파일을 열고, 정보를 쓰고, 모두가
그렇게 할 때까지 기다리는 것을 의미합니다. 필요한 모든 정보는 모든 프로세스에게
쉽게 사용 가능할 것입니다. 경쟁 조건을 피하기 위해 파일 시스템은
<a class="reference external" href="http://man7.org/linux/man-pages/man2/fcntl.2.html">fcntl</a> 을 통한 잠금을
지원해야합니다. 순위를 수동으로 지정하거나 프로세스가 스스로 순위를 매길 수
있습니다. 작업마다 고유한 <code class="docutils literal notranslate"><span class="pre">groupname</span></code> 을 정의하면, 여러 작업에 대해 동일한
파일 경로를 사용하고 충돌을 안전하게 피할 수 있습니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;file:///mnt/nfs/sharedfile&#39;</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                        <span class="n">group_name</span><span class="o">=</span><span class="s1">&#39;mygroup&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>TCP 초기화 &amp; 멀티 캐스트</strong></p>
<p>TCP를 통한 초기화는 두 가지 방법으로 수행될 수 있습니다.:</p>
<ol class="arabic simple">
<li>순위 0 프로세스의 IP 주소와 worold의 크기를 제공.</li>
<li><em>어떤</em> 유효한 IP <a class="reference external" href="https://en.wikipedia.org/wiki/Multicast_address">멀티 캐스트 주소</a> 와
worold의 크기를 제공.</li>
</ol>
<p>첫 번째 경우 모든 워커는 순위 0의 프로세스에 연결할 수 있으며 위에서 설명한 절차를
따릅니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;tcp://10.1.1.20:23456&#39;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>두 번째 경우에, 멀티 캐스트 주소가 잠재적으로 활성화 될 수있는 노드 그룹을 지정하고
위 절차를 수행하기 전에 각 프로세스가 초기 handshake를 허용하여 구성을 처리 할 수
있습니다. 또한 TCP 멀티 캐스트 초기화는 동일한 클러스터에서 여러 작업을 스케줄 할
수 있도록 <code class="docutils literal notranslate"><span class="pre">group_name</span></code> 인자 (공유 파일 방법과 동일)를 지원합니다.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;tcp://[ff15:1e18:5d4c:4cf0:d02d:b659:53ba:b0a7]:23456&#39;</span><span class="p">,</span>
                        <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<!--
## Internals
* init_process_group 뒤에 있는 마법 :

1. 인자의 유효성을 검사하고 구문을 분석합니다.
2. 백엔드 해결 : name2channel.at()
3. Drop GIL & THDProcessGroupInit : 채널을 인스턴스화하고 config의 마스터 주소를
   추가합니다.
4. 순위 0이 마스터, 다른 워커 초기화
5. 마스터 : 모든 워커를 위한 소켓 생성 -> 모든 워커가 연결될 때까지 대기 -> 다른
   프로세스의 위치에 대한 정보를 각자에게 보냄
6. 워커 : 마스터에 소켓을 생성하고, 자신의 정보를 보내고, 각 워커에 대한 정보를
   얻고, 각각과 handshake를 한다.
7. 이 때 모두가 모두와 handshake를 한다.
--><center><p><strong>알림</strong></p>
</center><p>PyTorch 개발자들이 구현, 문서화 및 테스트을 잘 수행해 준 것에 대해 감사드리고
싶습니다. 코드가 불분명 할 때, 나는 언제나 답을 찾기위해
<a class="reference external" href="http://pytorch.org/docs/master/distributed.html">docs</a> 나
<a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/test/test_distributed.py">tests</a> 의
도움을 받았습니다. 특히, 초기 초안에 대한 통찰력있는 의견 및 질문에 답변해주신
Soumith Chintala, Adam Paszke 및 Natalia Gimelshein에게 감사드립니다.</p>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="spatial_transformer_tutorial.html" class="btn btn-neutral float-right" title="공간 변형기 네트워크(Spatial Transformer Networks) 튜토리얼" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="reinforcement_q_learning.html" class="btn btn-neutral" title="강화 학습 (DQN) 튜토리얼" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Pytorch로 분산 어플리케이션 개발하기</a><ul>
<li><a class="reference internal" href="#setup">Setup</a></li>
<li><a class="reference internal" href="#point-to-point-communication">지점간 통신(Point-to-Point Communication)</a></li>
<li><a class="reference internal" href="#collective-communication">집단 통신 (Collective Communication)</a></li>
<li><a class="reference internal" href="#distributed-training">분산 학습(Distributed Training)</a><ul>
<li><a class="reference internal" href="#our-own-ring-allreduce">Our Own Ring-Allreduce</a></li>
</ul>
</li>
<li><a class="reference internal" href="#advanced-topics">Advanced Topics</a><ul>
<li><a class="reference internal" href="#id2">통신 백엔드</a></li>
<li><a class="reference internal" href="#id3">초기화 방법</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.4.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/language_data.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-71919972-3', 'auto');
  ga('send', 'pageview');

</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>