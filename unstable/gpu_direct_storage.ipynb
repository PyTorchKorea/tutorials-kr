{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Google Colab\uc5d0\uc11c \ub178\ud2b8\ubd81\uc744 \uc2e4\ud589\ud558\uc2e4 \ub54c\uc5d0\ub294 \n# https://tutorials.pytorch.kr/beginner/colab \ub97c \ucc38\uace0\ud558\uc138\uc694.\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# (prototype) Accelerating ``torch.save`` and ``torch.load`` with GPUDirect Storage\n\nGPUDirect Storage enables a direct data path for direct memory access transfers\nbetween GPU memory and storage, avoiding a bounce buffer through the CPU.\n\nIn version **2.7**, we introduced new prototype APIs to ``torch.cuda.gds`` that serve as thin wrappers around\nthe [cuFile APIs](https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-io-api)\nthat can be used with ``torch.Tensor`` to achieve improved I/O performance.\n\nIn this tutorial, we will demonstrate how to use the ``torch.cuda.gds`` APIs in conjunction with\ncheckpoints generated by ``torch.save`` and ``torch.load`` on local filesystem. \n\n.. grid:: 2\n\n    .. grid-item-card:: :octicon:`mortar-board;1em;` What you will learn\n       :class-card: card-prerequisites\n\n       * Understand how to use the ``torch.cuda.gds`` APIs in conjunction with\n         checkpoints generated by ``torch.save`` and ``torch.load`` on local filesystem\n    \n    .. grid-item-card:: :octicon:`list-unordered;1em;` Prerequisites\n       :class-card: card-prerequisites\n\n       * PyTorch v.2.7.0 or later\n       * GPUDirect Storage must be installed per\n         [the documentation](https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/contents.html)\n       * Ensure that the filesystem that you are saving/loading to supports GPUDirect Storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using GPUDirect Storage with ``torch.save`` and ``torch.load``\nGPUDirect Storage requires a storage alignment of 4KB. You can toggle this by using\n``torch.utils.serialization.config.save.storage_alignment``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.utils.serialization import config as serialization_config\n\nserialization_config.save.storage_alignment = 4096"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The steps involved in the process are as follows:\n   * Write the checkpoint file without any actual data. This reserves the space on disk.\n   * Read the offsets for the storage associated with each tensor in the checkpoint using ``FakeTensor``.\n   * Use ``GDSFile`` to write the appropriate data at these offsets.\n\nGiven a state dictionary of tensors that are on the GPU, one can use the ``torch.serialization.skip_data`` context\nmanager to save a checkpoint that contains all relevant metadata except the storage bytes. For each ``torch.Storage``\nin the state dictionary, space will be reserved within the checkpoint for the storage bytes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n\nm = nn.Linear(5, 10, device='cuda')\nsd = m.state_dict()\n\nwith torch.serialization.skip_data():\n    torch.save(sd, \"checkpoint.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can get the offsets that each storage should be written to within the checkpoint by loading under\na ``FakeTensorMode``. A FakeTensor is a tensor that has metadata (such as sizes, strides, dtype, device)\ninformation about the tensor but does not have any storage bytes. The following snippet will not materialize\nany data but will tag each ``FakeTensor`` with the offset within the checkpoint that\ncorresponds to the tensor.\n\nIf you are continuously saving the same state dictionary during training, you\nwould only need to obtain the offsets once and the same offsets can be re-used. Similarly if tensor is going to\nbe saved or loaded to repeatedly you can use the ``torch.cuda.gds.gds_register_buffer`` which wraps\n``cuFileBufRegister`` to register the storages as GDS buffers.\n\nNote that ``torch.cuda.gds.GdsFile.save_storage`` binds to the synchronous ``cuFileWrite`` API,\nso no synchronization is needed afterwards.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom torch._subclasses.fake_tensor import FakeTensorMode\n\nwith FakeTensorMode() as mode:\n    fake_sd = torch.load(\"checkpoint.pt\")\n\nfor k, v in fake_sd.items():\n    print(f\"key={k}, offset={v.untyped_storage()._checkpoint_offset}\")\n\nf = torch.cuda.gds.GdsFile(\"checkpoint.pt\", os.O_RDWR)\n\nfor k, v in sd.items():\n    offset = fake_sd[k].untyped_storage()._checkpoint_offset\n    # save_storage is a wrapper around `cuFileWrite`\n    f.save_storage(v.untyped_storage(), offset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We verify correctness of the saved checkpoint by ``torch.load`` and comparing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sd_loaded = torch.load(\"checkpoint.pt\")\nfor k, v in sd_loaded.items():\n    assert torch.equal(v, sd[k])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The loading flow is the inverse: you can use ``torch.load`` with the ``torch.serialization.skip_data`` context\nmanager to load everything except the storage bytes. This means that any tensors in the checkpoint will be\ncreated but their storages will be empty (as if the tensors were created via ``torch.empty``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with torch.serialization.skip_data():\n    sd_loaded = torch.load(\"checkpoint.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We once again use the ``FakeTensorMode`` to get the checkpoint offsets and\nascertain that the loaded checkpoint is the same as the saved checkpoint.\n\nSimilar to  ``torch.cuda.gds.GdsFile.save_storage``, ``torch.cuda.gds.GdsFile.load_storage``\nbinds to the synchronous ``cuFileRead`` API, so no synchronization is needed afterwards.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for k, v in sd_loaded.items():\n    assert not torch.equal(v, sd[k])\n    offset = fake_sd[k].untyped_storage()._checkpoint_offset\n    # load_storage is a wrapper around `cuFileRead`\n    f.load_storage(v.untyped_storage(), offset)\n\nfor k, v in sd_loaded.items():\n    assert torch.equal(v, sd[k])\n\ndel f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n\nIn this tutorial we have demonstrated how to use the prototype ``torch.cuda.gds`` APIs\nin conjunction with ``torch.save`` and ``torch.load`` on local filesystem. Please\nfile an issue in the PyTorch GitHub repo if you have any feedback.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}